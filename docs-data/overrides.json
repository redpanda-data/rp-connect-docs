{
  "inputs": [
    {
      "name": "amqp_0_9",
      "config": {
        "children": [
          {
            "name": "urls",
            "type": "array",
            "description": "A list of URLs to connect to. This input attempts to connect to each URL in the list, in order, until a successful connection is established. It then continues to use that URL until the connection is closed.\n\nIf an item in the list contains commas, it is split into multiple URLs."
          },
          {
            "name": "queue_declare",
            "description": "Passively declares the <<queue, target queue>> to make sure a queue with the specified name exists and is configured correctly. If the queue exists, then the passive declaration verifies that fields specified in this object match the its properties.",
            "children": [
              {
                "name": "auto_delete",
                "description": "Whether the declared queue auto-deletes when there are no active consumers."
              },
              {
                "name": "arguments",
                "type": "object",
                "description": "Arguments for server-specific implementations of the queue (optional). You can use arguments to configure additional parameters for queue types that require them. For more information about available arguments, see the https://github.com/rabbitmq/amqp091-go/blob/b3d409fe92c34bea04d8123a136384c85e8dc431/types.go#L282-L362[RabbitMQ Client Library^].\n\n[cols=\"1,2,2\"]\n|===\n| Argument | Description | Accepted values\n\n| `x-queue-type`\n| Declares the type of queue.\n| Options: `classic` (default), `quorum`, `stream`, `drop-head`, `reject-publish`, and `reject-publish-dlx`.\n\n| `x-max-length`\n| The maximum number of messages in the queue.\n| A non-negative integer.\n\n| `x-max-length-bytes`\n| The maximum size of messages (in bytes) in the queue.\n| A non-negative integer.\n\n| `x-overflow`\n| Sets the queue's overflow behavior.\n| Options: `drop-head` (default), `reject-publish`, `reject-publish-dlx`.\n\n| `x-message-ttl`\n| The duration (in milliseconds) that messages remain in the queue before they expire and are discarded.\n| A string that represents the number of milliseconds. For example, `60000` retains messages for one minute.\n\n| `x-expires`\n| The duration after which the queue automatically expires.\n| A positive integer.\n\n| `x-max-age`\n| The duration (in configurable units) that streamed messages are retained on disk before they are discarded.\n| Options: `Y`, `M`, `D`, `h`, `m`, `s`. For example, `7D` retains messages for a week.\n\n| `x-stream-max-segment-size-bytes`\n| The maximum size (in bytes) of the segment files held on disk.\n| A positive integer. Default: `500000000` (approximately 500 MB).\n\n| `x-queue-version`\n| The version of the classic queue to use.\n| Options: `1` or `2`.\n\n| `x-consumer-timeout`\n| The duration (in milliseconds) that a consumer can remain idle before it is automatically canceled.\n| A positive integer that represents the number of milliseconds. For example, `60000` sets a timeout duration of one minute.\n\n| `x-single-active-consumer`\n| When set to `true`, a single consumer receives messages from the queue even when multiple consumers are subscribed to it.\n| A boolean.\n\n|==="
              }
            ]
          },
          {
            "name": "bindings_declare",
            "description": "Passively declares the bindings of the target queue to make sure they exist and are configured correctly. If the bindings exist, then the passive declaration verifies that fields specified in this object match them."
          },
          {
            "name": "consumer_tag",
            "description": "A consumer tag to uniquely identify the consumer."
          },
          {
            "name": "auto_ack",
            "description": "Set to `true` to automatically acknowledge messages as soon as they are consumed rather than waiting for acknowledgments from downstream. This can improve throughput and prevent the pipeline from becoming blocked, but delivery guarantees are lost."
          },
          {
            "name": "nack_reject_patterns",
            "type": "array",
            "description": "A list of regular expression patterns to match against errors in messages that Redpanda Connect fails to deliver. When a message has an error that matches a pattern, it is dropped or delivered to a dead-letter queue (if a queue has been configured).\n\nBy default, failed messages are negatively acknowledged (nacked) and requeued."
          },
          {
            "name": "prefetch_count",
            "description": "The maximum number of pending messages at a given time."
          },
          {
            "name": "prefetch_size",
            "description": "The maximum size of pending messages (in bytes) at a given time."
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "root_cas",
                "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, that contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate, specify values for either the `cert` and `key` fields, or the `cert_file` and `key_file` fields."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "aws_kinesis",
      "config": {
        "children": [
          {
            "name": "dynamodb",
            "children": [
              {
                "name": "endpoint",
                "description": "Specify a custom endpoint for the AWS API."
              },
              {
                "name": "credentials",
                "description": "Manually configure the AWS credentials to use (optional). For more information, see the xref:guides:cloud/aws.adoc[].",
                "children": [
                  {
                    "name": "profile",
                    "description": "The profile from `~/.aws/credentials` to use."
                  },
                  {
                    "name": "id",
                    "description": "The ID of the AWS credentials to use."
                  },
                  {
                    "name": "secret",
                    "description": "The secret for the AWS credentials in use."
                  },
                  {
                    "name": "token",
                    "description": "The token for the AWS credentials in use. This is a required value for short-term credentials."
                  },
                  {
                    "name": "role",
                    "description": "The role ARN to assume."
                  },
                  {
                    "name": "role_external_id",
                    "description": "An external ID to use when assuming a role."
                  }
                ]
              }
            ]
          },
          {
            "name": "endpoint",
            "description": "Specify a custom endpoint for the AWS API."
          },
          {
            "name": "credentials",
            "description": "Manually configure the AWS credentials to use (optional). For more information, see the xref:guides:cloud/aws.adoc[].",
            "children": [
              {
                "name": "profile",
                "description": "The profile from `~/.aws/credentials` to use."
              },
              {
                "name": "id",
                "description": "The ID of the AWS credentials to use."
              },
              {
                "name": "secret",
                "description": "The secret for the AWS credentials in use."
              },
              {
                "name": "token",
                "description": "The token for the AWS credentials in use. This is a required value for short-term credentials."
              },
              {
                "name": "role",
                "description": "The role ARN to assume."
              },
              {
                "name": "role_external_id",
                "description": "An external ID to use when assuming a role."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "aws_sqs",
      "config": {
        "children": [
          {
            "name": "delete_message",
            "description": "Whether to delete the consumed message when it's acknowledged. Set to `false` to handle the deletion using a different mechanism."
          },
          {
            "name": "reset_visibility",
            "description": "Whether to set the visibility timeout of the consumed message to zero if Redpanda Connect receives a negative acknowledgement. Set to `false` to use the https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html[queue's visibility timeout^] for each message rather than releasing the message immediately for reprocessing."
          },
          {
            "name": "max_number_of_messages",
            "description": "The maximum number of messages that Redpanda Connect can return each time it polls the SQS URL. Enter values from `1` to `10` only."
          },
          {
            "name": "max_outstanding_messages",
            "description": "The maximum number of pending messages that Redpanda Connect can have in flight at the same time."
          },
          {
            "name": "wait_time_seconds",
            "description": "Whether to set a wait time (in seconds). Enter values from `1` to `20` to enable wait times and to activate https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-short-and-long-polling.html[log polling^] for queued messages."
          },
          {
            "name": "message_timeout",
            "description": "The maximum time allowed to process a received message before Redpanda Connect refreshes the https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-queue-message-identifiers.html[receipt handle^], and the message becomes visible in the queue again. Redpanda Connect attempts to refresh the receipt handle after half of the timeout has elapsed."
          }
        ]
      }
    },
    {
      "name": "azure_blob_storage",
      "config": {
        "children": [
          {
            "name": "targets_input",
            "description": "CAUTION: This is an experimental field that provides an optional source of download targets, configured as a xref:components:inputs/about.adoc[regular Redpanda Connect input]. Each message yielded by this input should be a single structured object containing a field `name`, which represents the blob to be downloaded.\n\nThis requires setting up https://learn.microsoft.com/en-gb/azure/event-grid/event-schema-blob-storage[Azure Blob Storage as an Event Grid source^] and an associated event handler that a Redpanda Connect input can read from. For example, use either one of the following:  \n\n* https://learn.microsoft.com/en-gb/azure/event-grid/handler-event-hubs[Azure Event Hubs] using the `kafka` input \n* https://learn.microsoft.com/en-gb/azure/event-grid/handler-event-grid-namespace-topic[Namespace topics] using the `mqtt` input"
          }
        ]
      }
    },
    {
      "name": "azure_queue_storage",
      "config": {
        "children": [
          {
            "name": "queue_name",
            "description": "The name of the source storage queue.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "cassandra",
      "config": {
        "children": [
          {
            "name": "backoff",
            "children": [
              {
                "name": "initial_interval",
                "description": "The initial period to wait between retry attempts. The retry interval increases for each failed attempt, up to the `backoff.max_interval` value."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "cockroachdb_changefeed",
      "config": {
        "children": [
          {
            "name": "cursor_cache",
            "description": "A https://www.docs.redpanda.com/redpanda-connect/components/caches/about[cache resource^] to use for storing the current latest cursor that has been successfully delivered, this allows Redpanda Connect to continue from that cursor upon restart, rather than consume the entire state of the table."
          }
        ]
      }
    },
    {
      "name": "gateway",
      "description": "The `gateway` input is a Cloud-only component that receives messages over HTTP and injects them into a running Redpanda Connect pipeline.\n\nIt's ideal for:\n- Receiving webhook events from third-party services\n- Accepting real-time telemetry or sensor data over HTTP\n- Building lightweight ingest endpoints for client apps\n\nFor on-premises or self-managed deployments, use the xref:redpanda-connect:components:inputs/http_server.adoc[`http_server`] input instead.\n\nThis component is fully managed and available in the following Redpanda Cloud deployment types:\n\n- **Serverless**\n- **Dedicated**\n- **Bring Your Own Cloud (BYOC)**\n\nWhen a pipeline with a `gateway` input is deployed, Redpanda Cloud provisions a secure URL that you can use to send HTTP requests. You can post raw payloads, JSON messages, or stream events in real time.\n\nAuthentication and access control are handled through standard Redpanda Cloud API tokens. For more information, see xref:redpanda-cloud:manage:api/cloud-api-authentication.adoc[].\n\nNetwork access:\n- On **public clusters** (Serverless and Dedicated), the gateway URL is accessible over the public internet.\n- On **private clusters** (BYOC), the gateway is accessible only from within your configured VPC.\n\n== Responses\n\nYou can return a response for each message received using xref:guides:sync_responses.adoc[synchronous responses]. When doing so, you can customize headers using the `sync_response.headers` field, which supports xref:configuration:interpolation.adoc#bloblang-queries[function interpolation] in the value based on the response message contents.\n\n== Metadata\n\nThis input adds the following metadata fields to each message:\n\n- `http_server_user_agent`\n- `http_server_request_path`\n- `http_server_verb`\n- `http_server_remote_ip`\n- All headers (only first values are taken)\n- All query parameters\n- All path parameters\n- All cookies\n\nYou can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation]."
    },
    {
      "name": "gcp_bigquery_select",
      "config": {
        "children": [
          {
            "name": "credentials_json",
            "description": "Optional field to set https://developers.google.com/workspace/guides/create-credentials#create_credentials_for_a_service_account[Google Service Account Credentials JSON^]."
          }
        ]
      }
    },
    {
      "name": "gcp_cloud_storage",
      "config": {
        "children": [
          {
            "name": "prefix",
            "description": "Optional path prefix, if set only objects with the prefix are consumed."
          },
          {
            "name": "credentials_json",
            "description": "Optional field to set https://developers.google.com/workspace/guides/create-credentials#create_credentials_for_a_service_account[Google Service Account Credentials JSON^]."
          }
        ]
      }
    },
    {
      "name": "gcp_pubsub",
      "config": {
        "children": [
          {
            "name": "credentials_json",
            "description": "Optional field to set https://developers.google.com/workspace/guides/create-credentials#create_credentials_for_a_service_account[Google Service Account Credentials JSON^]."
          }
        ]
      }
    },
    {
      "name": "gcp_spanner_cdc",
      "description": "\nConsumes change records from a Google Cloud Spanner change stream. This input allows\nyou to track and process database changes in real-time, making it useful for data\nreplication, event-driven architectures, and maintaining derived data stores.\n\nThe input reads from a specified change stream within a Spanner database and converts\neach change record into a message. The message payload contains the change records in\nJSON format, and metadata is added with details about the Spanner instance, database,\nand stream.\n\nChange streams provide a way to track mutations to your Spanner database tables. For\nmore information about Spanner change streams, refer to the link:https://cloud.google.com/spanner/docs/change-streams[Google Cloud documentation^].",
      "config": {
        "children": [
          {
            "name": "stream_id",
            "description": "The name of the change stream to track, the stream must exist in the database. To create a change stream, see the link:https://cloud.google.com/spanner/docs/change-streams/manage[Google Cloud documentation^]."
          },
          {
            "name": "auto_replay_nacks",
            "description": "Whether to automatically replay messages that are rejected (nacked) at the output level. If the cause of rejections is persistent, leaving this option enabled can result in back pressure.\n\nSet `auto_replay_nacks` to `false` to delete rejected messages. Disabling auto replays can greatly improve memory efficiency of high throughput streams, as the original shape of the data is discarded immediately upon consumption and mutation."
          },
          {
            "name": "credentials_json",
            "description": "Base64-encoded JSON credentials file for authenticating to GCP with a service account. If not provided, Application Default Credentials (ADC) is used.\n\nFor more information about how to create a service account and obtain the credentials JSON, see the link:https://cloud.google.com/docs/authentication/getting-started[Google Cloud documentation^]."
          },
          {
            "name": "database_id",
            "description": "The ID of the Spanner database to read from. This is the name of the database as it appears in the Spanner console or API.\n\nFor more information about how to create a Spanner database, see the link:https://cloud.google.com/spanner/docs/create-manage-databases[Google Cloud documentation^]."
          },
          {
            "name": "end_timestamp",
            "description": "The timestamp at which to stop reading change records from the change stream. This is an optional field that allows you to limit the range of change records processed by the input.\n\nThe timestamp should be in RFC3339 format, such as `2023-10-01T00:00:00Z`. If not provided, the input reads all available change records up to the current time."
          },
          {
            "name": "heartbeat_interval",
            "description": "The interval at which to send heartbeat messages to the output. Heartbeat messages are sent to indicate that the input is still active and processing changes. This can help prevent timeouts in downstream systems.\n\nSupported time units are `ns`, `us`, `ms`, `s`, `m`, and `h`. For example, `1s` sends a heartbeat every second."
          },
          {
            "name": "instance_id",
            "description": "The ID of the Spanner instance to read from. This is the name of the instance as it appears in the Spanner console or API.\n\nFor more information about how to create a Spanner instance, see the link:https://cloud.google.com/spanner/docs/create-manage-instances[Google Cloud documentation^]."
          },
          {
            "name": "metadata_table",
            "description": "The table to store metadata in (default: `cdc_metadata_<stream_id>`)."
          },
          {
            "name": "min_watermark_cache_ttl",
            "description": "Sets how frequently to query Spanner for the minimum watermark."
          },
          {
            "name": "project_id",
            "description": "The ID of the GCP project that contains the Spanner instance and database. This is the name of the project as it appears in the GCP console or API.\n\nFor more information about how to create a GCP project, see the link:https://cloud.google.com/resource-manager/docs/creating-managing-projects[Google Cloud documentation^]."
          },
          {
            "name": "start_timestamp",
            "description": "The timestamp at which to start reading change records from the change stream. This is an optional field that allows you to limit the range of change records processed by the input.\n\nThe timestamp should be in RFC3339 format, such as `2023-10-01T00:00:00Z` (default: current time)."
          },
          {
            "name": "stream_id",
            "description": "The name of the change stream to track. The stream must exist in the Spanner database. To create a change stream, follow the link:https://cloud.google.com/spanner/docs/change-streams/manage[Google Cloud documentation^]."
          },
          {
            "name": "batching",
            "children": [
              {
                "name": "byte_size",
                "description": "The maximum total size (in bytes) that a batch can reach before it is passed on for processing or delivery (flushed). When the combined size of all messages in the batch exceeds this limit, the batch is immediately sent to the next stage (such as a processor or output).\n\nSet to `0` to disable size-based batching. When disabled, messages are flushed based on other conditions (such as `batching.count` or `batching.period`)."
              },
              {
                "name": "check",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that returns a boolean value indicating whether a message should end a batch."
              },
              {
                "name": "count",
                "description": "The number of messages at which the batch should be flushed. Set the value to `0` to disable count-based batching."
              },
              {
                "name": "period",
                "description": "The length of time after which an incomplete batch should be flushed regardless of its size. Supported time units are `ns`, `us`, `ms`, `s`, `m`, and `h`. For example, `1s` flushes a batch after one second."
              },
              {
                "name": "processors",
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. All resulting messages are flushed as a single batch, so any attempt to split it into smaller batches with these processors will be ignored."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "git",
      "config": {
        "children": [
          {
            "name": "branch",
            "description": "The repository branch to check out."
          },
          {
            "name": "poll_interval",
            "description": "How frequently this input polls the Git repository for changes."
          },
          {
            "name": "include_patterns",
            "type": "array",
            "description": "A list of file patterns to read from. For example, you could read content from only Markdown and YAML files: `'**/*.md', 'configs/*.yaml'`. \n\nThe following patterns are supported:\n\n- Glob patterns: `*`, `/**/`, `?`\n- Character ranges: `[a-z]`. Escape any character with a special meaning using a backslash.\n\nIf this field is left empty, all files are read from."
          },
          {
            "name": "exclude_patterns",
            "type": "array",
            "description": "A list of file patterns to exclude. For example, you could choose not to read content from certain Git directories or image files: `'.git/**', '**/*.png'`. These patterns take precedence over `include_patterns`.\n\nThe following patterns are supported:\n\n- Glob patterns: `*`, `/**/`, `?`\n- Character ranges: `[a-z]`. Escape any character with a special meaning using a backslash."
          },
          {
            "name": "max_file_size",
            "description": "The maximum size of files to read from (in bytes). Files that exceed this limit are skipped. Set to `0` for unlimited file sizes."
          },
          {
            "name": "checkpoint_cache",
            "description": "Specify a xref:components:caches/about.adoc[`cache`] resource to store the last processed commit hash. After a restart, Redpanda Connect can then continue processing changes from where it left off, avoiding the need to reprocess all detected updates."
          },
          {
            "name": "auth",
            "description": "Options for authenticating with your Git repository.",
            "children": [
              {
                "name": "basic",
                "description": "Allows you to specify basic authentication.",
                "children": [
                  {
                    "name": "username",
                    "description": "The username to use for authentication."
                  },
                  {
                    "name": "password",
                    "description": "A password to authenticate with."
                  }
                ]
              },
              {
                "name": "ssh_key",
                "description": "Allows you to specify SSH key authentication.",
                "children": [
                  {
                    "name": "private_key_path",
                    "description": "The path to your private SSH key file. When using encrypted keys, you must also set a value for <<auth-ssh_key-passphrase, `private_key_passphrase`>>."
                  },
                  {
                    "name": "private_key",
                    "description": "Your private SSH key. When using encrypted keys, you must also set a value for <<auth-ssh_key-passphrase, `private_key_passphrase`>>."
                  },
                  {
                    "name": "passphrase",
                    "description": "The passphrase for your SSH private key."
                  }
                ]
              },
              {
                "name": "token",
                "description": "Allows you to specify token-based authentication.",
                "children": [
                  {
                    "name": "value",
                    "description": "The token value to use for token-based authentication."
                  }
                ]
              }
            ]
          },
          {
            "name": "auto_replay_nacks",
            "description": "Whether to automatically replay messages that are rejected (nacked) at the output level. If the cause of rejections is persistent, leaving this option enabled can result in back pressure.\n\nSet `auto_replay_nacks` to `false` to delete rejected messages. Disabling auto replays can greatly improve memory efficiency of high throughput streams, as the original shape of the data is discarded immediately upon consumption and mutation."
          }
        ]
      }
    },
    {
      "name": "http_client",
      "config": {
        "children": [
          {
            "name": "url",
            "description": "The URL to connect to. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "verb",
            "description": "A verb to connect with."
          },
          {
            "name": "headers",
            "description": "A map of headers to add to the request. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "metadata",
            "description": "Specify matching rules that determine which metadata keys to add to the HTTP request as headers (optional)."
          },
          {
            "name": "dump_request_log_level",
            "description": "EXPERIMENTAL: Set the logging level for the request and response payloads of each HTTP request."
          },
          {
            "name": "oauth",
            "description": "Allows you to specify open authentication using OAuth version 1.",
            "children": [
              {
                "name": "consumer_secret",
                "description": "The secret used to establish ownership of the consumer key."
              },
              {
                "name": "access_token",
                "description": "The value used to gain access to the protected resources on behalf of the user."
              },
              {
                "name": "access_token_secret",
                "description": "The secret that establishes ownership of the `oauth.access_token`."
              }
            ]
          },
          {
            "name": "oauth2",
            "description": "Allows you to specify open authentication using OAuth version 2 and the client credentials token flow.",
            "children": [
              {
                "name": "client_secret",
                "description": "The secret used to establish ownership of the client key."
              },
              {
                "name": "scopes",
                "description": "A list of requested permissions (optional)."
              },
              {
                "name": "endpoint_params",
                "description": "A list of endpoint parameters specified as arrays of strings (optional)."
              }
            ]
          },
          {
            "name": "jwt",
            "description": "BETA: Allows you to specify JSON Web Token (JWT) authentication.",
            "children": [
              {
                "name": "private_key_file",
                "description": "A file with the PEM encoded using PKCS1 or PKCS8 as private key."
              },
              {
                "name": "signing_method",
                "description": "A method used to sign the token, such as RS256, RS384, RS512 or EdDSA."
              },
              {
                "name": "headers",
                "description": "Add key/value headers to the JWT (optional)."
              }
            ]
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "root_cas",
                "description": "Specify a root certificate authority to use (optional). This is a string, representing a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate, specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "extract_headers",
            "description": "Specify which response headers to add to the resulting messages as metadata. Header keys are automatically converted to lowercase before matching, so make sure that your patterns target the lowercase versions of the expected header keys."
          },
          {
            "name": "rate_limit",
            "description": "A xref:components:rate_limits/about.adoc[rate limit] to throttle requests by (optional)."
          },
          {
            "name": "retry_period",
            "description": "The initial period to wait between failed requests before retrying."
          },
          {
            "name": "backoff_on",
            "description": "A list of status codes that indicate a request failure, and trigger retries with an increasing backoff period between attempts."
          },
          {
            "name": "drop_on",
            "description": "A list of status codes that indicate a request failure, where the input should not attempt retries. This helps avoid unnecessary retries for requests that are unlikely to succeed.\n\nNOTE: In these cases, the _request_ is dropped, but the _message_ that triggered the request is retained."
          },
          {
            "name": "successful_on",
            "description": "A list of HTTP status codes that should be considered as successful, even if they are not 2XX codes. This is useful for handling cases where non-2XX codes indicate that the request was processed successfully, such as `303 See Other` or `409 Conflict`. \n\nBy default, all 2XX codes are considered successful unless they are specified in `backoff_on` or `drop_on` fields."
          },
          {
            "name": "proxy_url",
            "description": "A HTTP proxy URL (optional)."
          },
          {
            "name": "disable_http2",
            "description": "Whether to disable HTTP/2. By default, HTTP/2 is enabled."
          },
          {
            "name": "payload",
            "description": "A payload to deliver for each request (optional). This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "drop_empty_bodies",
            "description": "Whether to drop empty payloads received from the target server."
          },
          {
            "name": "stream",
            "description": "Enables streaming mode, where the HTTP connection remains open and messages are processed line-by-line.",
            "children": [
              {
                "name": "reconnect",
                "description": "Whether to automatically reestablish the HTTP connection if it is lost."
              },
              {
                "name": "scanner",
                "description": "The xref:components:scanners/about.adoc[scanner] used to split the stream of bytes into individual messages. Scanners are useful for processing large data sources efficiently without holding the entire data set in memory. For example, the `csv` scanner processes individual rows in a CSV file without loading the entire file in memory."
              }
            ]
          },
          {
            "name": "auto_replay_nacks",
            "description": "Whether to automatically replay rejected messages (negative acknowledgements) at the output level. If the cause of rejections persists, leaving this option enabled can result in back pressure.\n\nSet `auto_replay_nacks` to `false` to delete rejected messages. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data is discarded immediately upon consumption and mutation."
          }
        ]
      }
    },
    {
      "name": "http_server",
      "config": {
        "children": [
          {
            "name": "sync_response",
            "children": [
              {
                "name": "status",
                "description": "Specify the status code to return with synchronous responses. This is a string value, which allows you to customize it based on resulting payloads and their metadata.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
              },
              {
                "name": "headers",
                "description": "Specify headers to return with synchronous responses.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "kafka",
      "config": {
        "children": [
          {
            "name": "instance_id",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, assign a unique value to `instance_id` to help brokers identify each input after restarts and prevent unnecessary rebalances."
          }
        ]
      }
    },
    {
      "name": "kafka_franz",
      "config": {
        "children": [
          {
            "name": "seed_brokers",
            "description": "A list of broker addresses to connect to in order. Use commas to separate multiple addresses in a single list item."
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "root_cas",
                "description": "Specify a root certificate authority to use (optional). This is a string, representing a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate, specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "sasl",
            "description": "Specify one or more methods or mechanisms of SASL authentication, which are attempted in order. If the broker supports the first SASL mechanism, all connections use it. If the first mechanism fails, the client picks the first supported mechanism. If the broker does not support any client mechanisms, all connections fail."
          },
          {
            "name": "metadata_max_age",
            "description": "The maximum period of time after which metadata is refreshed."
          },
          {
            "name": "request_timeout_overhead",
            "description": "Grants an additional buffer or overhead to requests that have timeout fields defined. This field is based on the behavior of Apache Kafka's `request.timeout.ms` parameter."
          },
          {
            "name": "conn_idle_timeout",
            "description": "Define how long connections can remain idle before they are closed."
          },
          {
            "name": "topics",
            "description": "A list of topics to consume from. Use commas to separate multiple topics in a single element.\n\nWhen a `consumer_group` is specified, partitions are automatically distributed across consumers of a topic. Otherwise, all partitions are consumed.\n\nAlternatively, you can specify explicit partitions to consume by using a colon after the topic name. For example, `foo:0` would consume the partition `0` of the topic foo. This syntax supports ranges. For example, `foo:0-10` would consume partitions `0` through to `10` inclusive.\n\nIt is also possible to specify an explicit offset to consume from by adding another colon after the partition. For example, `foo:0:10` would consume the partition `0` of the topic `foo` starting from the offset `10`. If the offset is not present (or remains unspecified) then the field `start_offset` determines which offset to start from."
          },
          {
            "name": "rack_id",
            "description": "A rack specifies where the client is physically located, and changes fetch requests to consume from the closest replica as opposed to the leader replica."
          },
          {
            "name": "instance_id",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, assign a unique value to `instance_id` to define the group\u2019s static membership, which can prevent unnecessary rebalances during reconnections. \n\nWhen you assign an instance ID, the client does not automatically leave the consumer group when it disconnects. To remove the client, you must use an external admin command on behalf of the instance ID."
          },
          {
            "name": "rebalance_timeout",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, `rebalance_timeout` sets a time limit for all consumer group members to complete their work and commit offsets after a rebalance has begun. The timeout excludes the time taken to detect a failed or late heartbeat, which indicates a rebalance is required."
          },
          {
            "name": "session_timeout",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, `session_timeout` sets the maximum interval between heartbeats sent by a consumer group member to the broker. If a broker doesn't receive a heartbeat from a group member before the timeout expires, it removes the member from the consumer group and initiates a rebalance.\n\nbroker"
          },
          {
            "name": "heartbeat_interval",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, `heartbeat_interval` sets how frequently a consumer group member should send heartbeats to Apache Kafka. Apache Kafka uses heartbeats to make sure that a group member's session is active. \n\nYou must set `heartbeat_interval` to less than one-third of `session_timeout`.\n\nThis field is equivalent to the Java `heartbeat.interval.ms` setting.\n\nclient"
          },
          {
            "name": "start_offset",
            "description": "Specify the offset from which this input starts or restarts consuming messages. Restarts occur when the `OffsetOutOfRange` error is seen during a fetch."
          },
          {
            "name": "fetch_max_bytes",
            "description": "The maximum size of a message batch (in bytes) that a broker tries to send during a client fetch. If individual records exceed the `fetch_max_bytes` value, brokers will still send them."
          },
          {
            "name": "fetch_max_wait",
            "description": "The maximum period of time a broker can wait for a fetch response to reach the required minimum number of bytes (`fetch_min_bytes`)."
          },
          {
            "name": "fetch_min_bytes",
            "description": "The minimum number of bytes that a broker tries to send during a fetch. This field is equivalent to the Java setting `fetch.min.bytes`."
          },
          {
            "name": "fetch_max_partition_bytes",
            "description": "The maximum number of bytes that are consumed from a single partition in a fetch request. This field is equivalent to the Java setting `fetch.max.partition.bytes`.\n\nIf a single batch is larger than the `fetch_max_partition_bytes` value, the batch is still sent so that the client can make progress."
          },
          {
            "name": "transaction_isolation_level",
            "description": "Defines how transactional messages are handled."
          },
          {
            "name": "consumer_group",
            "description": "An optional consumer group. When you specify this value: \n\n- The partitions of any topics, specified in the `topics` field, are automatically distributed across consumers sharing a consumer group\n- Partition offsets are automatically committed and resumed under this name\n\nConsumer groups are not supported when you specify explicit partitions to consume from in the `topics` field."
          },
          {
            "name": "checkpoint_limit",
            "description": "The maximum number of messages that are processed in parallel inside the same partition before back pressure is applied. \n\nWhen a message with a specific offset is delivered to the output, the offset is only committed when all messages of previous offsets have also been delivered. This behavior ensures at-least-once delivery guarantees. However, in the event of crashes or server faults, it also increases the likelihood of duplicates. To decrease this risk, reduce the `checkpoint_limit` value."
          },
          {
            "name": "multi_header",
            "description": "Decode headers into lists to allow the handling of multiple values with the same key."
          },
          {
            "name": "batching",
            "description": "Configure a xref:configuration:batching.adoc[batching policy] that applies to individual topic partitions in order to batch messages together before flushing them for processing. Batching can be beneficial for performance as well as useful for windowed processing, and doing so this way preserves the ordering of topic partitions.",
            "children": [
              {
                "name": "count",
                "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
              },
              {
                "name": "byte_size",
                "description": "The number of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
              },
              {
                "name": "period",
                "description": "The period after which an incomplete batch is flushed regardless of its size."
              },
              {
                "name": "processors",
                "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
              }
            ]
          },
          {
            "name": "topic_lag_refresh_period",
            "description": "The interval between refresh cycles. During each cycle, this input queries the Redpanda Connect server to calculate the topic lag - the number of produced messages that remain to be read from each topic/partition pair by the specified consumer group."
          },
          {
            "name": "auto_replay_nacks",
            "description": "Whether to automatically replay rejected messages (negative acknowledgements) at the output level. If the cause of rejections persists, leaving this option enabled can result in back pressure.\n\nSet `auto_replay_nacks` to `false` to delete rejected messages. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data is discarded immediately upon consumption and mutation."
          }
        ]
      }
    },
    {
      "name": "mongodb_cdc",
      "config": {
        "children": [
          {
            "name": "database",
            "description": "The name of the MongoDB database to stream changes from."
          },
          {
            "name": "collections",
            "description": "A list of collections to stream changes from. Specify each collection name as a separate item."
          },
          {
            "name": "checkpoint_cache",
            "description": "Specify a xref:components:caches/about.adoc[`cache` resource] to store the oplog position for the most recent data update streamed to Redpanda Connect. After a restart, Redpanda Connect can continue processing changes from this position, avoiding the need to reprocess all collection updates."
          },
          {
            "name": "checkpoint_key",
            "description": "The key identifier used to store the oplog position in <<checkpoint_cache,`checkpoint_cache`>>. If you have multiple `mongodb_cdc` inputs sharing the same cache, you can provide an alternative key."
          },
          {
            "name": "checkpoint_limit",
            "description": "The maximum number of in-flight messages emitted from this input. Increasing this limit enables parallel processing, and batching at the output level. To preserve at-least-once guarantees, any given oplog position is not acknowledged until all messages under that offset are delivered."
          },
          {
            "name": "read_batch_size",
            "description": "The number of documents to fetch in each message batch from MongoDB."
          },
          {
            "name": "read_max_wait",
            "description": "The maximum duration MongoDB waits to accumulate the <<read_batch_size,`read_batch_size`>> documents on a change stream before returning the batch to Redpanda Connect."
          },
          {
            "name": "stream_snapshot",
            "description": "When set to `true`, this input streams a snapshot of all existing data in the source collections before streaming data changes."
          },
          {
            "name": "snapshot_parallelism",
            "description": "Specifies the number of connections to use when reading the initial snapshot from one or more collections. Increase this number to enable parallel processing of the snapshot. \n\nThis feature uses the `$splitVector` command to split snapshot data into chunks for more efficient processing.\n\nThis field is only applicable when `stream_snapshot` is set to `true`."
          },
          {
            "name": "snapshot_auto_bucket_sharding",
            "description": "Uses the https://www.mongodb.com/docs/manual/reference/operator/aggregation/bucketAuto/[`$bucketAuto`^] command instead of the default, `$splitVector`, to split the snapshot data into chunks for processing. This is required for environments, such as MongoDB Atlas, where the `$splitVector` command is not available. To enable parallel processing in these environments:\n\n- Set this field to to `true`.\n- Set `stream_snapshot` to `true`.\n- Increase `snapshot_parallelism` to a value greater than `1`."
          },
          {
            "name": "document_mode",
            "description": "The mode in which MongoDB emits document changes to Redpanda Connect, specifically updates and deletes."
          },
          {
            "name": "json_marshal_mode",
            "description": "Controls the format used to convert a message from BSON to JSON when it is received by Redpanda Connect."
          },
          {
            "name": "auto_replay_nacks",
            "description": "Whether to automatically replay rejected messages (negative acknowledgements) at the output level. If the cause of rejections is persistent, leaving this option enabled can result in back pressure.\n\nSet `auto_replay_nacks` to `false` to delete rejected messages. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data is discarded immediately upon consumption and mutation."
          }
        ]
      }
    },
    {
      "name": "mqtt",
      "config": {
        "children": [
          {
            "name": "urls",
            "type": "array",
            "description": "A list of URLs to connect to. Use the format `scheme://host:port`, where:\n\n* `scheme` is one of the following: `tcp`, `ssl`, `ws`\n* `host` is the IP address or hostname\n* `port` is the port on which the MQTT broker accepts connections\n\nIf an item in the list contains commas, it is expanded into multiple URLs."
          }
        ]
      }
    },
    {
      "name": "mysql_cdc",
      "config": {
        "children": [
          {
            "name": "dsn",
            "description": "The data source name (DSN) of the MySQL database from which you want to stream updates. Use the format `user:password@tcp(localhost:3306)/database`."
          },
          {
            "name": "tables",
            "description": "A list of the database table names to stream changes from. Specify each table name as a separate item."
          },
          {
            "name": "checkpoint_cache",
            "description": "Specify a `cache` resource to store the binlog position of the most recent data update delivered to Redpanda Connect. After a restart, Redpanda Connect can continue processing changes from this last known position, avoiding the need to reprocess all table updates."
          },
          {
            "name": "checkpoint_key",
            "description": "The key identifier used to store the binlog position in <<checkpoint_cache,`checkpoint_cache`>>. If you have multiple `mysql_cdc` inputs sharing the same cache, you can provide an alternative key."
          },
          {
            "name": "snapshot_max_batch_size",
            "description": "The maximum number of table rows to fetch in each batch when taking a snapshot. This option is only available when `stream_snapshot` is set to `true`."
          },
          {
            "name": "stream_snapshot",
            "description": "When set to `true`, this input streams a snapshot of all existing data in the source database before streaming data changes. To use this setting, all database tables that you want to replicate _must_ have a primary key."
          },
          {
            "name": "auto_replay_nacks",
            "description": "Whether to automatically replay rejected messages (negative acknowledgements) at the output level. If the cause of rejections is persistent, leaving this option enabled can result in back pressure.\n\nSet `auto_replay_nacks` to `false` to delete rejected messages. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data is discarded immediately upon consumption and mutation."
          },
          {
            "name": "checkpoint_limit",
            "description": "The maximum number of messages that this input can process at a given time. Increasing this limit enables parallel processing, and batching at the output level. To preserve at-least-once guarantees, any given binlog position is not acknowledged until all messages under that offset are delivered."
          },
          {
            "name": "batching",
            "children": [
              {
                "name": "count",
                "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
              },
              {
                "name": "byte_size",
                "description": "The number of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
              },
              {
                "name": "period",
                "description": "The period of time after which an incomplete batch is flushed regardless of its size."
              },
              {
                "name": "check",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that returns a boolean value indicating whether a message should end a batch."
              },
              {
                "name": "processors",
                "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "nats",
      "config": {
        "children": [
          {
            "name": "urls",
            "type": "array",
            "description": "A list of URLs to connect to. If a list item contains commas, it will be expanded into multiple URLs."
          },
          {
            "name": "send_ack",
            "description": "Whether an automatic acknowledgment is sent as a reply to each message. When enabled, these replies are sent only when data has been delivered to all outputs."
          },
          {
            "name": "auth",
            "children": [
              {
                "name": "nkey",
                "description": "Your NKey seed or private key."
              },
              {
                "name": "user_credentials_file",
                "description": "An optional file containing user credentials which consist of a user JWT and corresponding NKey seed."
              },
              {
                "name": "user_jwt",
                "description": "An optional plain text user JWT to use along with the corresponding user NKey seed."
              },
              {
                "name": "user_nkey_seed",
                "description": "An optional plain text user NKey seed to use along with the corresponding user JWT."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "nats_jetstream",
      "config": {
        "children": [
          {
            "name": "urls",
            "type": "array",
            "description": "A list of URLs to connect to. If a list item contains commas, it will be expanded into multiple URLs."
          },
          {
            "name": "queue",
            "description": "An optional queue group to consume as."
          },
          {
            "name": "durable",
            "description": "Preserve the state of your consumer under a durable name."
          },
          {
            "name": "auth",
            "children": [
              {
                "name": "nkey",
                "description": "Your NKey seed or private key."
              },
              {
                "name": "user_credentials_file",
                "description": "An optional file containing user credentials which consist of a user JWT and corresponding NKey seed."
              },
              {
                "name": "user_jwt",
                "description": "An optional plain text user JWT to use along with the corresponding user NKey seed."
              },
              {
                "name": "user_nkey_seed",
                "description": "An optional plain text user NKey seed to use along with the user JWT."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "nats_kv",
      "config": {
        "children": [
          {
            "name": "urls",
            "type": "array",
            "description": "A list of URLs to connect to. If a list item contains commas, it will be expanded into multiple URLs."
          },
          {
            "name": "auth",
            "children": [
              {
                "name": "nkey",
                "description": "Your NKey seed or private key."
              },
              {
                "name": "user_credentials_file",
                "description": "An optional file containing user credentials which consist of a user JWT and corresponding NKey seed."
              },
              {
                "name": "user_jwt",
                "description": "An optional plain text user JWT to use along with the corresponding user NKey seed."
              },
              {
                "name": "user_nkey_seed",
                "description": "An optional plain text user NKey seed to use along with the corresponding user JWT."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "nats_stream",
      "config": {
        "children": [
          {
            "name": "urls",
            "type": "array",
            "description": "A list of URLs to connect to. If a list item contains commas, it will be expanded into multiple URLs."
          },
          {
            "name": "auth",
            "children": [
              {
                "name": "nkey",
                "description": "Your NKey seed or private key."
              },
              {
                "name": "user_credentials_file",
                "description": "An optional file containing user credentials which consist of a user JWT and corresponding NKey seed."
              },
              {
                "name": "user_jwt",
                "description": "An optional plain text user JWT to use along with the corresponding user NKey seed."
              },
              {
                "name": "user_nkey_seed",
                "description": "An optional plain text user NKey seed to use along with the corresponding user JWT."
              }
            ]
          },
          {
            "name": "extract_tracing_map",
            "description": "EXPERIMENTAL: A xref:guides:bloblang/about.adoc[Bloblang mapping] that attempts to extract an object containing tracing propagation information, which is then used as the root tracing span for the message. The specification of the extracted fields must match the format used by the service wide tracer."
          }
        ]
      }
    },
    {
      "name": "ockam_kafka",
      "config": {
        "children": [
          {
            "name": "kafka",
            "children": [
              {
                "name": "seed_brokers",
                "description": "A list of broker addresses to connect to (optional). List items that contain commas are expanded into multiple addresses."
              },
              {
                "name": "tls",
                "description": "Override system defaults with custom TLS settings.",
                "children": [
                  {
                    "name": "skip_cert_verify",
                    "description": "Whether to skip server-side certificate verification."
                  },
                  {
                    "name": "enable_renegotiation",
                    "description": "Whether to allow the remote server to request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`."
                  },
                  {
                    "name": "root_cas",
                    "description": "Specify a root certificate authority to use (optional). This is a string that represents a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
                  },
                  {
                    "name": "root_cas_file",
                    "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
                  },
                  {
                    "name": "client_certs",
                    "description": "A list of client certificates to use. For each certificate, specify either the fields `cert` and `key` or `cert_file` and `key_file`."
                  }
                ]
              },
              {
                "name": "topics",
                "description": "A list of topics to consume from (required). You can list multiple comma-separated topics in a single element.\n\nIf you specify a `consumer_group`, partitions are automatically distributed across consumers of a topic. Otherwise, all partitions are consumed.\n\nAlternatively, add a colon after the topic name to set the explicit partitions to consume. For example, `foo:0` consumes the partition `0` of the topic `foo`. This syntax also supports ranges. For example, `foo:0-10` consumes all partitions from `0` through to `10` inclusively.\n\nFinally, add another colon after the partition to set an explicit offset to consume from. For example, `foo:0:10` consumes the partition `0` of the topic `foo` starting from the offset `10`. If the offset is not present (or remains unspecified) then the field `start_offset` determines which offset to start from."
              },
              {
                "name": "regexp_topics",
                "description": "Whether listed topics are interpreted as regular expression patterns for matching multiple topics. Set this value to `false` when explicit partitions are specified for topics."
              },
              {
                "name": "rack_id",
                "description": "A rack identifier for this client."
              },
              {
                "name": "instance_id",
                "description": "When you specify a <<consumer_group,`consumer_group`>>, assign a unique value to `instance_id` to define the group\u2019s static membership, which can prevent unnecessary rebalances during reconnections. \n\nWhen you assign an instance ID, the client does not automatically leave the consumer group when it disconnects. To remove the client, you must use an external admin command on behalf of the instance ID."
              },
              {
                "name": "rebalance_timeout",
                "description": "When you specify a <<consumer_group,`consumer_group`>>, `rebalance_timeout` sets a time limit for all consumer group members to complete their work and commit offsets after a rebalance has begun. The timeout excludes the time taken to detect a failed or late heartbeat, which indicates a rebalance is required."
              },
              {
                "name": "session_timeout",
                "description": "When you specify a <<consumer_group,`consumer_group`>>, `session_timeout` sets the maximum interval between heartbeats sent by a consumer group member to the broker. If a broker doesn't receive a heartbeat from a group member before the timeout expires, it removes the member from the consumer group and initiates a rebalance.\n\nbroker"
              },
              {
                "name": "heartbeat_interval",
                "description": "When you specify a <<consumer_group,`consumer_group`>>, `heartbeat_interval` sets how frequently a consumer group member should send heartbeats to Apache Kafka. Apache Kafka uses heartbeats to make sure that a group member's session is active. \n\nYou must set `heartbeat_interval` to less than one-third of `session_timeout`.\n\nThis field is equivalent to the Java `heartbeat.interval.ms` setting.\n\nclient"
              },
              {
                "name": "start_offset",
                "description": "Specify the offset from which this input starts or restarts consuming messages. Restarts occur when the `OffsetOutOfRange` error is seen during a fetch."
              },
              {
                "name": "fetch_max_bytes",
                "description": "The maximum size of a message batch (in bytes) that a broker tries to send during a client fetch. If individual records exceed the `fetch_max_bytes` value, brokers will still send them."
              },
              {
                "name": "fetch_max_wait",
                "description": "The maximum period of time a broker can wait for a fetch response to reach the required minimum number of bytes (`fetch_min_bytes`)."
              },
              {
                "name": "fetch_min_bytes",
                "description": "The minimum number of bytes that a broker tries to send during a fetch. This field is equivalent to the Java setting `fetch.min.bytes`."
              },
              {
                "name": "fetch_max_partition_bytes",
                "description": "The maximum number of bytes that are consumed from a single partition in a fetch request. This field is equivalent to the Java setting `fetch.max.partition.bytes`.\n\nIf a single batch is larger than the `fetch_max_partition_bytes` value, the batch is still sent so that the client can make progress."
              },
              {
                "name": "transaction_isolation_level",
                "description": "Defines how transactional messages are handled."
              },
              {
                "name": "consumer_group",
                "description": "Assign a consumer group for the processing of messages (optional). When this value is set:\n\n* Partitions of specified topics are automatically distributed across consumers sharing a consumer group. \n* Partition offsets are automatically committed and resumed under this name.\n\nConsumer groups are not supported when explicit partitions to consume from are specified in the `topics` field."
              },
              {
                "name": "checkpoint_limit",
                "description": "The maximum number of messages that are processed in parallel inside the same partition before back pressure is applied. \n\nWhen a message with a specific offset is delivered to the output, the offset is only committed when all messages of previous offsets have also been delivered. This behavior ensures at-least-once delivery guarantees. However, in the event of crashes or server faults, it also increases the likelihood of duplicates. To decrease this risk, reduce the `checkpoint_limit` value."
              },
              {
                "name": "multi_header",
                "description": "Decode headers into lists to allow the handling of multiple values with the same key."
              },
              {
                "name": "batching",
                "description": "Configure a xref:configuration:batching.adoc[batching policy] for individual topic partitions. This allows the input to batch messages together before flushing them for processing. Batching may improve performance and is useful for windowed processing as it preserves the ordering of topic partitions.",
                "children": [
                  {
                    "name": "count",
                    "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
                  },
                  {
                    "name": "byte_size",
                    "description": "The number of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
                  },
                  {
                    "name": "period",
                    "description": "The period of time after which an incomplete batch is flushed regardless of its size."
                  },
                  {
                    "name": "check",
                    "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that returns a boolean value indicating whether a message should end a batch."
                  },
                  {
                    "name": "processors",
                    "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed (optional). All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
                  }
                ]
              },
              {
                "name": "topic_lag_refresh_period",
                "description": "The interval between refresh cycles. During each cycle, this input queries the Redpanda Connect server to calculate the topic lag - the number of produced messages that remain to be read from each topic/partition pair by the specified consumer group."
              }
            ]
          },
          {
            "name": "disable_content_encryption",
            "description": "Disables Kafka message encryption.\n\nIf this value is set to `true`:\n\n* Only message payloads remain unencrypted. This setting does not disable TLS or any other transport-layer encryption that may also be enabled.\n* All other `ockam_kafka` inlets and outlets in a topic must also have their settings set to `true`."
          },
          {
            "name": "enrollment_ticket",
            "description": "The path to a file or a URL where the enrollment ticket value is stored, or an inline hex-encoded value of the enrollment ticket (optional).\n\nYou can generate a new ticket using the https://command.ockam.io/manual/ockam-project-ticket.html[`ockam project ticket` command^]."
          },
          {
            "name": "identity_name",
            "description": "The name of the https://command.ockam.io/manual/ockam-identity.html[Ockam identity] to use. If this value is not provided, the default Ockam identity is automatically generated and used (optional)."
          },
          {
            "name": "allow",
            "description": "Use in conjunction with the `route_to_kafka_outlet` field to specify an access control policy for the Kafka Portal Outlet.\n\nFor example, setting this value to `kafka_us_east` forces the Kafka Outlet to present an Ockam credential, which confirms that the Outlet has the attribute `kafka_us_east=true`."
          },
          {
            "name": "route_to_kafka_outlet",
            "description": "The route to reach the Kafka Portal Outlet of your Ockam portal. For example, `/project/default`."
          },
          {
            "name": "allow_producer",
            "description": "Specify an access control policy for producers.\n\nFor example, setting this value to `orders_producer` forces the producer to present an Ockam credential, which confirms that the producer has the attribute `orders_producer=true`."
          },
          {
            "name": "relay",
            "description": "Make the Ockam node accessible through a relay with the supplied name (optional). \n\nFor example, setting this value to `orders_consumer` would require you to set the `route_to_consumer` on any producer to `/project/default/service/forward_to_orders_consumer/secure/api`."
          },
          {
            "name": "node_address",
            "description": "The TCP listening address of the Ockam node."
          },
          {
            "name": "encrypted_fields",
            "description": "The fields to encrypt in the Kafka messages when the record is a valid JSON map. By default, the whole record is encrypted."
          }
        ]
      }
    },
    {
      "name": "postgres_cdc",
      "config": {
        "children": [
          {
            "name": "dsn",
            "description": "The data source name (DSN) of the PostgreSQL database from which you want to stream updates. Use the format `postgres://[user[:password]@][netloc][:port][/dbname][?param1=value1&...]`. For example, if you wanted to disable SSL in a secure environment, you would add `sslmode=disable` to the connection string."
          },
          {
            "name": "include_transaction_markers",
            "description": "When set to `true`, creates empty messages for `BEGIN` and `COMMIT` operations which start and complete each transaction. Messages with the `operation` metadata field set to `BEGIN` or `COMMIT` have null message payloads."
          },
          {
            "name": "stream_snapshot",
            "description": "When set to `true`, this input streams a snapshot of all existing data in the source database before streaming data changes. To use this setting, all database tables that you want to replicate _must_ have a primary key."
          },
          {
            "name": "snapshot_batch_size",
            "description": "The number of table rows to fetch in each batch when querying the snapshot.\n\nThis option is only available when `stream_snapshot` is set to `true`."
          },
          {
            "name": "tables",
            "description": "A list of database table names to include in the snapshot and logical replication. Specify each table name as a separate item."
          },
          {
            "name": "checkpoint_limit",
            "description": "The maximum number of messages that this input can process at a given time. Increasing this limit enables parallel processing, and batching at the output level. To preserve at-least-once guarantees, any given log sequence number (LSN) is not acknowledged until all messages under that offset are delivered."
          },
          {
            "name": "temporary_slot",
            "description": "If set to `true`, the input creates a temporary replication slot that is automatically dropped when the connection to your source database is closed. You might use this option to:\n\n- Avoid data accumulating in the replication slot when a pipeline is paused or stopped\n- Test the connector\n\nIf the pipeline is restarted, another data snapshot is taken before data updates are streamed."
          },
          {
            "name": "slot_name",
            "description": "The name of the PostgreSQL logical replication slot to use. If not provided, a random name is generated unless you create a replication slot manually before starting replication.\n\nifndef::env-cloud[]\nNOTE: Starting from version 4.48.1, Redpanda Connect no longer adds the prefix `rs_` to the names of replication slots it creates. To continue using an existing replication slot after upgrading, manually add the `rs_` prefix to the slot name.\nendif::[]"
          },
          {
            "name": "pg_standby_timeout",
            "description": "Specify the standby timeout after which an idle connection is refreshed to keep the connection alive."
          },
          {
            "name": "pg_wal_monitor_interval",
            "description": "How often to report changes to the replication lag and write them to Redpanda Connect metrics."
          },
          {
            "name": "max_parallel_snapshot_tables",
            "description": "Specify the maximum number of tables that are processed in parallel when the initial snapshot of the source database is taken."
          },
          {
            "name": "unchanged_toast_value",
            "description": "Specify the value to emit when unchanged <<receive-toast-and-deleted-values, TOAST values>> appear in the message stream. Unchanged values occur for data updates and deletes when `REPLICA IDENTITY` is not set to `FULL`."
          },
          {
            "name": "heartbeat_interval",
            "description": "The interval between heartbeat messages, which Redpanda Connect writes to the WAL using the `pg_logical_emit_message` function. \n\nHeartbeat messages are useful when you subscribe to data changes from tables with low activity, while other tables in the database have higher-frequency updates. Heartbeat messages allow Redpanda Connect to periodically acknowledge new messages even when no data updates occur. Each acknowledgement advances the committed point in the WAL, which ensures that PostgreSQL can safely reclaim older log segments, preventing excessive disk space usage.\n\nSet `heartbeat_interval` to `0s` to disable heartbeats."
          },
          {
            "name": "auto_replay_nacks",
            "description": "Whether to automatically replay rejected messages (negative acknowledgements) at the output level. If the cause of rejections is persistent, leaving this option enabled can result in back pressure.\n\nSet `auto_replay_nacks` to `false` to delete rejected messages. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data is discarded immediately upon consumption and mutation."
          },
          {
            "name": "batching",
            "children": [
              {
                "name": "count",
                "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
              },
              {
                "name": "byte_size",
                "description": "The number of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
              },
              {
                "name": "period",
                "description": "The period of time after which an incomplete batch is flushed regardless of its size."
              },
              {
                "name": "check",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that returns a boolean value indicating whether a message should end a batch."
              },
              {
                "name": "processors",
                "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "redpanda",
      "config": {
        "children": [
          {
            "name": "seed_brokers",
            "description": "A list of broker addresses to connect to in order. Use commas to separate multiple addresses in a single list item."
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "enable_renegotiation",
                "description": "Whether to allow the remote server to request renegotiation. Enable this option if you\u2019re seeing the error message `local error: tls: no renegotiation`."
              },
              {
                "name": "root_cas",
                "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "sasl",
            "description": "Specify one or more methods or mechanisms of SASL authentication. They are tried in order. If the broker supports the first SASL mechanism, all connections use it. If the first mechanism fails, the client picks the first supported mechanism. If the broker does not support any client mechanisms, all connections fail."
          },
          {
            "name": "metadata_max_age",
            "description": "The maximum period of time after which metadata is refreshed."
          },
          {
            "name": "request_timeout_overhead",
            "description": "Grants an additional buffer or overhead to requests that have timeout fields defined. This field is based on the behavior of Apache Kafka's `request.timeout.ms` parameter."
          },
          {
            "name": "conn_idle_timeout",
            "description": "Define how long connections can remain idle before they are closed."
          },
          {
            "name": "topics",
            "description": "A list of topics to consume from. Use commas to separate multiple topics in a single element.\n\nWhen a `consumer_group` is specified, partitions are automatically distributed across consumers of a topic. Otherwise, all partitions are consumed.\n\nAlternatively, you can specify explicit partitions to consume by using a colon after the topic name. For example, `foo:0` would consume the partition `0` of the topic foo. This syntax supports ranges. For example, `foo:0-10` would consume partitions `0` through to `10` inclusive.\n\nIt is also possible to specify an explicit offset to consume from by adding another colon after the partition. For example, `foo:0:10` would consume the partition `0` of the topic `foo` starting from the offset `10`. If the offset is not present (or remains unspecified) then the field `start_offset` determines which offset to start from."
          },
          {
            "name": "regexp_topics",
            "description": "Whether listed topics are interpreted as regular expression patterns for matching multiple topics. When topics are specified with explicit partitions, this field must remain set to `false`."
          },
          {
            "name": "rack_id",
            "description": "A rack specifies where the client is physically located, and changes fetch requests to consume from the closest replica as opposed to the leader replica."
          },
          {
            "name": "instance_id",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, assign a unique value to `instance_id` to define the group\u2019s static membership, which can prevent unnecessary rebalances during reconnections. \n\nWhen you assign an instance ID, the client does not automatically leave the consumer group when it disconnects. To remove the client, you must use an external admin command on behalf of the instance ID."
          },
          {
            "name": "rebalance_timeout",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, `rebalance_timeout` sets a time limit for all consumer group members to complete their work and commit offsets after a rebalance has begun. The timeout excludes the time taken to detect a failed or late heartbeat, which indicates a rebalance is required."
          },
          {
            "name": "session_timeout",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, `session_timeout` sets the maximum interval between heartbeats sent by a consumer group member to the broker. If a broker doesn't receive a heartbeat from a group member before the timeout expires, it removes the member from the consumer group and initiates a rebalance.\n\nbroker"
          },
          {
            "name": "heartbeat_interval",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, `heartbeat_interval` sets how frequently a consumer group member should send heartbeats to Apache Kafka. Apache Kafka uses heartbeats to make sure that a group member's session is active. \n\nYou must set `heartbeat_interval` to less than one-third of `session_timeout`.\n\nThis field is equivalent to the Java `heartbeat.interval.ms` setting.\n\nclient"
          },
          {
            "name": "start_offset",
            "description": "Specify the offset from which this input starts or restarts consuming messages. Restarts occur when the `OffsetOutOfRange` error is seen during a fetch."
          },
          {
            "name": "fetch_max_bytes",
            "description": "The maximum number of bytes that a broker tries to send during a fetch.\n\nIf individual records are larger than the `fetch_max_bytes` value, brokers will still send them."
          },
          {
            "name": "fetch_max_wait",
            "description": "The maximum period of time a broker can wait for a fetch response to reach the required minimum number of bytes (`fetch_min_bytes`)."
          },
          {
            "name": "fetch_min_bytes",
            "description": "The minimum number of bytes that a broker tries to send during a fetch. This field is equivalent to the Java setting `fetch.min.bytes`."
          },
          {
            "name": "fetch_max_partition_bytes",
            "description": "The maximum number of bytes that are consumed from a single partition in a fetch request. This field is equivalent to the Java setting `fetch.max.partition.bytes`.\n\nIf a single batch is larger than the `fetch_max_partition_bytes` value, the batch is still sent so that the client can make progress."
          },
          {
            "name": "transaction_isolation_level",
            "description": "Defines how transactional messages are handled."
          },
          {
            "name": "consumer_group",
            "description": "An optional consumer group. When this value is specified: \n\n- The partitions of any topics, specified in the `topics` field, are automatically distributed across consumers sharing a consumer group\n- Partition offsets are automatically committed and resumed under this name\n\nConsumer groups are not supported when you specify explicit partitions to consume from in the `topics` field."
          },
          {
            "name": "partition_buffer_bytes",
            "description": "A buffer size (in bytes) for each consumed partition, which allows the internal queuing of records before they are flushed. Increasing this value may improve throughput but results in higher memory utilization. \n\nEach buffer can grow slightly beyond this value."
          },
          {
            "name": "topic_lag_refresh_period",
            "description": "The interval between refresh cycles. During each cycle, this input queries the Redpanda Connect server to calculate the topic lag - the number of produced messages that remain to be read from each topic/partition pair by the specified consumer group."
          },
          {
            "name": "auto_replay_nacks",
            "description": "Whether to automatically replay messages that are rejected (nacked) at the output level. If the cause of rejections is persistent, leaving this option enabled can result in back pressure.\n\nSet `auto_replay_nacks` to `false` to delete rejected messages. Disabling auto replays can greatly improve memory efficiency of high throughput streams, as the original shape of the data is discarded immediately upon consumption and mutation."
          }
        ]
      }
    },
    {
      "name": "redpanda_common",
      "config": {
        "children": [
          {
            "name": "topics",
            "description": "A list of topics to consume from. Use commas to separate multiple topics in a single element.\n\nWhen a `consumer_group` is specified, partitions are automatically distributed across consumers of a topic. Otherwise, all partitions are consumed.\n\nAlternatively, you can specify explicit partitions to consume by using a colon after the topic name. For example, `foo:0` would consume the partition `0` of the topic foo. This syntax supports ranges. For example, `foo:0-10` would consume partitions `0` through to `10` inclusive.\n\nIt is also possible to specify an explicit offset to consume from by adding another colon after the partition. For example, `foo:0:10` would consume the partition `0` of the topic `foo` starting from the offset `10`. If the offset is not present (or remains unspecified) then the field `start_offset` determines which offset to start from."
          },
          {
            "name": "regexp_topics",
            "description": "Whether listed topics are interpreted as regular expression patterns for matching multiple topics. When topics are specified with explicit partitions, this field must remain set to `false`."
          },
          {
            "name": "rack_id",
            "description": "A rack specifies where the client is physically located, and changes fetch requests to consume from the closest replica as opposed to the leader replica."
          },
          {
            "name": "instance_id",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, assign a unique value to `instance_id` to define the group\u2019s static membership, which can prevent unnecessary rebalances during reconnections. \n\nWhen you assign an instance ID, the client does not automatically leave the consumer group when it disconnects. To remove the client, you must use an external admin command on behalf of the instance ID."
          },
          {
            "name": "rebalance_timeout",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, `rebalance_timeout` sets a time limit for all consumer group members to complete their work and commit offsets after a rebalance has begun. The timeout excludes the time taken to detect a failed or late heartbeat, which indicates a rebalance is required."
          },
          {
            "name": "session_timeout",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, `session_timeout` sets the maximum interval between heartbeats sent by a consumer group member to the broker. If a broker doesn't receive a heartbeat from a group member before the timeout expires, it removes the member from the consumer group and initiates a rebalance.\n\nbroker"
          },
          {
            "name": "heartbeat_interval",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, `heartbeat_interval` sets how frequently a consumer group member should send heartbeats to Apache Kafka. Apache Kafka uses heartbeats to make sure that a group member's session is active. \n\nYou must set `heartbeat_interval` to less than one-third of `session_timeout`.\n\nThis field is equivalent to the Java `heartbeat.interval.ms` setting.\n\nclient"
          },
          {
            "name": "start_offset",
            "description": "Specify the offset from which this input starts or restarts consuming messages. Restarts occur when the `OffsetOutOfRange` error is seen during a fetch."
          },
          {
            "name": "fetch_max_bytes",
            "description": "The maximum number of bytes that a broker tries to send during a fetch. \n\nIf individual records are larger than the `fetch_max_bytes` value, brokers will still send them."
          },
          {
            "name": "fetch_max_wait",
            "description": "The maximum period of time a broker can wait for a fetch response to reach the required minimum number of bytes (`fetch_min_bytes`)."
          },
          {
            "name": "fetch_min_bytes",
            "description": "The minimum number of bytes that a broker tries to send during a fetch. This field is equivalent to the Java setting `fetch.min.bytes`."
          },
          {
            "name": "fetch_max_partition_bytes",
            "description": "The maximum number of bytes that are consumed from a single partition in a fetch request. This field is equivalent to the Java setting `fetch.max.partition.bytes`.\n\nIf a single batch is larger than the `fetch_max_partition_bytes` value, the batch is still sent so that the client can make progress."
          },
          {
            "name": "transaction_isolation_level",
            "description": "Defines how transactional messages are handled."
          },
          {
            "name": "consumer_group",
            "description": "An optional consumer group. When this value is specified: \n\n- The partitions of any topics, specified in the `topics` field, are automatically distributed across consumers sharing a consumer group\n- Partition offsets are automatically committed and resumed under this name\n\nConsumer groups are not supported when you specify explicit partitions to consume from in the `topics` field."
          },
          {
            "name": "partition_buffer_bytes",
            "description": "A buffer size (in bytes) for each consumed partition, which allows the internal queuing of records before they are flushed. Increasing this value may improve throughput but results in higher memory utilization. \n\nEach buffer can grow slightly beyond this value."
          },
          {
            "name": "topic_lag_refresh_period",
            "description": "The interval between refresh cycles. During each cycle, this input queries the Redpanda Connect server to calculate the topic lag - the number of produced messages that remain to be read from each topic/partition pair by the specified consumer group."
          },
          {
            "name": "auto_replay_nacks",
            "description": "Whether to automatically replay messages that are rejected (nacked) at the output level. If the cause of rejections is persistent, leaving this option enabled can result in back pressure.\n\nSet `auto_replay_nacks` to `false` to delete rejected messages. Disabling auto replays can greatly improve memory efficiency of high throughput streams, as the original shape of the data is discarded immediately upon consumption and mutation."
          }
        ]
      }
    },
    {
      "name": "redpanda_migrator",
      "config": {
        "children": [
          {
            "name": "seed_brokers",
            "description": "A list of broker addresses to connect to in order. Use commas to separate multiple addresses in a single list item."
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "root_cas",
                "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate, specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "sasl",
            "description": "Specify one or more methods of SASL authentication, which are tried in order. If the broker supports the first mechanism, all connections use that mechanism. If the first mechanism fails, the client picks the first supported mechanism. Connections fail if the broker does not support any client mechanisms."
          },
          {
            "name": "topics",
            "description": "A list of topics to consume from. Use commas to separate multiple topics in a single element.\n\nWhen a `consumer_group` is specified, partitions are automatically distributed across consumers of a topic. Otherwise, all partitions are consumed.\n\nAlternatively, you can specify explicit partitions to consume by using a colon after the topic name. For example, `foo:0` would consume the partition `0` of the topic foo. This syntax supports ranges. For example, `foo:0-10` would consume partitions `0` through to `10` inclusive.\n\nIt is also possible to specify an explicit offset to consume from by adding another colon after the partition. For example, `foo:0:10` would consume the partition `0` of the topic `foo` starting from the offset `10`. If the offset is not present (or remains unspecified) then the field `start_offset` determines which offset to start from."
          },
          {
            "name": "regexp_topics",
            "description": "Whether listed topics are interpreted as regular expression patterns for matching multiple topics. When topics are specified with explicit partitions, this field must remain set to `false`."
          },
          {
            "name": "rack_id",
            "description": "A rack identifier for this client."
          },
          {
            "name": "instance_id",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, assign a unique value to `instance_id` to define the group\u2019s static membership, which can prevent unnecessary rebalances during reconnections. \n\nWhen you assign an instance ID, the client does not automatically leave the consumer group when it disconnects. To remove the client, you must use an external admin command on behalf of the instance ID."
          },
          {
            "name": "rebalance_timeout",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, `rebalance_timeout` sets a time limit for all consumer group members to complete their work and commit offsets after a rebalance has begun. The timeout excludes the time taken to detect a failed or late heartbeat, which indicates a rebalance is required."
          },
          {
            "name": "session_timeout",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, `session_timeout` sets the maximum interval between heartbeats sent by a consumer group member to the broker. If a broker doesn't receive a heartbeat from a group member before the timeout expires, it removes the member from the consumer group and initiates a rebalance.\n\nbroker"
          },
          {
            "name": "heartbeat_interval",
            "description": "When you specify a <<consumer_group,`consumer_group`>>, `heartbeat_interval` sets how frequently a consumer group member should send heartbeats to Apache Kafka. Apache Kafka uses heartbeats to make sure that a group member's session is active. \n\nYou must set `heartbeat_interval` to less than one-third of `session_timeout`.\n\nThis field is equivalent to the Java `heartbeat.interval.ms` setting.\n\nclient"
          },
          {
            "name": "start_offset",
            "description": "Specify the offset from which this input starts or restarts consuming messages. Restarts occur when the `OffsetOutOfRange` error is seen during a fetch."
          },
          {
            "name": "fetch_max_bytes",
            "description": "The maximum number of bytes that a broker tries to send during a fetch.\n\nIf individual records are larger than the `fetch_max_bytes` value, brokers still send them."
          },
          {
            "name": "fetch_max_wait",
            "description": "The maximum period of time a broker can wait for a fetch response to reach the required minimum number of bytes (`fetch_min_bytes`)."
          },
          {
            "name": "fetch_min_bytes",
            "description": "The minimum number of bytes that a broker tries to send during a fetch. This field is equivalent to the Java setting `fetch.min.bytes`."
          },
          {
            "name": "fetch_max_partition_bytes",
            "description": "The maximum number of bytes that are consumed from a single partition in a fetch request. This field is equivalent to the Java setting `fetch.max.partition.bytes`.\n\nIf a single batch is larger than the `fetch_max_partition_bytes` value, the batch is still sent so that the client can make progress."
          },
          {
            "name": "transaction_isolation_level",
            "description": "Defines how transactional messages are handled."
          },
          {
            "name": "consumer_group",
            "description": "An optional consumer group. When specified, the partitions of specified topics are automatically distributed across consumers sharing a consumer group, and partition offsets are automatically committed and resumed under this name. Consumer groups are not supported when explicit partitions are specified to consume from in the `topics` field."
          },
          {
            "name": "metadata_max_age",
            "description": "The maximum period of time after which metadata is refreshed. Reducing this value increases the frequency with which newly-created topics are identified."
          },
          {
            "name": "request_timeout_overhead",
            "description": "Grants an additional buffer or overhead to requests that have timeout fields defined. This field is based on the behavior of Apache Kafka's `request.timeout.ms` parameter."
          },
          {
            "name": "conn_idle_timeout",
            "description": "Define how long connections can remain idle before they are closed."
          },
          {
            "name": "partition_buffer_bytes",
            "description": "A buffer size (in bytes) for each consumed partition, which allows the internal queuing of records before they are flushed. Increasing this value may improve throughput but results in higher memory utilization. \n\nEach buffer can grow slightly beyond this value."
          },
          {
            "name": "auto_replay_nacks",
            "description": "Whether to automatically replay messages that are rejected (nacked) at the output level. If the cause of rejections is persistent, leaving this option enabled can result in back pressure.\n\nSet `auto_replay_nacks` to `false` to delete rejected messages. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data is discarded immediately upon consumption and mutation."
          },
          {
            "name": "topic_lag_refresh_period",
            "description": "The interval between refresh cycles. During each cycle, this input queries the Redpanda Connect server to calculate the topic lag - the number of produced messages that remain to be read from each topic/partition pair by the specified consumer group."
          }
        ]
      }
    },
    {
      "name": "redpanda_migrator_bundle",
      "config": {
        "children": [
          {
            "name": "redpanda_migrator",
            "description": "The xref:components:inputs/redpanda_migrator.adoc[`redpanda_migrator` input] configuration."
          },
          {
            "name": "schema_registry",
            "description": "The xref:components:inputs/schema_registry.adoc[`schema_registry` input] configuration."
          }
        ]
      }
    },
    {
      "name": "redpanda_migrator_offsets",
      "config": {
        "children": [
          {
            "name": "seed_brokers",
            "description": "A list of broker addresses to connect to. Use commas to separate multiple addresses in a single list item."
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "root_cas",
                "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate, specify values for either the `cert` and `key`, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "sasl",
            "description": "Specify one or more methods of SASL authentication, which are attempted in order. If the broker supports the first mechanism, all connections use that mechanism. If the first mechanism fails, the client picks the first supported mechanism. Connections fail if the broker does not support any client mechanisms."
          },
          {
            "name": "metadata_max_age",
            "description": "The maximum period of time (in minutes) after which metadata is refreshed."
          },
          {
            "name": "topics",
            "description": "A list of topics to consume from. Use commas to separate multiple topics in a single element.\n\nWhen a `consumer_group` is specified, partitions are automatically distributed across consumers of a topic. Otherwise, all partitions are consumed.\n\nAlternatively, you can specify explicit partitions to consume by using a colon after the topic name. For example, `foo:0` would consume the partition `0` of the topic foo. This syntax supports ranges. For example, `foo:0-10` would consume partitions `0` through to `10` inclusive.\n\nIt is also possible to specify an explicit offset to consume from by adding another colon after the partition. For example, `foo:0:10` would consume the partition `0` of the topic `foo` starting from the offset `10`. If the offset is not present (or remains unspecified) then the field `start_from_oldest` determines which offset to start from."
          },
          {
            "name": "regexp_topics",
            "description": "Whether listed topics are interpreted as regular expression patterns for matching multiple topics. When topics are specified with explicit partitions, this field must remain set to `false`."
          },
          {
            "name": "rack_id",
            "description": "A rack specifies where the client is physically located, and changes fetch requests to consume from the closest replica as opposed to the leader replica."
          },
          {
            "name": "consumer_group",
            "description": "An optional consumer group. When this value is specified: \n\n- The partitions of any topics, specified in the `topics` field, are automatically distributed across consumers sharing a consumer group\n- Partition offsets are automatically committed and resumed under this name\n\nConsumer groups are not supported when you specify explicit partitions to consume from in the `topics` field."
          },
          {
            "name": "partition_buffer_bytes",
            "description": "A buffer size (in bytes) for each consumed partition, which allows the internal queuing of records before they are flushed. Increasing this value may improve throughput but results in higher memory utilization. \n\nEach buffer can grow slightly beyond this value."
          },
          {
            "name": "topic_lag_refresh_period",
            "description": "The interval between refresh cycles. During each cycle, this input queries the Redpanda Connect server to calculate the topic lag - the number of produced messages that remain to be read from each topic/partition pair by the specified consumer group."
          },
          {
            "name": "auto_replay_nacks",
            "description": "Whether to automatically replay messages that are rejected (nacked) at the output level. If the cause of rejections is persistent, leaving this option enabled can result in back pressure.\n\nSet `auto_replay_nacks` to `false` to delete rejected messages. Disabling auto replays can greatly improve memory efficiency of high throughput streams, as the original shape of the data is discarded immediately upon consumption and mutation."
          }
        ]
      }
    },
    {
      "name": "schema_registry",
      "config": {
        "children": [
          {
            "name": "subject_filter",
            "description": "Include only subjects which match the regular expression filter, or leave this field value blank to select all subjects."
          },
          {
            "name": "fetch_in_order",
            "description": "Indicate whether to fetch all schemas from the schema registry service and sort them by ID. Set this value to `true` if you use schemas that refer to other schemas (schema references)."
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "root_cas",
                "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "auto_replay_nacks",
            "description": "Whether to automatically replay messages that are rejected (nacked) at the output level. If the cause of rejections is persistent, leaving this option enabled can result in back pressure. \n\nSet `auto_replay_nacks` to `false` to delete rejected messages. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data is discarded immediately upon consumption and mutation."
          },
          {
            "name": "oauth",
            "description": "Configure OAuth version 1.0 to give this component authorized access to your schema registry.",
            "children": [
              {
                "name": "consumer_key",
                "description": "The value used to identify this component or client to your schema registry."
              },
              {
                "name": "consumer_secret",
                "description": "The secret used to establish ownership of the consumer key."
              },
              {
                "name": "access_token",
                "description": "The value this component can use to gain access to the data in the schema registry."
              },
              {
                "name": "access_token_secret",
                "description": "The secret that establishes ownership of the `oauth.access_token`."
              }
            ]
          },
          {
            "name": "basic_auth",
            "description": "Configure basic authentication for requests from this component to your schema registry.",
            "children": [
              {
                "name": "username",
                "description": "The username of the account credentials to authenticate as."
              },
              {
                "name": "password",
                "description": "The password of the account credentials to authenticate with."
              }
            ]
          },
          {
            "name": "jwt",
            "description": "BETA: Configure JSON Web Token (JWT) authentication for the secure transmission of data from your schema registry to this component.",
            "children": [
              {
                "name": "private_key_file",
                "description": "A PEM-encoded file containing a private key that is formatted using either PKCS1 or PKCS8 standards."
              },
              {
                "name": "signing_method",
                "description": "The method used to sign the token, such as RS256, RS384, RS512 or EdDSA."
              },
              {
                "name": "claims",
                "description": "Values used to pass the identity of the authenticated entity to the service provider. In this case, between this component and the schema registry."
              },
              {
                "name": "headers",
                "description": "The key/value pairs that identify the type of token and signing algorithm."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "sftp",
      "config": {
        "children": [
          {
            "name": "address",
            "description": "The address (hostname or IP address) of the SFTP server to connect to."
          },
          {
            "name": "credentials",
            "description": "The credentials required to log in to the SFTP server. This can include a username and password, or a private key for secure access.",
            "children": [
              {
                "name": "username",
                "description": "The username required to authenticate with the SFTP server."
              },
              {
                "name": "password",
                "description": "The password for the username used to authenticate with the SFTP server."
              },
              {
                "name": "private_key_file",
                "description": "The path to a private key file used to authenticate with the SFTP server. You can also provide a private key using the <<credentials-private_key,`private_key`>> field."
              },
              {
                "name": "private_key",
                "description": "The private key used to authenticate with the SFTP server. This field provides an alternative to the <<credentials-private_key_file, `private_key_file`>>."
              },
              {
                "name": "private_key_pass",
                "description": "A passphrase for the private key."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "slack",
      "config": {
        "children": [
          {
            "name": "app_token",
            "description": "The app-level token to use to authenticate and connect to Slack."
          },
          {
            "name": "bot_token",
            "description": "Your Slack bot user's OAuth token, which must have the https://api.slack.com/scopes/connections:write[`connections.write` scope^] to access your Slack app's https://api.slack.com/methods/apps.connections.open[Socket Mode WebSocket URL^]."
          },
          {
            "name": "auto_replay_nacks",
            "description": "Whether to automatically replay messages that are rejected (nacked) at the output level. If the cause of rejections is persistent, leaving this option enabled can result in back pressure.\n\nSet `auto_replay_nacks` to `false` to delete rejected messages. Disabling auto replays can greatly improve memory efficiency of high throughput streams, as the original shape of the data is discarded immediately upon consumption and mutation."
          }
        ]
      }
    },
    {
      "name": "slack_users",
      "config": {
        "children": [
          {
            "name": "bot_token",
            "description": "Your https://api.slack.com/concepts/token-types[Slack bot user's OAuth token^], which must have the https://api.slack.com/scopes/users:read[`users.read` scope^] to access your Slack organization."
          },
          {
            "name": "team_id",
            "description": "The encoded ID of a Slack team by which to filter the list of returned users, which you can get from the https://api.slack.com/methods/team.info[`team.info` Slack API method^]. If `team_id` is left empty, users from all teams within the organization are returned."
          },
          {
            "name": "auto_replay_nacks",
            "description": "Whether to automatically replay messages that are rejected (nacked) at the output level. If the cause of rejections is persistent, leaving this option enabled can result in back pressure.\n\nSet `auto_replay_nacks` to `false` to delete rejected messages. Disabling auto replays can greatly improve memory efficiency of high throughput streams, as the original shape of the data is discarded immediately upon consumption and mutation."
          }
        ]
      }
    },
    {
      "name": "socket_server",
      "config": {
        "children": [
          {
            "name": "tls",
            "children": [
              {
                "name": "client_auth",
                "description": "Specifies how client authentication is handled when using TLS."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "spicedb_watch",
      "config": {
        "children": [
          {
            "name": "endpoint",
            "description": "The endpoint of your SpiceDB instance."
          },
          {
            "name": "bearer_token",
            "description": "The SpiceDB bearer token to use to authenticate with your SpiceDB instance."
          },
          {
            "name": "max_receive_message_bytes",
            "description": "The maximum message size (in bytes) this input can receive. If a message exceeds this limit, an `rpc error` is written to the Redpanda Connect logs."
          },
          {
            "name": "cache",
            "description": "The <<configure-a-cache,cache resource>> that you must configure to store the ZedToken (ID) of the last message processed. The ZedToken is stored in the cache within the `ACK` function of the message. This means that a ZedToken is only stored when a message is successfully routed through all processors and outputs in the data pipeline."
          },
          {
            "name": "cache_key",
            "description": "The key identifier to use when storing the ZedToken (ID) of the last message received."
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "enable_renegotiation",
                "description": "Whether to allow the remote server to request renegotiation. Enable this option if you're seeing the error message `local error: \ntls: no renegotiation`."
              },
              {
                "name": "root_cas",
                "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent trusted root certificate, through possible intermediate signing certificates, to the host certificate.certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "sql_raw",
      "config": {
        "children": [
          {
            "name": "dsn",
            "description": "A Data Source Name to identify the target database."
          },
          {
            "name": "query",
            "description": "The query to execute. The style of placeholder to use depends on the driver, some drivers require question marks (`?`) whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2` and so on). The style to use is outlined in this table:\n\ninclude::components:partial$query_table.adoc[]"
          },
          {
            "name": "args_mapping",
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] that includes the same number of values in an array as the placeholder arguments in the <<query, `query`>> field."
          }
        ]
      }
    },
    {
      "name": "sql_select",
      "config": {
        "children": [
          {
            "name": "dsn",
            "description": "A Data Source Name to identify the target database."
          }
        ]
      }
    },
    {
      "name": "timeplus",
      "config": {
        "children": [
          {
            "name": "query",
            "description": "The query to execute on Timeplus Enterprise (Cloud or Self-Hosted) or `timeplusd`."
          },
          {
            "name": "url",
            "description": "The URL of your Timeplus instance, which should always include the schema and host."
          },
          {
            "name": "workspace",
            "description": "The ID of the workspace you want to read messages from. This field is required if you are connecting to Timeplus Enterprise (Cloud or Self-Hosted) using HTTP."
          },
          {
            "name": "apikey",
            "description": "The API key for the Timeplus Enterprise REST API. You need to generate the key in the web console of Timeplus Enterprise (Cloud). This field is required if you are reading messages from Timeplus Enterprise (Cloud)."
          },
          {
            "name": "username",
            "description": "The username for the Timeplus application server. This field is required if you are reading messages from Timeplus Enterprise (Self-Hosted) or `timeplusd`."
          },
          {
            "name": "password",
            "description": "The password for the Timeplus application server. This field is required if you are reading messages from Timeplus Enterprise (Self-Hosted) or `timeplusd`."
          }
        ]
      }
    },
    {
      "name": "websocket",
      "config": {
        "children": [
          {
            "name": "oauth",
            "description": "Allows you to specify open authentication using OAuth version 1."
          },
          {
            "name": "jwt",
            "description": "BETA: Allows you to specify JSON Web Token (JWT) authentication.",
            "children": [
              {
                "name": "private_key_file",
                "description": "A file with the PEM encoded using PKCS1 or PKCS8 as private key."
              },
              {
                "name": "signing_method",
                "description": "A method used to sign the token, such as RS256, RS384, RS512 or EdDSA."
              },
              {
                "name": "headers",
                "description": "Add key/value headers to the JWT (optional)."
              }
            ]
          }
        ]
      }
    }
  ],
  "outputs": [
    {
      "name": "amqp_0_9",
      "config": {
        "children": [
          {
            "name": "urls",
            "type": "array",
            "description": "A list of URLs to connect to. This input attempts to connect to each URL in the list, in order, until a successful connection is established. It then continues to use that URL until the connection is closed.\n\nIf an item in the list contains commas, it is split into multiple URLs."
          },
          {
            "name": "exchange",
            "description": "The AMQP exchange to publish messages to. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "exchange_declare",
            "description": "Passively declares the <<exchange, target exchange>> to check whether an exchange with the specified name exists and is configured correctly. If the exchange exists, then the passive declaration verifies that fields specified in this object match its properties. If the target exchange does not exist, this output creates it.",
            "children": [
              {
                "name": "enabled",
                "description": "Whether to enable exchange declaration."
              },
              {
                "name": "type",
                "description": "The type of the exchange, which determines how messages are routed to queues.\n\nNOTE: Dots (`.`) in message keys are only enforced in routing keys and message types for `topic` exchanges."
              },
              {
                "name": "durable",
                "description": "Whether the declared exchange is durable."
              },
              {
                "name": "arguments",
                "description": "Arguments for server-specific implementations of the exchange (optional). You can use arguments to configure additional parameters for exchange types that require them."
              }
            ]
          },
          {
            "name": "key",
            "description": "The binding key to set for each message. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "type",
            "description": "A custom message type to set for each message. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "content_type",
            "description": "The MIME type of each message. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "content_encoding",
            "description": "The content encoding attribute of each message. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "correlation_id",
            "description": "Set a unique correlation ID for each message using a dynamic interpolated expression to help match messages to responses. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "reply_to",
            "description": "Set the name of the queue to which responses are sent using a dynamic interpolated expression. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "expiration",
            "description": "Set the TTL of each message in milliseconds. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "message_id",
            "description": "Set a message ID for each message using a dynamic interpolated expression. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "user_id",
            "description": "Set the user ID to the name of the publisher. If this property is set by a publisher, its value must match the name of the user that opened the connection. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "app_id",
            "description": "Set an application ID for each message using a dynamic interpolated expression. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "metadata",
            "description": "Specify which (if any) metadata values are added to messages as headers.",
            "children": [
              {
                "name": "exclude_prefixes",
                "type": "array",
                "description": "Provide a list of explicit metadata key prefixes to exclude when adding metadata to sent messages."
              }
            ]
          },
          {
            "name": "priority",
            "description": "Set the priority of each message using a dynamic interpolated expression. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of messages to have in flight at a given time. Increase this number to improve throughput."
          },
          {
            "name": "persistent",
            "description": "Whether to store delivered messages on disk. By default, message delivery is transient."
          },
          {
            "name": "mandatory",
            "description": "Whether to set the mandatory flag on published messages. When set to `true`, a published message that cannot be routed to any queues is returned to the sender."
          },
          {
            "name": "immediate",
            "description": "Whether to set the immediate flag on published messages. When set to `true`, if there are no active consumers for a queue, the message is dropped instead of waiting."
          },
          {
            "name": "timeout",
            "description": "The maximum period to wait for a message acknowledgment before abandoning it and attempting a resend. If this value is not set, the system waits indefinitely."
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "root_cas",
                "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, that contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate, specify values for either the `cert` and `key` fields, or the `cert_file` and `key_file` fields."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "amqp_1",
      "config": {
        "children": [
          {
            "name": "content_type",
            "description": "The content type of the message body.\n\nSet this field value to `string` to transfer each message as an AMQP string. Consider using the `string` option if you want to write UTF-8 string messages, such as JSON messages, to your data destination."
          }
        ]
      }
    },
    {
      "name": "aws_dynamodb",
      "config": {
        "children": [
          {
            "name": "string_columns",
            "description": "A map of column keys to string values to store.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "backoff",
            "children": [
              {
                "name": "initial_interval",
                "description": "The initial period to wait between retry attempts. The retry interval increases for each failed attempt, up to the `backoff.max_interval` value."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "aws_kinesis",
      "config": {
        "children": [
          {
            "name": "partition_key",
            "description": "A required key for partitioning messages.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "hash_key",
            "description": "A optional hash key for partitioning messages.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "backoff",
            "children": [
              {
                "name": "initial_interval",
                "description": "The initial period to wait between retry attempts. The retry interval increases for each failed attempt, up to the `backoff.max_interval` value."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "aws_kinesis_firehose",
      "config": {
        "children": [
          {
            "name": "backoff",
            "children": [
              {
                "name": "initial_interval",
                "description": "The initial period to wait between retry attempts. The retry interval increases for each failed attempt, up to the `backoff.max_interval` value."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "aws_s3",
      "config": {
        "children": [
          {
            "name": "path",
            "description": "The path of each message to upload. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "tags",
            "description": "Key/value pairs to store with the object as tags.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "content_type",
            "description": "The content type to set for each object.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "content_encoding",
            "description": "An optional content encoding to set for each object.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "cache_control",
            "description": "The cache control to set for each object.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "content_disposition",
            "description": "The content disposition to set for each object.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "content_language",
            "description": "The content language to set for each object. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "content_md5",
            "description": "The https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html#checking-object-integrity-md5[content MD5^] to set for each object. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "website_redirect_location",
            "description": "The website redirect location to set for each object.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "storage_class",
            "description": "The storage class to set for each object.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "kms_key_id",
            "description": "An optional server-side encryption key."
          },
          {
            "name": "checksum_algorithm",
            "description": "The algorithm used to validate each object during its upload to the Amazon S3 bucket."
          },
          {
            "name": "server_side_encryption",
            "description": "An optional server-side encryption algorithm."
          }
        ]
      }
    },
    {
      "name": "aws_sns",
      "config": {
        "children": [
          {
            "name": "message_group_id",
            "description": "An optional group ID to set for messages.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "message_deduplication_id",
            "description": "An optional deduplication ID to set for messages.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "aws_sqs",
      "config": {
        "children": [
          {
            "name": "url",
            "description": "The URL of the target SQS queue. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "message_group_id",
            "description": "An optional group ID to set for messages.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "message_deduplication_id",
            "description": "An optional deduplication ID to set for messages.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "delay_seconds",
            "description": "An optional delay time in seconds for message. Value between 0 and 900\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "max_records_per_request",
            "description": "The maximum number of records delivered in a single SQS request. Enter only values from `0` to `10`."
          },
          {
            "name": "backoff",
            "children": [
              {
                "name": "initial_interval",
                "description": "The initial period to wait between retry attempts. The retry interval increases for each failed attempt, up to the `backoff.max_interval` value."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "azure_blob_storage",
      "config": {
        "children": [
          {
            "name": "container",
            "description": "The container for uploading the messages to.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "path",
            "description": "The path of each message to upload. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "blob_type",
            "description": "Block and Append blobs are comprized of blocks, and each blob can support up to 50,000 blocks. The default value is `+\"`BLOCK`\"+`.`\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "public_access_level",
            "description": "The container's public access level. The default value is `PRIVATE`.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "azure_cosmosdb",
      "config": {
        "children": [
          {
            "name": "patch_condition",
            "description": "Patch operation condition.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "item_id",
            "description": "ID of item to replace or delete. Only used by the Replace and Delete operations\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "azure_data_lake_gen2",
      "config": {
        "children": [
          {
            "name": "storage_account",
            "description": "The storage account to access. This field is ignored when the `storage_connection_string` field is populated."
          },
          {
            "name": "storage_access_key",
            "description": "The access key for the storage account. Use this field along with `storage_account` for authentication. This field is ignored when the `storage_connection_string` field is populated."
          },
          {
            "name": "storage_connection_string",
            "description": "The connection string for the storage account. You must enter a value for this field if no other authentication method is specified.\n\nNOTE: If the `storage_connection_string` field does not contain the `AccountName` parameter value, specify it in the\n`storage_account` field."
          },
          {
            "name": "storage_sas_token",
            "description": "The SAS token for the storage account. Use this field along with `storage_account` for authentication. This field is ignored when either the `storage_connection_string` or `storage_access_key` fields are populated."
          },
          {
            "name": "filesystem",
            "description": "The name of the data lake storage file system you want to upload messages to. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "path",
            "description": "The path (file name) of each message to upload to the data lake storage file system. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of messages to have in flight at a given time. Increase this number to improve throughput until performance plateaus."
          }
        ]
      }
    },
    {
      "name": "azure_queue_storage",
      "config": {
        "children": [
          {
            "name": "queue_name",
            "description": "The name of the target Queue Storage queue.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "ttl",
            "description": "The TTL of each individual message as a duration string. Defaults to 0, meaning no retention period is set\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "azure_table_storage",
      "config": {
        "children": [
          {
            "name": "table_name",
            "description": "The table to store messages into.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "partition_key",
            "description": "The partition key.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "row_key",
            "description": "The row key.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "properties",
            "description": "A map of properties to store into the table.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "transaction_type",
            "description": "Type of transaction operation.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "cache",
      "config": {
        "children": [
          {
            "name": "key",
            "description": "The key to store messages by, function interpolation should be used in order to derive a unique key for each message.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "ttl",
            "description": "The TTL of each individual item as a duration string. After this period an item will be eligible for removal during the next compaction. Not all caches support per-key TTLs, and those that do not will fall back to their generally configured TTL setting.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "cassandra",
      "config": {
        "children": [
          {
            "name": "backoff",
            "children": [
              {
                "name": "initial_interval",
                "description": "The initial period to wait between retry attempts. The retry interval increases for each failed attempt, up to the `backoff.max_interval` value."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "couchbase",
      "config": {
        "children": [
          {
            "name": "url",
            "description": "The Couchbase connection string."
          },
          {
            "name": "username",
            "description": "A username to authenticate with the Couchbase cluster."
          },
          {
            "name": "password",
            "description": "A password to authenticate with the Couchbase cluster."
          },
          {
            "name": "bucket",
            "description": "The name of the Couchbase bucket you want the output to access."
          },
          {
            "name": "collection",
            "description": "The name of the specific collection you want the output to write to."
          },
          {
            "name": "transcoder",
            "description": "Choose from the following Couchbase transcoders to convert the messages' data format before they are written to Couchbase."
          },
          {
            "name": "timeout",
            "description": "Operation timeout if this output cannot connect to the Couchbase cluster."
          },
          {
            "name": "id",
            "description": "The document ID to use.\n\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "content",
            "description": "The document content to update. When inserting, replacing, or upserting documents, you must set a `content` value."
          },
          {
            "name": "operation",
            "description": "The Couchbase operation to perform."
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of messages to have in flight at a given time. Increase this value to improve throughput."
          },
          {
            "name": "batching",
            "description": "Configure a xref:configuration:batching.adoc[batching policy].",
            "children": [
              {
                "name": "count",
                "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
              },
              {
                "name": "byte_size",
                "description": "The amount of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
              },
              {
                "name": "period",
                "description": "The period of time after which an incomplete batch is flushed regardless of its size."
              },
              {
                "name": "check",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that returns a boolean value indicating whether a message should end a batch."
              },
              {
                "name": "processors",
                "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "cypher",
      "config": {
        "children": [
          {
            "name": "uri",
            "description": "The connection URI for your graphing database. For more information, see https://neo4j.com/docs/go-manual/current/connect-advanced/[Neo4j's documentation^]."
          },
          {
            "name": "database_name",
            "description": "Set the target database against which expressions are evaluated."
          },
          {
            "name": "args_mapping",
            "description": "Mappings from incoming messages to the data, which are passed into the cypher expression as parameters. All mappings must be objects. By default, this field processes the entire payload."
          },
          {
            "name": "basic_auth",
            "description": "Configure basic authentication for requests to your graphing database.",
            "children": [
              {
                "name": "username",
                "description": "The username of the account credentials to authenticate as."
              },
              {
                "name": "password",
                "description": "The password of the account credentials to authenticate with."
              },
              {
                "name": "realm",
                "description": "The realm or process for authentication challenges."
              }
            ]
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "enable_renegotiation",
                "description": "Whether to allow the remote server to request renegotiation. Enable this option if you're seeing the error message \n`local error: tls: no renegotiation`."
              },
              {
                "name": "root_cas",
                "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent trusted root certificate, through possible intermediate signing certificates, to the host certificate.certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "batching",
            "description": "Configure a xref:configuration:batching.adoc[batching policy].",
            "children": [
              {
                "name": "count",
                "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
              },
              {
                "name": "byte_size",
                "description": "The amount of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
              },
              {
                "name": "period",
                "description": "The period of time after which an incomplete batch is flushed regardless of its size."
              },
              {
                "name": "check",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that returns a boolean value indicating whether a message should end a batch."
              },
              {
                "name": "processors",
                "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
              }
            ]
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of message batches to have in flight at a given time. Increase this value to improve throughput."
          }
        ]
      }
    },
    {
      "name": "elasticsearch",
      "config": {
        "children": [
          {
            "name": "index",
            "description": "The index to place messages.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "action",
            "description": "The action to take on the document. This field must resolve to one of the following action types: `create`, `index`, `update`, `upsert` or `delete`.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "pipeline",
            "description": "An optional pipeline id to preprocess incoming documents.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "id",
            "description": "The ID for indexed messages. Use interpolation to create a unique ID for each message.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "type",
            "description": "The document mapping type. This field is required for versions of elasticsearch earlier than 6.0.0, but are invalid for versions 7.0.0 or later.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "routing",
            "description": "The routing key to use for the document.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "retry_on_conflict",
            "description": "The number of times to retry an update operation when a version conflict occurs."
          },
          {
            "name": "backoff",
            "children": [
              {
                "name": "initial_interval",
                "description": "The initial period to wait between retry attempts. The retry interval increases for each failed attempt, up to the `backoff.max_interval` value."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "elasticsearch_v8",
      "config": {
        "children": [
          {
            "name": "urls",
            "type": "array",
            "description": "A list of URLs to connect to. This output attempts to connect to each URL in the list, in order, until a successful connection is established. If an item in the list contains commas, it is split into multiple URLs."
          },
          {
            "name": "index",
            "description": "The Elasticsearch index where messages are published. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "action",
            "description": "The action to perform on each document. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].\n\nFor more information on how the `update` action works, see <<example-pipelines, Example pipelines>>."
          },
          {
            "name": "id",
            "description": "Define the ID for indexed messages. Use xref:configuration:interpolation.adoc#bloblang-queries[function interpolations] to dynamically create a unique ID for each message."
          },
          {
            "name": "pipeline",
            "description": "Specify the ID of a pipeline to preprocess incoming documents before they are published (optional). This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "routing",
            "description": "The routing key to use for the document. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "retry_on_conflict",
            "description": "The number of times to retry an update operation when a version conflict occurs."
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "enabled",
                "description": "Enable custom TLS settings. By default, custom settings are disabled."
              },
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "root_cas",
                "description": "Specify a root certificate authority to use (optional). This is a string, representing a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate, specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "basic_auth",
            "children": [
              {
                "name": "username",
                "description": "The username to use for authentication."
              }
            ]
          },
          {
            "name": "batching",
            "children": [
              {
                "name": "count",
                "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
              },
              {
                "name": "byte_size",
                "description": "The number of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
              },
              {
                "name": "period",
                "description": "The period after which an incomplete batch is flushed regardless of its size."
              },
              {
                "name": "processors",
                "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "file",
      "config": {
        "children": [
          {
            "name": "path",
            "description": "The file to write to, if the file does not yet exist it will be created.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "gcp_bigquery",
      "config": {
        "children": [
          {
            "name": "project",
            "description": "Specify the project ID of the dataset to insert data into. If not set, the project ID is inferred from the project linked to the service account or read from the `GOOGLE_CLOUD_PROJECT` environment variable."
          },
          {
            "name": "job_project",
            "description": "Specify the project ID in which jobs are executed. If not set, the `project` value is used."
          },
          {
            "name": "table",
            "description": "The table to insert messages into."
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of message batches to have in flight at a given time. Increase this value to improve throughput."
          },
          {
            "name": "create_disposition",
            "description": "Specifies the circumstances under which a destination table is created. \n\n* Use `CREATE_IF_NEEDED` to create the destination table if it does not already exist. Tables are created atomically on successful completion of a job. \n* Use `CREATE_NEVER` if the destination table must already exist."
          },
          {
            "name": "ignore_unknown_values",
            "description": "Set this value to `true` to ignore values that do not match the schema:\n\n* For the `CSV` format, extra values at the end of a line are ignored. \n* For the `NEWLINE_DELIMITED_JSON` format, values that do not match any column name are ignored. \n\nBy default, this value is set to `false`, and records containing unknown values are treated as bad records. Use the `max_bad_records` field to customize how bad records are handled."
          },
          {
            "name": "max_bad_records",
            "description": "The maximum number of bad records to ignore when reading data and <<ignore_unknown_values, `ignore_unknown_values`>> is set to `true`."
          },
          {
            "name": "auto_detect",
            "description": "Whether this component automatically infers the options and schema for `CSV` and `NEWLINE_DELIMITED_JSON` sources. \n\nIf this value is set to `false` and the destination table doesn't exist, the output throws an insertion error as it is unable to insert data. \n\nCAUTION: This field delegates schema detection to the GCP BigQuery service. For the `CSV` format, values like `no` may be treated as booleans."
          },
          {
            "name": "credentials_json",
            "description": "Sets the  https://developers.google.com/workspace/guides/create-credentials#create_credentials_for_a_service_account[Google Service Account Credentials JSON^] (optional)."
          },
          {
            "name": "csv",
            "description": "Specify how CSV data is interpreted.",
            "children": [
              {
                "name": "header",
                "description": "A list of values to use as the header for each batch of messages. If not specified, the first line of each message is used as the header."
              },
              {
                "name": "field_delimiter",
                "description": "The separator for fields in a CSV file. The output uses this value when reading or exporting data."
              },
              {
                "name": "allow_jagged_rows",
                "description": "Set to `true` to treat optional missing trailing columns as nulls in CSV data."
              },
              {
                "name": "allow_quoted_newlines",
                "description": "Whether quoted data sections containing new lines are allowed when reading CSV data."
              },
              {
                "name": "encoding",
                "description": "The character encoding of CSV data."
              },
              {
                "name": "skip_leading_rows",
                "description": "The number of rows at the top of a CSV file that BigQuery will skip when reading data. The default value is `1`, which allows Redpanda Connect to add the specified header in the first line of each batch sent to BigQuery."
              }
            ]
          },
          {
            "name": "batching",
            "description": "Configure a xref:configuration:batching.adoc[batching policy].",
            "children": [
              {
                "name": "count",
                "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
              },
              {
                "name": "byte_size",
                "description": "The amount of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
              },
              {
                "name": "period",
                "description": "The period of time after which an incomplete batch is flushed regardless of its size."
              },
              {
                "name": "check",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that returns a boolean value indicating whether a message should end a batch."
              },
              {
                "name": "processors",
                "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "gcp_cloud_storage",
      "config": {
        "children": [
          {
            "name": "path",
            "description": "The path of each message to upload. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "content_type",
            "description": "The content type to set for each object.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "content_encoding",
            "description": "An optional content encoding to set for each object.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "credentials_json",
            "description": "Optional field to set https://developers.google.com/workspace/guides/create-credentials#create_credentials_for_a_service_account[Google Service Account Credentials JSON^]."
          }
        ]
      }
    },
    {
      "name": "gcp_pubsub",
      "config": {
        "children": [
          {
            "name": "credentials_json",
            "description": "Optional field to set https://developers.google.com/workspace/guides/create-credentials#create_credentials_for_a_service_account[Google Service Account Credentials JSON^]."
          },
          {
            "name": "topic",
            "description": "The topic to publish to.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "ordering_key",
            "description": "The ordering key to use for publishing messages.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "hdfs",
      "config": {
        "children": [
          {
            "name": "directory",
            "description": "A directory to store message files within. If the directory does not exist it will be created.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "path",
            "description": "The path to upload messages as. Use interpolation functions to generate unique file paths.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "http_client",
      "config": {
        "children": [
          {
            "name": "url",
            "description": "The URL to connect to. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "verb",
            "description": "A verb to connect with."
          },
          {
            "name": "headers",
            "description": "A map of headers to add to the request. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "metadata",
            "description": "Specify matching rules that determine which metadata keys to add to the HTTP request as headers (optional)."
          },
          {
            "name": "dump_request_log_level",
            "description": "EXPERIMENTAL: Set the logging level for the request and response payloads of each HTTP request."
          },
          {
            "name": "oauth",
            "description": "Allows you to specify open authentication using OAuth version 1.",
            "children": [
              {
                "name": "consumer_secret",
                "description": "The secret used to establish ownership of the consumer key."
              },
              {
                "name": "access_token",
                "description": "The value used to gain access to the protected resources on behalf of the user."
              },
              {
                "name": "access_token_secret",
                "description": "The secret that establishes ownership of the `oauth.access_token`."
              }
            ]
          },
          {
            "name": "oauth2",
            "description": "Allows you to specify open authentication using OAuth version 2 and the client credentials token flow.",
            "children": [
              {
                "name": "client_secret",
                "description": "The secret used to establish ownership of the client key."
              },
              {
                "name": "scopes",
                "description": "A list of requested permissions (optional)."
              },
              {
                "name": "endpoint_params",
                "description": "A list of endpoint parameters specified as arrays of strings (optional)."
              }
            ]
          },
          {
            "name": "jwt",
            "description": "BETA: Allows you to specify JSON Web Token (JWT) authentication.",
            "children": [
              {
                "name": "private_key_file",
                "description": "A file with the PEM encoded using PKCS1 or PKCS8 as private key."
              },
              {
                "name": "signing_method",
                "description": "A method used to sign the token, such as RS256, RS384, RS512 or EdDSA."
              },
              {
                "name": "headers",
                "description": "Add key/value headers to the JWT (optional)."
              }
            ]
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "root_cas",
                "description": "Specify a root certificate authority to use (optional). This is a string, representing a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate, specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "extract_headers",
            "description": "Specify which response headers to add to the resulting synchronous response messages as metadata. Header keys are automatically converted to lowercase before matching, so make sure that your patterns target the lowercase versions of the expected header keys.\n\nThis field is only applicable when `propagate_response` is set to `true`.",
            "selfManagedOnly": true
          },
          {
            "name": "rate_limit",
            "description": "A xref:components:rate_limits/about.adoc[rate limit] to throttle requests by (optional)."
          },
          {
            "name": "retry_period",
            "description": "The initial period to wait between failed requests before retrying."
          },
          {
            "name": "backoff_on",
            "description": "A list of status codes that indicate a request failure and trigger retries with an increasing backoff period between attempts."
          },
          {
            "name": "drop_on",
            "description": "A list of status codes that indicate a request failure where the input should not attempt retries. This helps avoid unnecessary retries for requests that are unlikely to succeed.\n\nNOTE: In these cases, the _request_ is dropped, but the _message_ that triggered the request is retained."
          },
          {
            "name": "successful_on",
            "description": "A list of HTTP status codes that should be considered as successful, even if they are not 2XX codes. This is useful for handling cases where non-2XX codes indicate that the request was processed successfully, such as `303 See Other` or `409 Conflict`. \n\nBy default, all 2XX codes are considered successful unless they are specified in `backoff_on` or `drop_on` fields."
          },
          {
            "name": "proxy_url",
            "description": "A HTTP proxy URL (optional)."
          },
          {
            "name": "disable_http2",
            "description": "Whether to disable HTTP/2. By default, HTTP/2 is enabled."
          },
          {
            "name": "batch_as_multipart",
            "description": "When set to `true`, sends all message in a batch as a single request using https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html[RFC1341^]. \n\nWhen set to `false`, sends messages in a batch as individual requests."
          },
          {
            "name": "propagate_response",
            "description": "Whether to xref:guides:sync_responses.adoc[propagate server responses back] to the input.",
            "selfManagedOnly": true
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput."
          },
          {
            "name": "batching",
            "children": [
              {
                "name": "count",
                "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
              },
              {
                "name": "byte_size",
                "description": "The amount of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
              },
              {
                "name": "period",
                "description": "The period after which an incomplete batch is flushed regardless of its size."
              },
              {
                "name": "processors",
                "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
              }
            ]
          },
          {
            "name": "multipart",
            "description": "EXPERIMENTAL: Create explicit multipart HTTP requests by specifying an array of parts to add to a request. Each part consists of content headers and a data field, which can be populated dynamically. \n\nIf populated, this field overrides the <<message-sends, default request creation behavior>>."
          }
        ]
      }
    },
    {
      "name": "kafka",
      "config": {
        "children": [
          {
            "name": "topic",
            "description": "The topic to publish messages to.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "key",
            "description": "The key to publish messages with.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "partition",
            "description": "The manually-specified partition to publish messages to, relevant only when the field `partitioner` is set to `manual`. Must be able to parse as a 32-bit integer.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "backoff",
            "children": [
              {
                "name": "initial_interval",
                "description": "The initial period to wait between retry attempts. The retry interval increases for each failed attempt, up to the `backoff.max_interval` value."
              }
            ]
          },
          {
            "name": "timestamp_ms",
            "description": "Set a timestamp (in milliseconds) for each message (optional). When left empty, the current timestamp is used.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "kafka_franz",
      "config": {
        "children": [
          {
            "name": "seed_brokers",
            "description": "A list of broker addresses to connect to in order. Use commas to separate multiple addresses in a single list item."
          },
          {
            "name": "topic",
            "description": "A topic to write messages to. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "key",
            "description": "An optional key to populate for each message. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "partition",
            "description": "Set a partition for each message (optional). This field is only relevant when the `partitioner` is set to `manual`.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].\n\nYou must provide an interpolation string that is a valid integer."
          },
          {
            "name": "idempotent_write",
            "description": "Enables the idempotent write producer option. This requires the `IDEMPOTENT_WRITE` permission on `CLUSTER`. Disable this option if the `IDEMPOTENT_WRITE` permission is unavailable."
          },
          {
            "name": "metadata",
            "description": "Specify which (if any) metadata values are added to messages as headers."
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of batches to send in parallel at any given time."
          },
          {
            "name": "timeout",
            "description": "The maximum period of time to wait for message sends before abandoning the request and retrying."
          },
          {
            "name": "batching",
            "children": [
              {
                "name": "count",
                "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
              },
              {
                "name": "byte_size",
                "description": "The number of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
              },
              {
                "name": "period",
                "description": "The period after which an incomplete batch is flushed regardless of its size."
              },
              {
                "name": "processors",
                "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
              }
            ]
          },
          {
            "name": "max_message_bytes",
            "description": "The maximum space (in bytes) that an individual message may use. Messages larger than this value are rejected. This field corresponds to Kafka's `max.message.bytes`."
          },
          {
            "name": "broker_write_max_bytes",
            "description": "The maximum number of bytes this output can write to a broker connection in a single write. This field corresponds to Kafka\u2019s `socket.request.max.bytes`."
          },
          {
            "name": "compression",
            "description": "Set an explicit compression type (optional). The default preference is to use `snappy` when the broker supports it. Otherwise, use `none`."
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "root_cas",
                "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "sasl",
            "description": "Specify one or more methods or mechanisms of SASL authentication, which are attempted in order. If the broker supports the first SASL mechanism, all connections use it. If the first mechanism fails, the client picks the first supported mechanism. If the broker does not support any client mechanisms, all connections fail."
          },
          {
            "name": "metadata_max_age",
            "description": "The maximum period of time after which metadata is refreshed."
          },
          {
            "name": "request_timeout_overhead",
            "description": "Grants an additional buffer or overhead to requests that have timeout fields defined. This field is based on the behavior of Apache Kafka's `request.timeout.ms` parameter, but with the option to extend the timeout deadline."
          },
          {
            "name": "conn_idle_timeout",
            "description": "Define how long connections can remain idle before they are closed."
          },
          {
            "name": "timestamp_ms",
            "description": "Set a timestamp (in milliseconds) for each message (optional). When left empty, the current timestamp is used.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "mongodb",
      "config": {
        "children": [
          {
            "name": "username",
            "description": "The username required to connect to the database."
          },
          {
            "name": "password",
            "description": "The password required to connect to the database."
          },
          {
            "name": "collection",
            "description": "The name of the target collection. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "operation",
            "description": "The MongoDB database operation to perform."
          },
          {
            "name": "write_concern",
            "description": "The https://www.mongodb.com/docs/manual/reference/write-concern/[write concern settings^] for the MongoDB connection.",
            "children": [
              {
                "name": "w",
                "description": "The `w` requests acknowledgement, which write operations propagate to the specified number of MongoDB instances."
              },
              {
                "name": "j",
                "description": "The `j` requests acknowledgement from MongoDB, which is created when write operations are written to the journal."
              }
            ]
          },
          {
            "name": "document_map",
            "description": "A Bloblang map that represents a document to store in MongoDB, expressed as https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/[extended JSON in canonical form^]. The `document_map` parameter is required for the following database operations: `insert-one`, `replace-one`, and `update-one`."
          },
          {
            "name": "filter_map",
            "description": "A Bloblang map that represents a filter for a MongoDB command, expressed as https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/[extended JSON in canonical form^]. The `filter_map` parameter is required for all database operations except `insert-one`. \n\nThis output uses `filter_map` to find documents for the specified operation. For example, for a `delete-one` operation, the filter map should include the fields required to locate the document for deletion."
          },
          {
            "name": "hint_map",
            "description": "A Bloblang map that represents a hint or index for a MongoDB command to use, expressed as https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/[extended JSON in canonical form^]. This map is optional, and is used with all operations except `insert-one`. \n\nDefine a `hint_map` to improve performance when finding documents in the MongoDB database."
          },
          {
            "name": "upsert",
            "description": "The `upsert` parameter is optional, and only applies for `update-one` and `replace-one` operations. If the filter specified in `filter_map` matches an existing document, this operation updates or replaces the document, otherwise a new document is created."
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of messages to have in flight at a given time. Increase this number to improve throughput."
          },
          {
            "name": "batching",
            "children": [
              {
                "name": "count",
                "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
              },
              {
                "name": "byte_size",
                "description": "The number of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
              },
              {
                "name": "period",
                "description": "The period after which an incomplete batch is flushed regardless of its size."
              },
              {
                "name": "processors",
                "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "mqtt",
      "config": {
        "children": [
          {
            "name": "urls",
            "type": "array",
            "description": "A list of URLs to connect to. Use the format `scheme://host:port`, where:\n\n* `scheme` is one of the following: `tcp`, `ssl`, `ws`\n* `host` is the IP address or hostname\n* `port` is the port on which the MQTT broker accepts connections\n\nIf an item in the list contains commas, it is expanded into multiple URLs."
          },
          {
            "name": "topic",
            "description": "The topic to publish messages to.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "retained_interpolated",
            "description": "Override the value of `retained` with an interpolable value, this allows it to be dynamically set based on message contents. The value must resolve to either `true` or `false`.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "nats",
      "config": {
        "children": [
          {
            "name": "urls",
            "type": "array",
            "description": "A list of URLs to connect to. If a list item contains commas, it will be expanded into multiple URLs."
          },
          {
            "name": "subject",
            "description": "The subject to publish to.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "headers",
            "description": "Explicit message headers to add to messages.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "auth",
            "children": [
              {
                "name": "nkey",
                "description": "Your NKey seed or private key."
              },
              {
                "name": "user_credentials_file",
                "description": "An optional file containing user credentials which consist of a user JWT and corresponding NKey seed."
              },
              {
                "name": "user_jwt",
                "description": "An optional plain text user JWT to use along with the corresponding user NKey seed."
              },
              {
                "name": "user_nkey_seed",
                "description": "An optional plain text user NKey seed to use along with the corresponding user JWT."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "nats_jetstream",
      "config": {
        "children": [
          {
            "name": "urls",
            "type": "array",
            "description": "A list of URLs to connect to. If a list item contains commas, it will be expanded into multiple URLs."
          },
          {
            "name": "subject",
            "description": "A subject to write to. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "headers",
            "description": "Explicit message headers to add to messages.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "auth",
            "children": [
              {
                "name": "nkey",
                "description": "Your NKey seed or private key."
              },
              {
                "name": "user_credentials_file",
                "description": "An optional file containing user credentials which consist of a user JWT and corresponding NKey seed."
              },
              {
                "name": "user_jwt",
                "description": "An optional plain text user JWT to use along with the corresponding user NKey seed."
              },
              {
                "name": "user_nkey_seed",
                "description": "An optional plain text user NKey seed to use along with the corresponding user JWT."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "nats_kv",
      "config": {
        "children": [
          {
            "name": "urls",
            "type": "array",
            "description": "A list of URLs to connect to. If a list item contains commas, it will be expanded into multiple URLs."
          },
          {
            "name": "key",
            "description": "The key for each message.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "auth",
            "children": [
              {
                "name": "nkey",
                "description": "Your NKey seed or private key."
              },
              {
                "name": "user_credentials_file",
                "description": "An optional file containing user credentials which consist of a user JWT and corresponding NKey seed."
              },
              {
                "name": "user_jwt",
                "description": "An optional plain text user JWT to use along with the corresponding user NKey seed."
              },
              {
                "name": "user_nkey_seed",
                "description": "An optional plain text user NKey seed to use along with the corresponding user JWT."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "nats_stream",
      "config": {
        "children": [
          {
            "name": "urls",
            "type": "array",
            "description": "A list of URLs to connect to. If a list item contains commas, it will be expanded into multiple URLs."
          },
          {
            "name": "auth",
            "children": [
              {
                "name": "nkey",
                "description": "Your NKey seed or private key."
              },
              {
                "name": "user_credentials_file",
                "description": "An optional file containing user credentials which consist of a user JWT and corresponding NKey seed."
              },
              {
                "name": "user_jwt",
                "description": "An optional plain text user JWT to use along with the corresponding user NKey seed."
              },
              {
                "name": "user_nkey_seed",
                "description": "An optional plain text user NKey seed to use along with the corresponding user JWT."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "nsq",
      "config": {
        "children": [
          {
            "name": "topic",
            "description": "The topic to publish to.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "ockam_kafka",
      "config": {
        "children": [
          {
            "name": "kafka",
            "children": [
              {
                "name": "seed_brokers",
                "description": "A list of broker addresses to connect to (optional). List items that contain commas are expanded into multiple addresses."
              },
              {
                "name": "topic",
                "description": "The Kafka topic to write messages to (required). This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
              },
              {
                "name": "key",
                "description": "Populates a key for each message (optional). This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
              },
              {
                "name": "partitioner",
                "description": "Override the default murmur2 hashing partitioner (optional)."
              },
              {
                "name": "partition",
                "description": "Set an explicit partition for each message (optional). To use this field, set the `partitioner` to `manual`. You must provide an interpolation string that is a valid integer. \n\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
              },
              {
                "name": "idempotent_write",
                "description": "Enables the `idempotent_write` producer option. This requires `IDEMPOTENT_WRITE` permission on `CLUSTER`. Disable this option if the correct permission is not available."
              },
              {
                "name": "metadata",
                "description": "Determines which metadata values are added to messages as headers.",
                "children": [
                  {
                    "name": "include_prefixes",
                    "description": "A list of explicit metadata key prefixes to match against."
                  },
                  {
                    "name": "include_patterns",
                    "type": "array",
                    "description": "A list of explicit metadata key regular expression (re2) patterns to match against."
                  }
                ]
              },
              {
                "name": "max_in_flight",
                "description": "The maximum number of message batches to send in parallel at any given time."
              },
              {
                "name": "timeout",
                "description": "The maximum period of time allowed for sending messages before a request is abandoned and a retry attempted."
              },
              {
                "name": "batching",
                "description": "Configure a xref:configuration:batching.adoc[batching policy].",
                "children": [
                  {
                    "name": "count",
                    "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
                  },
                  {
                    "name": "byte_size",
                    "description": "The number of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
                  },
                  {
                    "name": "period",
                    "description": "The period of time after which an incomplete batch is flushed regardless of its size."
                  },
                  {
                    "name": "check",
                    "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that returns a boolean value indicating whether a message should end a batch."
                  },
                  {
                    "name": "processors",
                    "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed (optional). All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
                  }
                ]
              },
              {
                "name": "max_message_bytes",
                "description": "The maximum size of an individual message in bytes. Messages larger than this value are rejected. This field is equivalent to Kafka's `max.message.bytes`."
              },
              {
                "name": "broker_write_max_bytes",
                "description": "The maximum number of bytes this output can write to a broker connection in a single write. This field corresponds to Kafka\u2019s `socket.request.max.bytes`."
              },
              {
                "name": "compression",
                "description": "Set an explicit compression type (optional). The preferred default is `snappy` when the broker supports it, with a fall back to `none`."
              },
              {
                "name": "tls",
                "description": "Override system defaults with custom TLS settings.",
                "children": [
                  {
                    "name": "skip_cert_verify",
                    "description": "Whether to skip server-side certificate verification."
                  },
                  {
                    "name": "enable_renegotiation",
                    "description": "Whether to allow the remote server to request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`."
                  },
                  {
                    "name": "root_cas",
                    "description": "Specify a root certificate authority to use (optional). This is a string that represents a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
                  },
                  {
                    "name": "root_cas_file",
                    "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
                  },
                  {
                    "name": "client_certs",
                    "description": "A list of client certificates to use. For each certificate, specify either the fields `cert` and `key` or `cert_file` and `key_file`."
                  }
                ]
              },
              {
                "name": "timestamp_ms",
                "description": "Set a timestamp (in milliseconds) for each message (optional). Leave this field empty to use the current timestamp.\n\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
              }
            ]
          },
          {
            "name": "disable_content_encryption",
            "description": "If this value is set to `true`:\n\n* Only message payloads remain unencrypted. This setting does not disable TLS or any other transport-layer encryption that may also be enabled.\n* All other `ockam_kafka` inlets and outlets must also have their settings set to `true`."
          },
          {
            "name": "enrollment_ticket",
            "description": "The path to a file or a URL where the enrollment ticket value is stored, or an inline hex-encoded value of the enrollment ticket (optional).\n\nYou can generate a new ticket using the https://command.ockam.io/manual/ockam-project-ticket.html[`ockam project ticket` command^]."
          },
          {
            "name": "identity_name",
            "description": "The name of the https://command.ockam.io/manual/ockam-identity.html[Ockam identity^] to use. If this value is not provided, the default Ockam identity is automatically generated and used (optional)."
          },
          {
            "name": "allow",
            "description": "Use in conjunction with the `route_to_kafka_outlet` field to specify an access control policy for the Kafka Portal Outlet.\n\nFor example, setting this value to `kafka_us_east` forces the Kafka Outlet to present an Ockam credential, which confirms that the Outlet has the attribute `kafka_us_east=true`."
          },
          {
            "name": "route_to_kafka_outlet",
            "description": "The route to reach the Kafka Outlet of your Ockam portal. For example, `/project/default`."
          },
          {
            "name": "allow_consumer",
            "description": "Specify an access control policy for consumers.\n\nFor example, setting this value to `orders_consumer` forces the consumer to present an Ockam credential, which confirms that the consumer has the attribute `orders_consumer=true`."
          },
          {
            "name": "route_to_consumer",
            "description": "The route to the Kafka consumer. For example, `/project/default/service/forward_to_orders_consumer/secure/api` would connect to a consumer exposed through a relay named `orders_consumer`."
          }
        ]
      }
    },
    {
      "name": "opensearch",
      "config": {
        "children": [
          {
            "name": "index",
            "description": "The index to place messages.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "action",
            "description": "The action to take on the document. This field must resolve to one of the following action types: `index`, `update` or `delete`.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "id",
            "description": "The ID for indexed messages. Interpolation should be used in order to create a unique ID for each message.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "pipeline",
            "description": "An optional pipeline id to preprocess incoming documents.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "routing",
            "description": "The routing key to use for the document.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "pinecone",
      "config": {
        "children": [
          {
            "name": "api_key",
            "description": "The Pinecone API key."
          },
          {
            "name": "namespace",
            "description": "The namespace to write to - writes to the default namespace by default.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "id",
            "description": "The ID for the index entry in Pinecone.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "pulsar",
      "config": {
        "children": [
          {
            "name": "key",
            "description": "The key to publish messages with.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "ordering_key",
            "description": "The ordering key to publish messages with.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "pusher",
      "config": {
        "children": [
          {
            "name": "channel",
            "description": "Pusher channel to publish to. Interpolation functions can also be used\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "qdrant",
      "config": {
        "children": [
          {
            "name": "tls",
            "description": "Specify a secure TLS (HTTPS) connection to the Qdrant server."
          },
          {
            "name": "collection_name",
            "description": "The name of the collection in Qdrant.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "questdb",
      "config": {
        "children": [
          {
            "name": "max_in_flight",
            "description": "The maximum number of messages to have in flight at a given time. Increase this value to improve throughput."
          },
          {
            "name": "batching",
            "children": [
              {
                "name": "count",
                "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
              },
              {
                "name": "byte_size",
                "description": "The amount of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
              },
              {
                "name": "period",
                "description": "The period of time after which an incomplete batch is flushed regardless of its size."
              },
              {
                "name": "check",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that returns a boolean value indicating whether a message should end a batch."
              },
              {
                "name": "processors",
                "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
              }
            ]
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "enable_renegotiation",
                "description": "Whether to allow the remote server to request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`."
              },
              {
                "name": "root_cas",
                "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent trusted root certificate, through possible intermediate signing certificates, to the host certificate.certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "address",
            "description": "The host and port of the QuestDB server."
          },
          {
            "name": "username",
            "description": "The username to use for basic authentication."
          },
          {
            "name": "password",
            "description": "The password to use for basic authentication."
          },
          {
            "name": "token",
            "description": "The bearer token to use for authentication, which takes precedence over the basic authentication username and password."
          },
          {
            "name": "retry_timeout",
            "description": "The period of time to continue retrying after a failed HTTP request. The interval between retries is an exponential backoff starting at 10 ms, and doubling after each failed attempt up to a maximum of 1 second."
          },
          {
            "name": "request_timeout",
            "description": "The period of time to wait for a response from the QuestDB server in addition to any connection timeout calculated for the `request_min_throughput` field."
          },
          {
            "name": "request_min_throughput",
            "description": "The minimum expected throughput in bytes per second for HTTP requests. If the throughput is lower than this value, the connection times out. The `quest_db` output uses this value to calculate an additional timeout on top of the `request_timeout`. This setting is useful for large requests. Set it to `0` to disable this logic."
          },
          {
            "name": "table",
            "description": "The destination table in QuestDB."
          },
          {
            "name": "designated_timestamp_field",
            "description": "The name of the designated timestamp field in QuestDB."
          },
          {
            "name": "designated_timestamp_unit",
            "description": "Units used for the designated timestamp field in QuestDB."
          },
          {
            "name": "timestamp_string_fields",
            "description": "String fields with textual timestamps."
          },
          {
            "name": "timestamp_string_format",
            "description": "The timestamp format, which is used when parsing timestamp string fields and uses Golang's time formatting."
          },
          {
            "name": "symbols",
            "description": "Columns that must be the `symbol` type. String values default to `string` types."
          },
          {
            "name": "doubles",
            "description": "Columns that must be the `double` type, with `int` as the default."
          },
          {
            "name": "error_on_empty_messages",
            "description": "Mark a message as an error if it is empty after field validation."
          }
        ]
      }
    },
    {
      "name": "redis_hash",
      "config": {
        "children": [
          {
            "name": "key",
            "description": "The key for each message, function interpolations should be used to create a unique key per message.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "fields",
            "description": "A map of key/value pairs to set as hash fields.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "redis_list",
      "config": {
        "children": [
          {
            "name": "key",
            "description": "The key for each message, function interpolations can be optionally used to create a unique key per message.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "redis_pubsub",
      "config": {
        "children": [
          {
            "name": "channel",
            "description": "The channel to publish messages to.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "redis_streams",
      "config": {
        "children": [
          {
            "name": "stream",
            "description": "The stream to add messages to.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "redpanda",
      "config": {
        "children": [
          {
            "name": "seed_brokers",
            "description": "A list of broker addresses to connect to in order. Use commas to separate multiple addresses in a single list item."
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "enable_renegotiation",
                "description": "Whether to allow the remote server to request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`."
              },
              {
                "name": "root_cas",
                "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "sasl",
            "description": "Specify one or more methods or mechanisms of SASL authentication, which are attempted in order. If the broker supports the first SASL mechanism, all connections use it. If the first mechanism fails, the client picks the first supported mechanism. If the broker does not support any client mechanisms, all connections fail."
          },
          {
            "name": "metadata_max_age",
            "description": "The maximum period of time after which metadata is refreshed."
          },
          {
            "name": "request_timeout_overhead",
            "description": "Grants an additional buffer or overhead to requests that have timeout fields defined. This field is based on the behavior of Apache Kafka's `request.timeout.ms` parameter, but with the option to extend the timeout deadline."
          },
          {
            "name": "conn_idle_timeout",
            "description": "Define how long connections can remain idle before they are closed."
          },
          {
            "name": "topic",
            "description": "A topic to write messages to. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "key",
            "description": "An optional key to populate for each message. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "partition",
            "description": "Set a partition for each message (optional). This field is only relevant when the `partitioner` is set to `manual`.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].\n\nYou must provide an interpolation string that is a valid integer."
          },
          {
            "name": "metadata",
            "description": "Specify which (if any) metadata values are added to messages as headers."
          },
          {
            "name": "timestamp_ms",
            "description": "Set a timestamp (in milliseconds) for each message (optional). When left empty, the current timestamp is used. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of messages to have in flight at a given time. Increase this number to improve throughput until performance plateaus."
          },
          {
            "name": "idempotent_write",
            "description": "Enable the idempotent write producer option. This requires the `IDEMPOTENT_WRITE` permission on `CLUSTER`. Disable this option if the `IDEMPOTENT_WRITE` permission is not available."
          },
          {
            "name": "compression",
            "description": "Set an explicit compression type (optional). The default preference is to use `snappy` when the broker supports it. Otherwise, use `none`."
          },
          {
            "name": "timeout",
            "description": "The maximum period of time to wait for message sends before abandoning the request and retrying."
          },
          {
            "name": "max_message_bytes",
            "description": "The maximum space (in bytes) that an individual message may use. Messages larger than this value are rejected. This field corresponds to Kafka's `max.message.bytes`."
          },
          {
            "name": "broker_write_max_bytes",
            "description": "The maximum number of bytes this output can write to a broker connection in a single write. This field corresponds to Kafka\u2019s `socket.request.max.bytes`."
          }
        ]
      }
    },
    {
      "name": "redpanda_common",
      "config": {
        "children": [
          {
            "name": "topic",
            "description": "A topic to write messages to. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "key",
            "description": "A key to populate for each message (optional). This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "partition",
            "description": "Set a partition for each message (optional). This field is only relevant when the `partitioner` is set to `manual`.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].\n\nYou must provide an interpolation string that is a valid integer."
          },
          {
            "name": "metadata",
            "description": "Specify which (if any) metadata values are added to messages as headers."
          },
          {
            "name": "timestamp_ms",
            "description": "Set a timestamp (in milliseconds) for each message (optional). When left empty, the current timestamp is used. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of messages to have in flight at a given time. Increase this number to improve throughput until performance plateaus."
          },
          {
            "name": "batching",
            "children": [
              {
                "name": "count",
                "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
              },
              {
                "name": "byte_size",
                "description": "The number of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
              },
              {
                "name": "period",
                "description": "The period after which an incomplete batch is flushed regardless of its size."
              },
              {
                "name": "processors",
                "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "redpanda_migrator",
      "config": {
        "children": [
          {
            "name": "seed_brokers",
            "description": "A list of broker addresses to connect to. Use commas to separate multiple addresses in a single list item."
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "root_cas",
                "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate, specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "sasl",
            "description": "Specify one or more methods of SASL authentication, which are tried in order. If the broker supports the first mechanism, all connections will use that mechanism. If the first mechanism fails, the client picks the first supported mechanism. Connections fail if the broker does not support any client mechanisms."
          },
          {
            "name": "topic",
            "description": "A topic to write messages to.\n\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "key",
            "description": "An optional key to populate for each message.\n\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "partition",
            "description": "An optional explicit partition to set for each message. This field is only relevant when the `partitioner` is set to `manual`. The provided interpolation string must be a valid integer.\n\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "metadata",
            "description": "Specify which (if any) metadata values are added to messages as headers."
          },
          {
            "name": "metadata_max_age",
            "description": "The maximum period of time after which metadata is refreshed. Reducing this value increases the frequency with which newly-created topics are identified."
          },
          {
            "name": "request_timeout_overhead",
            "description": "Grants an additional buffer or overhead to requests that have timeout fields defined. This field is based on the behavior of Apache Kafka's `request.timeout.ms` parameter, but with the option to extend the timeout deadline."
          },
          {
            "name": "conn_idle_timeout",
            "description": "Define how long connections can remain idle before they are closed."
          },
          {
            "name": "topic_prefix",
            "description": "Adds the specified prefix to the name of each migrated topic. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "timestamp_ms",
            "description": "Set a timestamp (in milliseconds) for each message (optional). When left empty, the current timestamp is used.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of batches to send in parallel at any given time."
          },
          {
            "name": "input_resource",
            "description": "The xref:components:inputs/redpanda_migrator.adoc[`redpanda_migrator` input] used to read topics and ACLs. If your input has a custom label, update this field to match the custom label value."
          },
          {
            "name": "replication_factor_override",
            "description": "Whether to override the replication factor of input topics when creating copies of them on the output cluster. You must specify the new replication factor in the <<replication-factor, `replication_factor` field>>."
          },
          {
            "name": "replication_factor",
            "description": "The replication factor for created topics. This is only used when `replication_factor_override` is set to `true`."
          },
          {
            "name": "translate_schema_ids",
            "description": "When set to `true`, this field automatically translates the schema ID in each message to match the corresponding schema in the destination schema registry."
          },
          {
            "name": "schema_registry_output_resource",
            "description": "The label of the xref:components:outputs/schema_registry.adoc[`schema_registry` output] to use for fetching schema IDs."
          },
          {
            "name": "rack_id",
            "description": "A rack identifier for this client."
          },
          {
            "name": "idempotent_write",
            "description": "Enable the idempotent write producer option. This requires the `IDEMPOTENT_WRITE` permission on `CLUSTER`. Disable this option if the `IDEMPOTENT_WRITE` permission is unavailable."
          },
          {
            "name": "compression",
            "description": "Set an explicit compression type (optional). The default preference is to use `snappy` when the broker supports it. Otherwise, use `none`."
          },
          {
            "name": "timeout",
            "description": "The maximum period of time to wait for message sends before abandoning the request and retrying."
          },
          {
            "name": "max_message_bytes",
            "description": "The maximum space in bytes that an individual message may use. Messages larger than this value are rejected. This field corresponds to Kafka's `max.message.bytes`."
          },
          {
            "name": "broker_write_max_bytes",
            "description": "The maximum number of bytes this output can write to a broker connection in a single write. This field corresponds to Kafka\u2019s `socket.request.max.bytes`."
          }
        ]
      }
    },
    {
      "name": "redpanda_migrator_bundle",
      "config": {
        "children": [
          {
            "name": "redpanda_migrator",
            "description": "The xref:components:outputs/redpanda_migrator.adoc[`redpanda_migrator` output] configuration."
          },
          {
            "name": "schema_registry",
            "description": "The xref:components:outputs/schema_registry.adoc[`schema_registry` output] configuration. The `subject` field must be left empty."
          },
          {
            "name": "translate_schema_ids",
            "description": "When set to `true`, this field enables:\n\n- The `translate_schema_ids` field in the specified xref:components:outputs/redpanda_migrator.adoc#translate_schema_ids[`redpanda_migrator` output].\n- The `translate_ids` field in the specified xref:components:outputs/schema_registry.adoc#translate_ids[`schema_registry` output].\n\nWhen set to `false`, both fields are disabled."
          }
        ]
      }
    },
    {
      "name": "redpanda_migrator_offsets",
      "config": {
        "children": [
          {
            "name": "seed_brokers",
            "description": "A list of broker addresses to connect to. Use commas to separate multiple addresses in a single list item."
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "root_cas",
                "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate, specify values for either the `cert` and `key`, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "sasl",
            "description": "Specify one or more methods of SASL authentication, which are attempted in order. If the broker supports the first mechanism, all connections use that mechanism. If the first mechanism fails, the client picks the first supported mechanism. Connections fail if the broker does not support any client mechanisms."
          },
          {
            "name": "metadata_max_age",
            "description": "The maximum period of time after which metadata is refreshed."
          },
          {
            "name": "request_timeout_overhead",
            "description": "Grants an additional buffer or overhead to requests that have timeout fields defined. This field is based on the behavior of Apache Kafka's `request.timeout.ms` parameter, but with the option to extend the timeout deadline."
          },
          {
            "name": "conn_idle_timeout",
            "description": "Define how long connections can remain idle before they are closed."
          },
          {
            "name": "offset_topic",
            "description": "The name of the Kafka offset topic to process. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "offset_topic_prefix",
            "description": "Adds the specified prefix to the name of each migrated Kafka offset topic. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "offset_group",
            "description": "The name of the Kafka offset consumer group to process. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "offset_partition",
            "description": "The Kafka offset partition ID to process. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "offset_commit_timestamp",
            "description": "The Kafka offset commit timestamp to process. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "offset_metadata",
            "description": "The Kafka offset metadata value to process. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "is_high_watermark",
            "description": "Indicates whether the processed message is the high watermark, which is the offset of the last fully replicated message in the Kafka topic partition. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "timeout",
            "description": "The maximum period of time to wait for message sends before abandoning the request and retrying it."
          },
          {
            "name": "max_message_bytes",
            "description": "The maximum number of bytes that an individual message may use. Messages larger than this value are rejected. This field corresponds to Kafka's `max.message.bytes`."
          },
          {
            "name": "broker_write_max_bytes",
            "description": "The maximum number of bytes this output can write to a broker connection in a single write. This field corresponds to Kafka\u2019s `socket.request.max.bytes`."
          },
          {
            "name": "max_retries",
            "description": "The maximum number of retries before giving up on the request. If set to `0`, there is no discrete limit."
          },
          {
            "name": "backoff",
            "description": "Control the time intervals between retry attempts.",
            "children": [
              {
                "name": "initial_interval",
                "description": "The initial amount of time to wait between retry attempts. This value increases for each failed attempt up to the `backoff.max_interval` value."
              },
              {
                "name": "max_interval",
                "description": "The maximum amount of time to wait between retry attempts."
              },
              {
                "name": "max_elapsed_time",
                "description": "The maximum amount of time to wait before retry attempts are abandoned. If set to `0`, there is no waiting period."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "retry",
      "config": {
        "children": [
          {
            "name": "backoff",
            "children": [
              {
                "name": "initial_interval",
                "description": "The initial period to wait between retry attempts. The retry interval increases for each failed attempt, up to the `backoff.max_interval` value."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "slack_reaction",
      "type": "output",
      "status": "experimental",
      "plugin": true,
      "description": "Add or remove an emoji reaction from a Slack message.",
      "categories": null,
      "config": {
        "children": [
          {
            "name": "bot_token",
            "description": "Your Slack Bot User OAuth token used to authenticate the API request. This token must have the necessary `reactions:write` and `channels:read` (or related) scopes. It typically begins with `xoxb-`."
          },
          {
            "name": "channel_id",
            "description": "The unique Slack channel ID where the target message resides. Channel IDs usually start with `C` for public channels or `G` for private channels. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "timestamp",
            "description": "The timestamp of the message to react to. This is a unique identifier for the message, usually obtained from a previous Slack API call (such as `chat.postMessage` or `conversations.history`). It typically looks like a Unix timestamp with a decimal. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "emoji",
            "description": "The name of the emoji to be added or removed, without surrounding colons. Use the plain emoji name, such as `thumbsup` or `tada`. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "action",
            "description": "Whether to add or remove the reaction. When set to `add`, the specified emoji reaction is applied to the target message. When set to `remove`, the emoji reaction is removed from the target message."
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of messages to have in flight at a given time. Increasing this value can improve throughput in high-volume scenarios, but be cautious not to exceed Slack's API rate limits."
          }
        ]
      }
    },
    {
      "name": "schema_registry",
      "config": {
        "children": [
          {
            "name": "subject",
            "description": "The subject name.\n\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "backfill_dependencies",
            "description": "Backfill missing schema references and previous schema versions. If set to `true`, you must also configure a xref:components:inputs/schema_registry.adoc[`schema_registry`] input to read source schemas."
          },
          {
            "name": "translate_ids",
            "description": "When set to `true`, this field automatically translates the schema ID in each message to match the corresponding schema in the destination schema registry. The updated message is then written to the destination schema registry."
          },
          {
            "name": "input_resource",
            "description": "The label of the xref:components:inputs/schema_registry.adoc[`schema_registry` input] from which to read source schemas."
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "root_cas",
                "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of messages to have in flight at a given time. Increase this number to improve throughput."
          },
          {
            "name": "oauth",
            "description": "Configure OAuth version 1.0 to give this component authorized access to your schema registry.",
            "children": [
              {
                "name": "consumer_key",
                "description": "The value used to identify this component or client to your schema registry."
              },
              {
                "name": "consumer_secret",
                "description": "The secret used to establish ownership of the consumer key."
              },
              {
                "name": "access_token",
                "description": "The value this component can use to gain access to the schema registry."
              },
              {
                "name": "access_token_secret",
                "description": "The secret that establishes ownership of the `oauth.access_token`."
              }
            ]
          },
          {
            "name": "basic_auth",
            "description": "Configure basic authentication for requests from this component to your schema registry.",
            "children": [
              {
                "name": "username",
                "description": "The username of the account credentials to authenticate as."
              },
              {
                "name": "password",
                "description": "The password of the account credentials to authenticate with."
              }
            ]
          },
          {
            "name": "jwt",
            "description": "BETA: Configure JSON Web Token (JWT) authentication for the secure transmission of data from this component to your schema registry.",
            "children": [
              {
                "name": "private_key_file",
                "description": "A PEM-encoded file containing a private key that is formatted using either PKCS1 or PKCS8 standards."
              },
              {
                "name": "signing_method",
                "description": "The method used to sign the token, such as RS256, RS384, RS512 or EdDSA."
              },
              {
                "name": "claims",
                "description": "Values used to pass the identity of the authenticated entity to the service provider. In this case, between this component and the schema registry."
              },
              {
                "name": "headers",
                "description": "The key/value pairs that identify the type of token and signing algorithm."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "sftp",
      "config": {
        "children": [
          {
            "name": "address",
            "description": "The address (hostname or IP address) of the SFTP server to connect to."
          },
          {
            "name": "path",
            "description": "The file to save the messages to on the SFTP server. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "credentials",
            "description": "The credentials required to log in to the SFTP server. This can include a username and password, or a private key for secure access.",
            "children": [
              {
                "name": "username",
                "description": "The username required to authenticate with the SFTP server."
              },
              {
                "name": "password",
                "description": "The password for the username used to authenticate with the SFTP server."
              },
              {
                "name": "private_key_file",
                "description": "The path to a private key file used to authenticate with the SFTP server. You can also provide a private key using the <<credentials-private_key,`private_key`>> field."
              },
              {
                "name": "private_key",
                "description": "The private key used to authenticate with the SFTP server. This field provides an alternative to the <<credentials-private_key_file, `private_key_file`>>."
              },
              {
                "name": "private_key_pass",
                "description": "A passphrase for private key."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "slack_post",
      "config": {
        "children": [
          {
            "name": "bot_token",
            "description": "Your Slack bot user's OAuth token, which must have the correct permissions to post messages to the target Slack channel."
          },
          {
            "name": "channel_id",
            "description": "The encoded ID of the target Slack channel. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "thread_ts",
            "description": "Specify the thread timestamp (`ts` value) of another message to post a reply within the same thread. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "text",
            "description": "The text content of the message. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].\n\nYou can either specify message content in the `text` or `blocks` fields, but not both."
          },
          {
            "name": "blocks",
            "description": "A Bloblang query that should return a JSON array of https://api.slack.com/reference/block-kit/blocks[Slack blocks^].\n\nYou can either specify message content in the `text` or `blocks` fields, but not both."
          },
          {
            "name": "markdown",
            "description": "When set to `true`, this output accepts message content in Markdown format."
          },
          {
            "name": "unfurl_links",
            "description": "When set to `true`, this output provides previews of linked content in Slack messages. For more information about unfurling links, see the https://api.slack.com/reference/messaging/link-unfurling[Slack documentation^]."
          },
          {
            "name": "unfurl_media",
            "description": "When set to `true`, this output provides previews of rich content in Slack messages, such as videos or embedded tweets."
          },
          {
            "name": "link_names",
            "description": "When set to `1`, this output finds and links to https://api.slack.com/reference/surfaces/formatting#mentioning-groups[user groups^] mentioned in Slack messages."
          }
        ]
      }
    },
    {
      "name": "snowflake_put",
      "config": {
        "children": [
          {
            "name": "private_key",
            "description": "Your private SSH key. When using encrypted keys, you must also set a value for <<private_key_pass,`private_key_pass`>>."
          },
          {
            "name": "private_key_file",
            "description": "The path to a file containing your private SSH key. When using encrypted keys, you must also set a value for <<private_key_pass,`private_key_pass`>>."
          },
          {
            "name": "private_key_pass",
            "description": "The passphrase for your private SSH key."
          },
          {
            "name": "stage",
            "description": "Stage name. Use either one of the\n\t\thttps://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage.html[supported^] stage types.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "path",
            "description": "Stage path.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "file_name",
            "description": "Stage file name. Will be equal to the Request ID if not set or empty.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "file_extension",
            "description": "Stage file extension. Will be derived from the configured `compression` if not set or empty.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "request_id",
            "description": "Request ID. Will be assigned a random UUID (v4) string if not set or empty.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "snowpipe",
            "description": "An optional Snowpipe name. Use the `<snowpipe>` part from `<database>.<schema>.<snowpipe>`.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "snowflake_streaming",
      "config": {
        "children": [
          {
            "name": "account",
            "description": "The https://docs.snowflake.com/en/user-guide/admin-account-identifier#account-name[Snowflake account name to use^]. \n\nUse the format `<orgname>-<account_name>` where:\n\n- The `<orgname>` is the name of your Snowflake organization.\n- The `<account_name>` is the unique name of your account with your Snowflake organization.\n\nTo find the correct value for this field, run the following query in Snowflake:\n\n```sql\nWITH HOSTLIST AS \n(SELECT * FROM TABLE(FLATTEN(INPUT => PARSE_JSON(SYSTEM$allowlist()))))\nSELECT REPLACE(VALUE:host,'.snowflakecomputing.com','') AS ACCOUNT_IDENTIFIER\nFROM HOSTLIST\nWHERE VALUE:type = 'SNOWFLAKE_DEPLOYMENT_REGIONLESS';\n```"
          },
          {
            "name": "url",
            "description": "Specify a custom URL to connect to Snowflake. This parameter overrides the default URL, which is automatically generated from the value of `output.snowflake_streaming.account`. By default, the URL is constructed as follows: `https://<output.snowflake_streaming.account>.snowflakecomputing.com`."
          },
          {
            "name": "user",
            "description": "Specify a user to run the Snowpipe Stream. To learn how to create a user, see the https://docs.snowflake.com/en/user-guide/admin-user-management[Snowflake documentation^]."
          },
          {
            "name": "role",
            "description": "The role of the user specified in the `user` field. The user's role must have the https://docs.snowflake.com/en/user-guide/data-load-snowpipe-streaming-overview#required-access-privileges[required privileges^] to call the Snowpipe Streaming APIs. For more information about user roles, see the https://docs.snowflake.com/en/user-guide/admin-user-management#user-roles[Snowflake documentation^]."
          },
          {
            "name": "database",
            "description": "The Snowflake database you want to write data to."
          },
          {
            "name": "schema",
            "description": "The schema of the Snowflake database you want to write data to."
          },
          {
            "name": "table",
            "description": "The Snowflake table you want to write data to. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "private_key",
            "description": "The PEM-encoded private RSA key to use for authentication with Snowflake. You must specify a value for this field or the `private_key_file` field."
          },
          {
            "name": "private_key_file",
            "description": "A `.p8`, PEM-encoded file to load the private RSA key from. You must specify a value for this field or the `private_key` field."
          },
          {
            "name": "private_key_pass",
            "description": "If the RSA key is encrypted, specify the RSA key passphrase."
          },
          {
            "name": "mapping",
            "description": "The xref:guides:bloblang/about.adoc[Bloblang `mapping`] to execute on each message."
          },
          {
            "name": "init_statement",
            "description": "Optional SQL statements to execute immediately after this output connects to Snowflake for the first time. This is a useful way to initialize tables before processing data. \n\nNOTE: Make sure your SQL statements are idempotent, so they do not cause issues when run multiple times after service restarts."
          },
          {
            "name": "schema_evolution",
            "description": "Options to control schema updates when messages are written to the Snowflake table.",
            "children": [
              {
                "name": "enabled",
                "description": "Whether schema evolution is enabled. When set to `true`, the Snowflake table is automatically created based on the schema of the first message written to it, if the table does not already exist. As new fields are added to subsequent messages in the pipeline, new columns are created in the Snowflake table. Any required columns are marked as `nullable` if new messages do not include data for them."
              },
              {
                "name": "ignore_nulls",
                "description": "When set to `true` and schema evolution is enabled, new columns that have `null` values _are not_ added to the Snowflake table. This behavior:\n\n-  Prevents unnecessary schema changes caused by placeholder or incomplete data.\n-  Avoids creating table columns with incorrect data types.\n\nNOTE: Redpanda does not recommend updating the default setting unless you are confident about the data type of `null` columns in advance."
              },
              {
                "name": "processors",
                "description": "A series of processors to execute when new columns are added to the Snowflake table. You can use these processors to:\n\n- Run side effects when the schema evolves.\n- Enrich the message with additional information to guide the schema changes.\n\nFor example, a processor could read the schema from the schema registry that a message was produced with and use that schema to determine the data type of the new column in Snowflake.\n\nThe input to these processors is an object with the value and name of the new column, the original message, and details of the Snowflake table the output writes to. \n\nFor example: `{\"value\": 42.3, \"name\":\"new_data_field\", \"message\": {\"existing_data_field\": 42, \"new_data_field\": \"db_field_name\"}, \"db\": MY_DATABASE\", \"schema\": \"MY_SCHEMA\", \"table\": \"MY_TABLE\"}`\n\nThe output from the processors must be a valid message, which contains a string that specifies the column type for the new column in Snowflake. The metadata remains the same as in the original message that triggered the schema update."
              }
            ]
          },
          {
            "name": "build_options",
            "description": "Options for optimizing the build of the output data that is sent to Snowflake. Monitor the `snowflake_build_output_latency_ns` metric to assess whether you need to update these options.",
            "children": [
              {
                "name": "parallelism",
                "description": "The maximum amount of parallel processing to use when building the output for Snowflake."
              },
              {
                "name": "chunk_size",
                "description": "The number of table rows to submit in each chunk for processing."
              }
            ]
          },
          {
            "name": "batching",
            "description": "Lets you configure a xref:configuration:batching.adoc[batching policy].\n\nType*: `object`\n```yml\n# Examples\nbatching:\n  byte_size: 5000\n  count: 0\n  period: 1s\nbatching:\n  count: 10\n  period: 1s\nbatching:\n  check: this.contains(\"END BATCH\")\n  count: 0\n  period: 1m\n```",
            "children": [
              {
                "name": "count",
                "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
              },
              {
                "name": "byte_size",
                "description": "The amount of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
              },
              {
                "name": "period",
                "description": "The period after which an incomplete batch is flushed regardless of its size."
              },
              {
                "name": "processors",
                "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
              }
            ]
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of messages to have in flight at a given time. Increase this number to improve throughput until performance plateaus."
          },
          {
            "name": "channel_prefix",
            "description": "The prefix to use when creating a channel name for connecting to a Snowflake table. Adding a `channel_prefix` avoids the creation of duplicate channel names, which result in errors and prevent multiple instances of Redpanda Connect from writing at the same time.\n\nYou can specify either the `channel_prefix` or `channel_name`, but not both. If neither field is populated, this output creates a channel name based on a table's fully-qualified name, which results in a single stream per table. \n\nThe maximum number of channels open at any time is determined by the value in the `max_in_flight` field. \n\nNOTE: Snowflake limits the number of streams per table to 10,000. If you need to use more than 10,000 streams, contact https://www.snowflake.com/en/support/[Snowflake support^]."
          },
          {
            "name": "channel_name",
            "description": "The channel name to use when connecting to a Snowflake table. Duplicate channel names cause errors and prevent multiple instances of Redpanda Connect from writing at the same time, and so this field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].\n\nRedpanda Connect assumes that a message batch contains messages for a single channel, which means that interpolation is only executed on the first message in each batch. If your pipeline uses an input that is partitioned, such as an Apache Kafka topic, batch messages at the input level to make sure all messages are processed by the same channel.\n\nYou can specify either the `channel_name` or `channel_prefix`, but not both. If neither field is populated, this output creates a channel name based on a table's fully-qualified name, which results in a single stream per table.\n\nNOTE: Snowflake limits the number of streams per table to 10,000. If you need to use more than 10,000 streams, contact https://www.snowflake.com/en/support/[Snowflake support^]."
          },
          {
            "name": "offset_token",
            "description": "The offset token to use for exactly-once delivery of data to a Snowflake table. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].\n\nThis output assumes that messages within a batch are in increasing order by offset token. When data is sent on a channel, the offset token of each message in the batch is compared to the latest token processed by the channel. If the offset token is lexicographically less than the latest token, it's assumed the message is a duplicate and is dropped. Messages must be delivered to the output in order, otherwise they are processed as duplicates and dropped.\n\nTo avoid dropping retried messages if later messages have succeeded in the meantime, use a dead-letter queue to process failed messages. See the <<example-pipelines, Ingesting data exactly once from Redpanda>> example.\n\nNOTE: If you're using a numeric value as an offset token, pad the value so that it's lexicographically ordered in its string representation because offset tokens are compared in string form. For more details, see the <<example-pipelines, Ingesting data exactly once from Redpanda>> example.\n\nFor more information about offset tokens, see https://docs.snowflake.com/en/user-guide/data-load-snowpipe-streaming-overview#offset-tokens[Snowflake Documentation^]."
          },
          {
            "name": "commit_timeout",
            "description": "The maximum duration to wait while data updates from a message batch are asynchronously committed to Snowflake."
          }
        ]
      }
    },
    {
      "name": "sql",
      "config": {
        "children": [
          {
            "name": "query",
            "description": "The query to execute. The style of placeholder to use depends on the driver, some drivers require question marks (`?`) whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2` and so on). The style to use is outlined in this table:\n\ninclude::components:partial$query_table.adoc[]"
          }
        ]
      }
    },
    {
      "name": "sql_insert",
      "config": {
        "children": [
          {
            "name": "dsn",
            "description": "A Data Source Name to identify the target database."
          }
        ]
      }
    },
    {
      "name": "sql_raw",
      "config": {
        "children": [
          {
            "name": "dsn",
            "description": "A Data Source Name to identify the target database."
          },
          {
            "name": "query",
            "description": "The query to execute. \n\nYou must include the correct placeholders for the specified database driver. Some drivers use question marks (`?`), whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2`, and so on). \n\ninclude::components:partial$query_table.adoc[]"
          },
          {
            "name": "args_mapping",
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] that includes the same number of values in an array as the placeholder arguments in the <<query, `query`>> field."
          },
          {
            "name": "queries",
            "description": "A list of database statements to run in addition to your main <<query, `query`>>. If you specify multiple queries, they are executed within a single transaction. For more information, see <<Examples, Examples>>."
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of database statements to execute in parallel."
          }
        ]
      }
    },
    {
      "name": "timeplus",
      "config": {
        "children": [
          {
            "name": "target",
            "description": "The destination platform. For Timeplus Enterprise (Cloud or Self-Hosted), enter `timeplus`, or `timeplusd` for the `timeplusd` component."
          },
          {
            "name": "url",
            "description": "The URL of your Timeplus instance, which should always include the schema and host."
          },
          {
            "name": "workspace",
            "description": "The ID of the workspace you want to send messages to. This field is required if the `target` field is set to `timeplus`."
          },
          {
            "name": "stream",
            "description": "The name of the destination data stream. Make sure the schema of the data stream matches this output."
          },
          {
            "name": "apikey",
            "description": "The API key for the Ingest API. You need to generate this in the web console of Timeplus Enterprise (Cloud). This field is required if you are sending messages to Timeplus Enterprise (Cloud)."
          },
          {
            "name": "username",
            "description": "The username for the Timeplus application server. This field is required if you are sending messages to Timeplus Enterprise (Self-Hosted) or `timeplusd`."
          },
          {
            "name": "password",
            "description": "The password for the Timeplus application server. This field is required if you are sending messages to Timeplus Enterprise (Self-Hosted) or `timeplusd`."
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of message batches to have in flight at a given time. Increase this number to improve throughput."
          },
          {
            "name": "batching",
            "description": "Configure a xref:configuration:batching.adoc[batching policy].",
            "children": [
              {
                "name": "count",
                "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
              },
              {
                "name": "byte_size",
                "description": "The amount of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
              },
              {
                "name": "period",
                "description": "The period of time after which an incomplete batch is flushed regardless of its size."
              },
              {
                "name": "check",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that returns a boolean value indicating whether a message should end a batch."
              },
              {
                "name": "processors",
                "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "websocket",
      "config": {
        "children": [
          {
            "name": "oauth",
            "description": "Allows you to specify open authentication using OAuth version 1."
          },
          {
            "name": "jwt",
            "description": "BETA: Allows you to specify JSON Web Token (JWT) authentication.",
            "children": [
              {
                "name": "private_key_file",
                "description": "A file with the PEM encoded using PKCS1 or PKCS8 as private key."
              },
              {
                "name": "signing_method",
                "description": "A method used to sign the token, such as RS256, RS384, RS512 or EdDSA."
              },
              {
                "name": "headers",
                "description": "Add key/value headers to the JWT (optional)."
              }
            ]
          }
        ]
      }
    }
  ],
  "processors": [
    {
      "name": "archive",
      "config": {
        "children": [
          {
            "name": "path",
            "description": "The path to set for each message in the archive (when applicable).\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "aws_bedrock_chat",
      "config": {
        "children": [
          {
            "name": "model",
            "description": "The model ID to use. For a full list, see the https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html[AWS Bedrock documentation^]."
          },
          {
            "name": "stop",
            "description": "The likelihood of the model selecting higher-probability options while generating a response. A lower value makes the model more likely to choose higher-probability options. A higher value makes the model more likely to choose lower-probability options."
          },
          {
            "name": "credentials",
            "description": "Configure which AWS credentials to use (optional). For more information, see xref:guides:cloud/aws.adoc[].",
            "children": [
              {
                "name": "profile",
                "description": "The profile from `~/.aws/credentials` to use."
              },
              {
                "name": "secret",
                "description": "The secret for the credentials you want to use."
              },
              {
                "name": "token",
                "description": "The token for the credentials you want to use. You must enter this value when using short-term credentials."
              },
              {
                "name": "role",
                "description": "The role ARN to assume."
              },
              {
                "name": "role_external_id",
                "description": "The external ID to use when assuming a role."
              }
            ]
          },
          {
            "name": "endpoint",
            "description": "Specify a custom endpoint for the AWS API."
          },
          {
            "name": "temperature",
            "description": "A list of stop sequences. A stop sequence is a sequence of characters that causes the model to stop generating the response."
          },
          {
            "name": "top_p",
            "description": "The percentage of most-likely candidates that the model considers for the next token. For example, if you choose a value of `0.8`, the model selects from the top 80% of the probability distribution of tokens that could be next in the sequence."
          }
        ]
      }
    },
    {
      "name": "aws_bedrock_embeddings",
      "config": {
        "children": [
          {
            "name": "model",
            "description": "The ID of the LLM that you want to use to generate vector embeddings. For a full list, see the https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html[AWS Bedrock documentation^]."
          },
          {
            "name": "text",
            "description": "The prompt you want to generate a vector embedding for. The processor submits the entire payload as a string."
          },
          {
            "name": "region",
            "description": "The region in which your AWS resources are hosted."
          },
          {
            "name": "endpoint",
            "description": "Specify a custom endpoint for the AWS API."
          },
          {
            "name": "credentials",
            "description": "Manually configure the AWS credentials to use (optional). For more information, see the xref:guides:cloud/aws.adoc[Amazon Web Services guide].",
            "children": [
              {
                "name": "profile",
                "description": "The profile from `~/.aws/credentials` to use."
              },
              {
                "name": "id",
                "description": "The ID of the AWS credentials to use."
              },
              {
                "name": "secret",
                "description": "The secret for the AWS credentials in use."
              },
              {
                "name": "token",
                "description": "The token for the AWS credentials in use. This is a required value for short-term credentials."
              },
              {
                "name": "role",
                "description": "The role ARN to assume."
              },
              {
                "name": "role_external_id",
                "description": "An external ID to use when assuming a role."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "azure_cosmosdb",
      "config": {
        "children": [
          {
            "name": "patch_condition",
            "description": "Patch operation condition.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "item_id",
            "description": "ID of item to replace or delete. Only used by the Replace and Delete operations\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "benchmark",
      "config": {
        "children": [
          {
            "name": "interval",
            "description": "How often to emit rolling statistics. Set to `0`, if you only want to log summary statistics when the processor shuts down."
          },
          {
            "name": "count_bytes",
            "description": "Whether to measure the number of bytes per second of throughput. If set to `true`, Redpanda Connect must serialize structured data to count the number of bytes processed, which can unnecessarily degrade performance if serialization is not required elsewhere in your pipeline."
          }
        ]
      }
    },
    {
      "name": "cache",
      "config": {
        "children": [
          {
            "name": "key",
            "description": "A key to use with the cache.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "value",
            "description": "A value to use with the cache (when applicable).\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "ttl",
            "description": "The time to live (TTL) of each individual item as a duration string. After this period an item will be eligible for removal during the next compaction. Not all caches support per-key TTLs, those that do will have a configuration field `default_ttl`, and those that do not will fall back to their generally configured TTL setting.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "cached",
      "config": {
        "children": [
          {
            "name": "key",
            "description": "A key to be resolved for each message, if the key already exists in the cache then the cached result is used, otherwise the processors are applied and the result is cached under this key. The key could be static and therefore apply generally to all messages or it could be an interpolated expression that is potentially unique for each message.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "ttl",
            "description": "An optional expiry period to set for each cache entry. Some caches only have a general TTL and will therefore ignore this setting.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "cohere_chat",
      "config": {
        "children": [
          {
            "name": "model",
            "description": "The name of the Cohere large language model (LLM) you want to use."
          },
          {
            "name": "prompt",
            "description": "The user prompt you want to generate a response for. By default, the processor submits the entire payload as a string.\n\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "system_prompt",
            "description": "The system prompt to submit along with the user prompt.\n\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "max_tokens",
            "description": "The maximum number of tokens to allow in the chat completion."
          },
          {
            "name": "temperature",
            "description": "Choose a sampling temperature between `0` and `2`: \n\n* Higher values, such as `0.8` make the output more random.\n* Lower values, such as `0.2` make the output more focused and deterministic.\n\nRedpanda recommends adding a value for this field or `top_p`, but not both."
          },
          {
            "name": "response_format",
            "description": "Choose the model's output format. If `json_schema` is specified, then you must also configure a `json_schema` or `schema_registry`."
          },
          {
            "name": "json_schema",
            "description": "The JSON schema to use when responding in `json_schema` format. To learn more about the JSON schema features supported, see the https://docs.cohere.com/docs/structured-outputs-json[Cohere documentation^]."
          },
          {
            "name": "schema_registry",
            "description": "The schema registry to dynamically load schemas from when responding in `json_schema` format. Schemas themselves must be in JSON format. To learn more about the JSON schema features supported, see the https://docs.cohere.com/docs/structured-outputs-json[Cohere documentation^].",
            "children": [
              {
                "name": "refresh_interval",
                "description": "The refresh rate for fetching the latest schema. If not specified the schema does not refresh."
              },
              {
                "name": "tls",
                "description": "Override system defaults with custom TLS settings.",
                "children": [
                  {
                    "name": "skip_cert_verify",
                    "description": "Whether to skip server-side certificate verification."
                  },
                  {
                    "name": "enable_renegotiation",
                    "description": "Whether to allow the remote server to request renegotiation. Enable this option if you're seeing the error message `local error: \ntls: no renegotiation`."
                  },
                  {
                    "name": "root_cas",
                    "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent trusted root certificate, through possible intermediate signing certificates, to the host certificate."
                  },
                  {
                    "name": "root_cas_file",
                    "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent trusted root certificate, through possible intermediate signing certificates, to the host certificate.certificate."
                  },
                  {
                    "name": "client_certs",
                    "description": "A list of client certificates to use. For each certificate specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
                  }
                ]
              },
              {
                "name": "oauth",
                "description": "Configure OAuth version 1.0 to give this component authorized access to your schema registry.",
                "children": [
                  {
                    "name": "enabled",
                    "description": "Whether to use OAuth version 1 in requests to the schema registry."
                  },
                  {
                    "name": "consumer_key",
                    "description": "The value used to identify this component or client to your schema registry."
                  },
                  {
                    "name": "consumer_secret",
                    "description": "The secret used to establish ownership of the consumer key."
                  },
                  {
                    "name": "access_token",
                    "description": "The value this component can use to gain access to the data in the schema registry."
                  },
                  {
                    "name": "access_token_secret",
                    "description": "The secret that establishes ownership of the `oauth.access_token`."
                  }
                ]
              },
              {
                "name": "basic_auth",
                "description": "Configure basic authentication for requests from this component to your schema registry.",
                "children": [
                  {
                    "name": "username",
                    "description": "The username of the account credentials to authenticate as."
                  },
                  {
                    "name": "password",
                    "description": "The password of the account credentials to authenticate with."
                  }
                ]
              },
              {
                "name": "jwt",
                "description": "BETA: Configure JSON Web Token (JWT) authentication for the secure transmission of data from your schema registry to this component.",
                "children": [
                  {
                    "name": "private_key_file",
                    "description": "A file in PEM format encoded via PKCS1 or PKCS8 as private key."
                  },
                  {
                    "name": "signing_method",
                    "description": "The method used to sign the token, such as RS256, RS384, RS512 or EdDSA."
                  },
                  {
                    "name": "claims",
                    "description": "Values used to pass the identity of the authenticated entity to the service provider. In this case, between this component and the schema registry."
                  },
                  {
                    "name": "headers",
                    "description": "The key/value pairs that identify the type of token and signing algorithm."
                  }
                ]
              }
            ]
          },
          {
            "name": "top_p",
            "description": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. For example, a `top_p` of `0.1` means only the tokens comprising the top 10% probability mass are sampled.\n\nRedpanda recommends adding a value for this field or `temperature`, but not both."
          },
          {
            "name": "frequency_penalty",
            "description": "A number between `-2.0` and `2.0`. Positive values penalize new tokens based on the frequency of their appearance in the text so far. This decreases the model's likelihood to repeat the same line verbatim."
          },
          {
            "name": "presence_penalty",
            "description": "A number between `-2.0` and `2.0`. Positive values penalize new tokens based on the frequency of their appearance in the text so far. This increases the model's likelihood to talk about new topics."
          },
          {
            "name": "seed",
            "description": "If specified, Redpanda Connect makes a best effort to sample deterministically. Repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed."
          },
          {
            "name": "stop",
            "description": "Specify up to four sequences to stop the API from generating further tokens."
          },
          {
            "name": "max_tool_calls",
            "description": "The maximum number of tool calls the model can perform."
          },
          {
            "name": "tools",
            "description": "External tools that the model can invoke, such as functions, APIs, or web browsing. You can define a series of processors that describe these tools, enabling the model to use agent-like behavior to decide when and how to invoke them to enhance response generation."
          }
        ]
      }
    },
    {
      "name": "cohere_embeddings",
      "config": {
        "children": [
          {
            "name": "model",
            "description": "The name of the Cohere LLM you want to use."
          },
          {
            "name": "input_type",
            "description": "The type of text input passed to the model."
          },
          {
            "name": "dimensions",
            "description": "The number of dimensions (numerical values) in each vector embedding generated by this processor. This parameter only supports https://docs.cohere.com/v2/docs/embeddings[`embed-v4.0`^] and newer models."
          }
        ]
      }
    },
    {
      "name": "cohere_rerank",
      "config": {
        "children": [
          {
            "name": "api_key",
            "description": "Your API key for the Cohere API."
          },
          {
            "name": "model",
            "description": "The name of the Cohere LLM you want to use."
          },
          {
            "name": "query",
            "description": "The search query you want to execute. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "documents",
            "description": "A list of text strings that are compared to the specified query. For optimal performance:\n\n- Send fewer than 1000 documents in a single request\n- Send structured data in YAML format"
          },
          {
            "name": "top_n",
            "description": "The number of documents to return when the query is executed. If set to `0`, all documents are returned."
          },
          {
            "name": "max_tokens_per_doc",
            "description": "This processor automatically truncates long documents to the specified number of tokens."
          }
        ]
      }
    },
    {
      "name": "command",
      "config": {
        "children": [
          {
            "name": "name",
            "description": "The name of the command to execute.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "couchbase",
      "config": {
        "children": [
          {
            "name": "id",
            "description": "Document id.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "dedupe",
      "config": {
        "children": [
          {
            "name": "key",
            "description": "An interpolated string yielding the key to deduplicate by for each message.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "gcp_bigquery_select",
      "config": {
        "children": [
          {
            "name": "credentials_json",
            "description": "Optional field to set https://developers.google.com/workspace/guides/create-credentials#create_credentials_for_a_service_account[Google Service Account Credentials JSON^]."
          }
        ]
      }
    },
    {
      "name": "gcp_vertex_ai_chat",
      "config": {
        "children": [
          {
            "name": "project",
            "description": "The GCP project ID to use."
          },
          {
            "name": "credentials_json",
            "description": "An optional field to set a Google Service Account Credentials JSON."
          },
          {
            "name": "location",
            "description": "Specify the location of a fine tuned model. For base models, you can omit this field."
          },
          {
            "name": "prompt",
            "description": "The prompt you want to generate a response for. By default, the processor submits the entire payload as a string.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "system_prompt",
            "description": "The system prompt to submit to the Vertex AI LLM.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "temperature",
            "description": "Controls the randomness of predictions."
          },
          {
            "name": "response_format",
            "description": "The format of the generated response. You must also prompt the model to output the appropriate response type."
          },
          {
            "name": "top_p",
            "description": "Enables nucleus sampling (optional)."
          },
          {
            "name": "top_k",
            "description": "Enables top-k sampling (optional)."
          },
          {
            "name": "stop",
            "description": "Sets the stop sequences to use. When this pattern is encountered the LLM stops generating text and returns the final response."
          },
          {
            "name": "presence_penalty",
            "description": "Positive values penalize new tokens if they appear in the text already, increasing the model's likelihood to include new topics."
          }
        ]
      }
    },
    {
      "name": "gcp_vertex_ai_embeddings",
      "config": {
        "children": [
          {
            "name": "project",
            "description": "The ID of your Google Cloud project."
          },
          {
            "name": "credentials_json",
            "description": "Set your Google Service Account Credentials as JSON."
          },
          {
            "name": "location",
            "description": "The location of the Vertex AI large language model (LLM) that you want to use."
          },
          {
            "name": "task_type",
            "description": "Use the following options to optimize embeddings that the model generates for specific use cases."
          },
          {
            "name": "text",
            "description": "The text you want to generate vector embeddings for. By default, the processor submits the entire payload as a string.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "output_dimensions",
            "description": "The maximum length of a generated vector embedding. If this value is set, generated embeddings are truncated to this size."
          }
        ]
      }
    },
    {
      "name": "google_drive_download",
      "config": {
        "children": [
          {
            "name": "credentials_json",
            "description": "The JSON key for your service account (optional). If left empty, Application Default Credentials are used. For more details, see <<authentication, Authentication>>."
          },
          {
            "name": "file_id",
            "description": "The ID of the file to download from Google Drive. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "mime_type",
            "description": "The https://developers.google.com/workspace/drive/api/guides/mime-types[MIME type^] of the file for download. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "export_mime_types",
            "description": "Maps Google Drive MIME types to https://developers.google.com/workspace/drive/api/guides/ref-export-formats[supported file export formats^]. The MIME type is the key, and the export format is the value."
          }
        ]
      }
    },
    {
      "name": "google_drive_list_labels",
      "config": {
        "children": [
          {
            "name": "credentials_json",
            "description": "The JSON key for your service account (optional). If left empty, Application Default Credentials are used. For more details, see <<authentication, Authentication>>."
          }
        ]
      }
    },
    {
      "name": "google_drive_search",
      "config": {
        "children": [
          {
            "name": "credentials_json",
            "description": "The JSON key for your service account (optional). If left empty, Application Default Credentials are used. For more details, see <<authentication, Authentication>>."
          },
          {
            "name": "query",
            "description": "Specify a search query to locate matching files in Google Drive. This field supports:\n\n- The same query syntax as the Google Drive UI\n- xref:configuration:interpolation.adoc#bloblang-queries[Bloblang interpolation functions] for dynamic query generation"
          },
          {
            "name": "projection",
            "description": "Partial fields to include in the Google Drive search result."
          },
          {
            "name": "include_label_ids",
            "description": "A comma delimited list of label IDs to include in the Google Drive search result. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "max_results",
            "description": "The maximum number of search results to return."
          }
        ]
      }
    },
    {
      "name": "group_by_value",
      "config": {
        "children": [
          {
            "name": "value",
            "description": "The interpolated string to group based on.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "http",
      "config": {
        "children": [
          {
            "name": "url",
            "description": "The URL to connect to. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "verb",
            "description": "A verb to connect with."
          },
          {
            "name": "headers",
            "description": "A map of headers to add to the request. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "metadata",
            "description": "Specify matching rules that determine which metadata keys should be added to the HTTP request as headers."
          },
          {
            "name": "dump_request_log_level",
            "description": "EXPERIMENTAL: Set the logging level for the request and response payloads of each HTTP request."
          },
          {
            "name": "oauth",
            "description": "Allows you to specify open authentication using OAuth version 1.",
            "children": [
              {
                "name": "access_token",
                "description": "The value used to gain access to the protected resources on behalf of the user."
              },
              {
                "name": "access_token_secret",
                "description": "The secret that establishes ownership of the `oauth.access_token`."
              }
            ]
          },
          {
            "name": "oauth2",
            "description": "Allows you to specify open authentication via OAuth version 2 and the client credentials token flow.",
            "children": [
              {
                "name": "client_secret",
                "description": "The secret used to establish ownership of the client key."
              },
              {
                "name": "scopes",
                "description": "A list of requested permissions (optional)."
              },
              {
                "name": "endpoint_params",
                "description": "A list of endpoint parameters specified as arrays of strings (optional)."
              }
            ]
          },
          {
            "name": "jwt",
            "description": "BETA: Allows you to specify JSON Web Token (JWT) authentication.",
            "children": [
              {
                "name": "private_key_file",
                "description": "A file with the PEM encoded using PKCS1 or PKCS8 as private key."
              },
              {
                "name": "signing_method",
                "description": "A method used to sign the token, such as RS256, RS384, RS512 or EdDSA."
              },
              {
                "name": "headers",
                "description": "Add key/value headers to the JWT (optional)."
              }
            ]
          },
          {
            "name": "tls",
            "description": "Override system defaults with custom TLS settings.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "root_cas",
                "description": "Specify a root certificate authority to use (optional). This is a string, representing a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate, specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "extract_headers",
            "description": "Specify which response headers to add to the resulting messages as metadata. Header keys are automatically converted to lowercase before matching, so make sure that your patterns target the lowercase versions of the expected header keys."
          },
          {
            "name": "rate_limit",
            "description": "A xref:components:rate_limits/about.adoc[rate limit] to throttle requests by (optional)."
          },
          {
            "name": "retry_period",
            "description": "The initial period to wait between failed requests before retrying."
          },
          {
            "name": "follow_redirects",
            "description": "Whether to follow redirects, including all responses with HTTP status codes in the 300-399 range. If set to `false`, the response message includes only the body, status, and headers from the redirect response, and this processor does not make a request to the URL specified in the `Location` header."
          },
          {
            "name": "backoff_on",
            "description": "A list of status codes that indicate a request failure, and trigger retries with an increasing backoff period between attempts."
          },
          {
            "name": "drop_on",
            "description": "A list of status codes that indicate a request failure, where the input should not attempt retries. This helps avoid unnecessary retries for requests that are unlikely to succeed.\n\nNOTE: In these cases, the _request_ is dropped, but the _message_ that triggered the request is retained."
          },
          {
            "name": "successful_on",
            "description": "A list of HTTP status codes that should be considered as successful, even if they are not 2XX codes. This is useful for handling cases where non-2XX codes indicate that the request was processed successfully, such as `303 See Other` or `409 Conflict`. \n\nBy default, all 2XX codes are considered successful unless they are specified in `backoff_on` or `drop_on` fields."
          },
          {
            "name": "proxy_url",
            "description": "A HTTP proxy URL (optional)."
          },
          {
            "name": "disable_http2",
            "description": "Whether to disable HTTP/2. By default, HTTP/2 is enabled."
          },
          {
            "name": "batch_as_multipart",
            "description": "When set to `true`, sends all message in a batch as a single request using https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html[RFC1341^]. \n\nWhen set to `false`, sends messages in a batch as individual requests."
          },
          {
            "name": "parallel",
            "description": "When processing batched messages, this field determines whether messages in the batch are sent in parallel. If set to `false`, messages are sent serially."
          }
        ]
      }
    },
    {
      "name": "insert_part",
      "config": {
        "children": [
          {
            "name": "content",
            "description": "The content of the message being inserted.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "javascript",
      "config": {
        "children": [
          {
            "name": "code",
            "description": "An inline JavaScript program to run. You must specify a value for either the `code` or `file` field."
          },
          {
            "name": "file",
            "description": "A file containing a JavaScript program to run. You must specify a value for either the `code` or `file` field."
          },
          {
            "name": "global_folders",
            "description": "A list of directories to load modules from if the requested JavaScript module is not found elsewhere."
          }
        ]
      }
    },
    {
      "name": "log",
      "config": {
        "children": [
          {
            "name": "message",
            "description": "The message to print.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "metric",
      "config": {
        "children": [
          {
            "name": "labels",
            "description": "A map of label names and values that can be used to enrich metrics. Labels are not supported by some metric destinations, in which case the metrics series are combined.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "value",
            "description": "For some metric types specifies a value to set, increment. Certain metrics exporters such as Prometheus support floating point values, but those that do not will cast a floating point value into an integer.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "mongodb",
      "config": {
        "children": [
          {
            "name": "username",
            "description": "The username required to connect to the database."
          },
          {
            "name": "password",
            "description": "The password required to connect to the database."
          },
          {
            "name": "operation",
            "description": "The MongoDB database operation to perform."
          },
          {
            "name": "write_concern",
            "description": "The https://www.mongodb.com/docs/manual/reference/write-concern/[write concern settings^] for the MongoDB connection.",
            "children": [
              {
                "name": "w",
                "description": "The `w` requests acknowledgement, which write operations propagate to the specified number of MongoDB instances."
              },
              {
                "name": "j",
                "description": "The `j` requests acknowledgement from MongoDB, which is created when write operations are written to the journal."
              }
            ]
          },
          {
            "name": "document_map",
            "description": "A Bloblang map that represents a document to store in MongoDB, expressed as https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/[extended JSON in canonical form^]. The `document_map` parameter is required for the following database operations: `insert-one`, `replace-one`, `update-one`, and `aggregate`."
          },
          {
            "name": "filter_map",
            "description": "A Bloblang map that represents a filter for a MongoDB command, expressed as https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/[extended JSON in canonical form^]. The `filter_map` parameter is required for all database operations except `insert-one`. \n\nThis output uses `filter_map` to find documents for the specified operation. For example, for a `delete-one` operation, the filter map should include the fields required to locate the document for deletion."
          },
          {
            "name": "hint_map",
            "description": "A Bloblang map that represents a hint or index for a MongoDB command to use, expressed as https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/[extended JSON in canonical form^]. This map is optional, and is used with all operations except `insert-one`. \n\nDefine a `hint_map` to improve performance when finding documents in the MongoDB database."
          },
          {
            "name": "upsert",
            "description": "The `upsert` parameter is optional, and only applies for `update-one` and `replace-one` operations. If the filter specified in `filter_map` matches an existing document, this operation updates or replaces the document, otherwise a new document is created."
          },
          {
            "name": "json_marshal_mode",
            "description": "Controls the format of the output message (optional)."
          }
        ]
      }
    },
    {
      "name": "nats_kv",
      "config": {
        "children": [
          {
            "name": "urls",
            "type": "array",
            "description": "A list of URLs to connect to. If a list item contains commas, it will be expanded into multiple URLs."
          },
          {
            "name": "key",
            "description": "The key for each message. Supports https://docs.nats.io/nats-concepts/subjects#wildcards[wildcards^] for the `history` and `keys` operations.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "revision",
            "description": "The revision of the key to operate on. Used for `get_revision` and `update` operations.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "auth",
            "children": [
              {
                "name": "nkey",
                "description": "Your NKey seed or private key."
              },
              {
                "name": "user_credentials_file",
                "description": "An optional file containing user credentials which consist of a user JWT and corresponding NKey seed."
              },
              {
                "name": "user_jwt",
                "description": "An optional plain text user JWT to use along with the corresponding user NKey seed."
              },
              {
                "name": "user_nkey_seed",
                "description": "An optional plain text user NKey seed to use along with the corresponding user JWT."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "nats_request_reply",
      "config": {
        "children": [
          {
            "name": "urls",
            "type": "array",
            "description": "A list of URLs to connect to. If a list item contains commas, it will be expanded into multiple URLs."
          },
          {
            "name": "subject",
            "description": "A subject to write to.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "headers",
            "description": "Explicit message headers to add to messages.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "auth",
            "children": [
              {
                "name": "nkey",
                "description": "Your NKey seed or private key."
              },
              {
                "name": "user_credentials_file",
                "description": "An optional file containing user credentials which consist of a user JWT and corresponding NKey seed."
              },
              {
                "name": "user_jwt",
                "description": "An optional plain text user JWT to use along with the corresponding user NKey seed."
              },
              {
                "name": "user_nkey_seed",
                "description": "An optional plain text user NKey seed to use along with the corresponding user JWT."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "ollama_chat",
      "config": {
        "children": [
          {
            "name": "prompt",
            "description": "The prompt you want to generate a response for. By default, the processor submits the entire payload as a string.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "system_prompt",
            "description": "The system prompt to submit to the Ollama LLM.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "image",
            "description": "An optional image to submit along with the <<prompt, `prompt`>> value. The result is a byte array."
          },
          {
            "name": "response_format",
            "description": "The format of the response the Ollama model generates. If specifying JSON output, then the `prompt` should specify that the output should be in JSON as well."
          },
          {
            "name": "stop",
            "description": "Sets the stop sequences to use. When this pattern is encountered, the LLM stops generating text and returns the final response."
          },
          {
            "name": "save_prompt_metadata",
            "description": "Set to `true` to save the prompt value to a metadata field (`@prompt`) on the corresponding output message. If you use the `system_prompt` field, its value is also saved to an `@system_prompt` metadata field on each output message."
          },
          {
            "name": "history",
            "description": "Include historical messages in a chat request. You must use a Bloblang query to create an array of objects in the form of `[{\"role\": \"\", \"content\":\"\"}]` where:\n\n- `role` is the sender of the original messages, either `system`, `user`, `assistant`, or `tool`.\n- `content` is the text of the original messages."
          },
          {
            "name": "max_tool_calls",
            "description": "The maximum number of sequential calls you can make to external tools to retrieve additional information to answer a prompt."
          },
          {
            "name": "tools",
            "description": "The external tools the LLM can invoke, such as functions, APIs, or web browsing. You can build a series of processors that include definitions of these tools, and the specified LLM can choose when to invoke them to help answer a prompt. For more information, see <<Examples, examples>>."
          },
          {
            "name": "runner",
            "children": [
              {
                "name": "context_size",
                "description": "Sets the size of the context window used to generate the next token. Using a larger context window uses more memory and takes longer to process."
              }
            ]
          },
          {
            "name": "cache_directory",
            "description": "If `server_address` is not set - the directory to download the Ollama binary and use as a model cache."
          },
          {
            "name": "download_url",
            "description": "If `server_address` is not set - the URL to download the Ollama binary from. Defaults to the official Ollama GitHub release for this platform."
          }
        ]
      }
    },
    {
      "name": "ollama_embeddings",
      "config": {
        "children": [
          {
            "name": "text",
            "description": "The text you want to create vector embeddings for. By default, the processor submits the entire payload as a string.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "ollama_moderation",
      "config": {
        "children": [
          {
            "name": "prompt",
            "description": "The prompt you used to generate a response from an LLM.\n\nIf you're using the `ollama_chat` processor, you can set the `save_prompt_metadata` field to save the contents of your prompts. You can then run them through `ollama_moderation` processor to check the model responses for safety. For more details, see <<Examples, Examples>>.\n\nYou can also check the safety of your prompts. For more information, see the xref:components:processors/ollama_chat.adoc#examples[`ollama_chat` processor] documentation.\n\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "response",
            "description": "The LLM's response that you want to check for safety.\n\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "runner",
            "children": [
              {
                "name": "context_size",
                "description": "Sets the size of the context window used to generate the next token. Using a larger context window uses more memory and takes longer to process."
              },
              {
                "name": "gpu_layers",
                "description": "Sets the number of layers to offload to the GPU for computation. This generally results in increased performance. By default, the runtime decides the number of layers dynamically."
              },
              {
                "name": "threads",
                "description": "Sets the number of threads to use during response generation. For optimal performance, set this value to the number of physical CPU cores your system has. By default, the runtime decides the optimal number of threads."
              },
              {
                "name": "use_mmap",
                "description": "Map the model into memory. Set to `true` to load only the necessary parts of the model into memory. This setting is only supported on Unix systems."
              },
              {
                "name": "use_mlock",
                "description": "Set to `true` to lock the model in memory, preventing it from being swapped out when it's mapped into memory. This option can improve performance but reduces the benefits of memory-mapping by increasing RAM usage and slowing model load times."
              }
            ]
          },
          {
            "name": "server_address",
            "description": "The address of the Ollama server to use. Leave this field blank and the processor starts and runs a local Ollama server, or specify the address of your own local or remote server."
          },
          {
            "name": "cache_directory",
            "description": "If the `server_address` is not set, download the Ollama binary to this directory and use it as a model cache."
          },
          {
            "name": "download_url",
            "description": "If `server_address` is not set, download the Ollama binary from this URL. The default value is the official Ollama GitHub release for this platform."
          }
        ]
      }
    },
    {
      "name": "openai_chat_completion",
      "config": {
        "children": [
          {
            "name": "server_address",
            "description": "The OpenAI API endpoint to which the processor sends requests. Update the default value to use a different OpenAI-compatible service."
          },
          {
            "name": "api_key",
            "description": "The API secret key for OpenAI API."
          },
          {
            "name": "prompt",
            "description": "The user prompt for which a response is generated. By default, the processor sends the entire payload as a string unless customized using this field."
          },
          {
            "name": "system_prompt",
            "description": "The system prompt to submit along with the user prompt. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "history",
            "description": "Include messages from a prior conversation. You must use a Bloblang query to create an array of objects in the form of `[{\"role\": \"user\", \"content\": \"<text>\"}, {\"role\":\"assistant\", \"content\":\"<text>\"}]` where:\n\n- `role` is the sender of the original messages, either `system`, `user`, or `assistant`.\n- `content` is the text of the original messages.\n\nFor more information, see <<Examples, Examples>>."
          },
          {
            "name": "image",
            "description": "An optional image to submit along with the prompt. The result of the Bloblang mapping must be a byte array."
          },
          {
            "name": "max_tokens",
            "description": "The maximum number of tokens to generate for chat completion."
          },
          {
            "name": "temperature",
            "description": "Choose a sampling temperature between `0` and `2`: \n\n* Higher values, such as `0.8` make the output more random.\n* Lower values, such as `0.2` make the output more focused and deterministic.\n\nRedpanda recommends adding a value for this field or <<top_p, `top_p`>>, but not both."
          },
          {
            "name": "user",
            "description": "A unique identifier that represents the end-user generating the prompt. This value can help OpenAI monitor and detect https://openai.com/policies/usage-policies/[platform abuse^]. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "response_format",
            "description": "Specify the configured <<model, model's>> output format.\n\nIf you choose the `json_schema` option, you must also configure a `json_schema` or `schema_registry`."
          },
          {
            "name": "json_schema",
            "description": "The JSON schema used by the model when generating responses in `json_schema` format. To learn more about supported JSON schema features, see the https://platform.openai.com/docs/guides/structured-outputs/supported-schemas[OpenAI documentation^].",
            "children": [
              {
                "name": "name",
                "description": "The name of the JSON schema to use."
              },
              {
                "name": "description",
                "description": "An optional description, which helps the model understand the schema's purpose."
              },
              {
                "name": "schema",
                "description": "The JSON schema for the model to use when generating the output."
              }
            ]
          },
          {
            "name": "schema_registry",
            "description": "The schema registry to dynamically load schemas for model responses in `json_schema` format. Schemas must be in JSON format. To learn more about supported JSON schema features, see the https://platform.openai.com/docs/guides/structured-outputs/supported-schemas[OpenAI documentation^].",
            "children": [
              {
                "name": "name_prefix",
                "description": "A prefix to add to the schema registry name. To form the complete schema registry name, the schema ID is appended as a suffix."
              },
              {
                "name": "subject",
                "description": "The subject name used to fetch the schema from the schema registry."
              },
              {
                "name": "refresh_interval",
                "description": "How frequently to poll the schema registry for updates. If not specified, the schema does not refresh automatically."
              },
              {
                "name": "tls",
                "description": "Specify custom TLS settings to override system defaults.",
                "children": [
                  {
                    "name": "skip_cert_verify",
                    "description": "Whether to skip server-side certificate verification."
                  },
                  {
                    "name": "enable_renegotiation",
                    "description": "Whether to allow the remote server to request renegotiation. Enable this option if you're seeing the error message `local error: \ntls: no renegotiation`."
                  },
                  {
                    "name": "root_cas",
                    "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent trusted root certificate, through possible intermediate signing certificates, to the host certificate."
                  },
                  {
                    "name": "root_cas_file",
                    "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, that contains a certificate chain from the parent trusted root certificate, through possible intermediate signing certificates, to the host certificate.certificate."
                  },
                  {
                    "name": "client_certs",
                    "description": "A list of client certificates to use. For each certificate, specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
                  }
                ]
              },
              {
                "name": "oauth",
                "description": "Configure OAuth version 1.0 to give this component authorized access to your schema registry.",
                "children": [
                  {
                    "name": "enabled",
                    "description": "Whether to use OAuth version 1 in requests to the schema registry."
                  },
                  {
                    "name": "consumer_key",
                    "description": "The value used to identify this component or client to your schema registry."
                  },
                  {
                    "name": "consumer_secret",
                    "description": "The secret used to establish ownership of the consumer key."
                  },
                  {
                    "name": "access_token",
                    "description": "The value this component can use to gain access to the data in the schema registry."
                  },
                  {
                    "name": "access_token_secret",
                    "description": "The secret that establishes ownership of the `oauth.access_token`."
                  }
                ]
              },
              {
                "name": "basic_auth",
                "description": "Configure basic authentication for requests from this component to your schema registry.",
                "children": [
                  {
                    "name": "username",
                    "description": "The username of the account credentials to authenticate as."
                  },
                  {
                    "name": "password",
                    "description": "The password of the account credentials to authenticate with."
                  }
                ]
              },
              {
                "name": "jwt",
                "children": [
                  {
                    "name": "private_key_file",
                    "description": "A file in PEM format, encoded using PKCS1 or PKCS8 as private key."
                  },
                  {
                    "name": "signing_method",
                    "description": "The method used to sign the token, such as RS256, RS384, RS512, or EdDSA."
                  },
                  {
                    "name": "claims",
                    "description": "Values used to pass the identity of the authenticated entity to the service provider. In this case, between this component and the schema registry."
                  },
                  {
                    "name": "headers",
                    "description": "The key/value pairs that identify the type of token and signing algorithm (optional)."
                  }
                ]
              }
            ]
          },
          {
            "name": "top_p",
            "description": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. For example, a `top_p` of `0.1` means only the tokens comprising the top 10% probability mass are sampled.\n\nRedpanda recommends adding a value for this field or `temperature`, but not both."
          },
          {
            "name": "frequency_penalty",
            "description": "Specify a number between `-2.0` and `2.0`. Positive values penalize new tokens based on the frequency of their appearance in the text so far. This decreases the model's likelihood to repeat the same line verbatim."
          },
          {
            "name": "presence_penalty",
            "description": "Specify a number between `-2.0` and `2.0`. Positive values penalize new tokens if they have appeared in the text so far. This increases the model's likelihood to talk about new topics."
          },
          {
            "name": "seed",
            "description": "When set to a specific number, Redpanda Connect attempts to generate consistent responses for requests that use the same prompt, seed, and parameters."
          },
          {
            "name": "stop",
            "description": "Specify up to four stop sequences to use. When the model encounters a stop pattern, it stops generating text and returns the final response."
          },
          {
            "name": "tools",
            "description": "External tools the model can invoke, such as functions, APIs, or web browsing. You can build a series of processors that include definitions of these tools, and the specified model can choose when to invoke them to help answer a prompt. For more information, see <<Examples, Examples>>.\n\nNOTE: If you don't want to use external tools, enter an empty array `tools:[]`."
          }
        ]
      }
    },
    {
      "name": "openai_image_generation",
      "config": {
        "children": [
          {
            "name": "quality",
            "description": "The quality of the image to generate. Use `hd` to create images with finer details and greater consistency across the image. This parameter is only supported for `dall-e-3` models.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "size",
            "description": "The size of the generated image. Choose from `256x256`, `512x512`, or `1024x1024` for `dall-e-2`. Choose from `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "style",
            "description": "The style of the generated image. Choose from `vivid` or `natural`. Vivid causes the model to lean towards generating hyperreal and dramatic images. Natural causes the model to produce more natural, less hyperreal looking images. This parameter is only supported for `dall-e-3`.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "openai_speech",
      "config": {
        "children": [
          {
            "name": "voice",
            "description": "The type of voice to use when generating the audio.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "response_format",
            "description": "The format to generate audio in. Default is `mp3`.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "openai_transcription",
      "config": {
        "children": [
          {
            "name": "language",
            "description": "The language of the input audio. Supplying the input language in ISO-639-1 format improves accuracy and latency.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "prompt",
            "description": "Optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "openai_translation",
      "config": {
        "children": [
          {
            "name": "prompt",
            "description": "Optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "parquet_decode",
      "config": {
        "children": [
          {
            "name": "handle_logical_types",
            "description": "Set to `v2` to enable enhanced decoding of logical types, or keep the default value (`v1`) to ignore logical type metadata when decoding values.\n\nIn Parquet format, logical types are represented using standard physical types along with metadata that provides additional context. For example, UUIDs are stored as a `FIXED_LEN_BYTE_ARRAY` physical type, but the schema metadata identifies them as UUIDs. By enabling `v2`, this processor uses the metadata descriptions of logical types to produce more meaningful values during decoding.\n\nNOTE: For backward compatibility, this field enables logical-type handling for the specified Parquet format version, and all earlier versions. When creating new pipelines, Redpanda recommends that you use the newest documented version."
          }
        ]
      }
    },
    {
      "name": "parquet_encode",
      "config": {
        "children": [
          {
            "name": "default_encoding",
            "description": "The default encoding type to use for fields. A custom default encoding is only necessary when consuming data with libraries that do not support `DELTA_LENGTH_BYTE_ARRAY`."
          }
        ]
      }
    },
    {
      "name": "protobuf",
      "config": {
        "children": [
          {
            "name": "operator",
            "description": "The <<operators, operator>> to execute."
          },
          {
            "name": "message",
            "description": "The fully-qualified name of the protobuf message to convert from or to JSON."
          },
          {
            "name": "discard_unknown",
            "description": "When set to `true`, the `from_json` operator discards fields that are unknown to the schema."
          },
          {
            "name": "use_proto_names",
            "description": "When set to `true`, the `to_json` operator deserializes fields exactly as named in schema file."
          },
          {
            "name": "import_paths",
            "description": "A list of directories that contain `.proto` files, including all definitions required for parsing the target message. If left empty, the current directory is used. This processor imports all `.proto` files listed within specified or default directories."
          },
          {
            "name": "use_enum_numbers",
            "description": "When set to `true`, the `to_json` operator deserializes enumeration fields as their numerical values instead of their string names. For example, an enum field with a value of `ENUM_VALUE_ONE` is represented as `1` in the JSON output."
          }
        ]
      }
    },
    {
      "name": "qdrant",
      "config": {
        "children": [
          {
            "name": "api_token",
            "description": "The Qdrant API token to use for authentication, which defaults to an empty string."
          },
          {
            "name": "tls",
            "description": "Specify a secure TLS (HTTPS) connection to the Qdrant server.",
            "children": [
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "enable_renegotiation",
                "description": "Whether to allow the remote server to request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`."
              },
              {
                "name": "root_cas",
                "description": "Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "root_cas_file",
                "description": "Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields."
              }
            ]
          },
          {
            "name": "collection_name",
            "description": "The name of the Qdrant collection you want to query. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "vector_mapping",
            "description": "A mapping to extract search vectors from the returned document."
          },
          {
            "name": "filter",
            "description": "Specify additional filtering to perform on returned results. Mappings must return https://qdrant.tech/documentation/concepts/filtering/[a valid filter^] using the proto3-encoded form."
          },
          {
            "name": "payload_fields",
            "description": "The fields to include or exclude in returned results. Use this field in combination with `payload_filter`."
          },
          {
            "name": "payload_filter",
            "description": "Whether to include or exclude the fields specified in `payload_fields` from the returned results."
          },
          {
            "name": "limit",
            "description": "The maximum number of points to return from the collection."
          }
        ]
      }
    },
    {
      "name": "redis",
      "config": {
        "children": [
          {
            "name": "command",
            "description": "The command to execute.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "redpanda_data_transform",
      "config": {
        "children": [
          {
            "name": "input_key",
            "description": "An optional key to populate for each message.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "retry",
      "config": {
        "children": [
          {
            "name": "backoff",
            "children": [
              {
                "name": "initial_interval",
                "description": "The initial period to wait between retry attempts. The retry interval increases for each failed attempt, up to the `backoff.max_interval` value."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "schema_registry_decode",
      "config": {
        "children": [
          {
            "name": "avro",
            "children": [
              {
                "name": "raw_unions",
                "description": "Whether Avro messages should be decoded into normal JSON (JSON that meets the expectations of regular internet JSON) rather than https://avro.apache.org/docs/current/specification/[Avro JSON^]. \n\nIf set to `false`, Avro messages are decoded as https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodec[Avro JSON^].\n\nFor example, the union schema `[\"null\",\"string\",\"Transaction\"]`, where `Transaction` is a record name, would be decoded as:\n\n- A `null` as a JSON `null`\n- The string `\"a\"` as `{\"string\": \"a\"}`\n- A `Transaction` instance as `{\"Transaction\": {...}}`, where `{...}` indicates the JSON encoding of a `Transaction` instance.\n\nIf set to `true`, Avro messages are decoded as https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodecForStandardJSONFull[standard JSON^].\n\nFor example, the same union schema `[\"null\",\"string\",\"Transaction\"]` is decoded as:\n\n- A `null` as JSON `null`\n- The string `\"a\"` as `\"a\"`\n- A `Transaction` instance as `{...}`, where `{...}` indicates the JSON encoding of a `Transaction` instance.\n\nFor more details on the difference between standard JSON and Avro JSON, see the https://github.com/linkedin/goavro/blob/5ec5a5ee7ec82e16e6e2b438d610e1cab2588393/union.go#L224-L249[comment in Goavro^] and the https://github.com/linkedin/goavro[underlying library used for Avro serialization^]."
              },
              {
                "name": "preserve_logical_types",
                "description": "Choose whether to:\n\n- Transform logical types into their primitive type (default). For example, decimals become raw bytes and timestamps become plain integers.\n- Preserve logical types.\n\nSet to `true` to preserve logical types."
              },
              {
                "name": "mapping",
                "description": "Define a custom mapping to apply to the JSON representation of Avro schemas. You can use mappings to convert custom types emitted by other tools, such as Debezium, into standard Avro types."
              }
            ]
          },
          {
            "name": "cache_duration",
            "description": "The duration after which a cached schema is considered stale and is removed from the cache."
          },
          {
            "name": "oauth",
            "description": "Allows you to specify open authentication using OAuth version 1."
          },
          {
            "name": "jwt",
            "description": "BETA: Allows you to specify JSON Web Token (JWT) authentication.",
            "children": [
              {
                "name": "private_key_file",
                "description": "A file with the PEM encoded using PKCS1 or PKCS8 as private key."
              },
              {
                "name": "signing_method",
                "description": "A method used to sign the token, such as RS256, RS384, RS512 or EdDSA."
              },
              {
                "name": "headers",
                "description": "Add key/value headers to the JWT (optional)."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "schema_registry_encode",
      "config": {
        "children": [
          {
            "name": "subject",
            "description": "The schema subject to derive schemas from.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "avro_raw_json",
            "description": "Whether Avro messages should be parsed as normal JSON (JSON that meets the expectations of regular internet JSON) rather than https://avro.apache.org/docs/current/specification/[Avro JSON^]. \n\nIf set to `false`, the schema returned from the subject is parsed as https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodec[Avro JSON^].\n\nFor example, the union schema `[\"null\",\"string\",\"Transaction\"]`, where `Transaction` is a record name, would be decoded as:\n\n- A `null` as a JSON `null`\n- The string `\"a\"` as `{\"string\": \"a\"}`\n- A `Transaction` instance as `{\"Transaction\": {...}}`, where `{...}` indicates the JSON encoding of a `Transaction` instance.\n\nIf set to `true`, the schema returned from the subject is parsed as https://pkg.go.dev/github.com/linkedin/goavro/v2#NewCodecForStandardJSONFull[standard JSON^].\n\nFor example, the same union schema `[\"null\",\"string\",\"Transaction\"]` is decoded as:\n\n- A `null` as JSON `null`\n- The string `\"a\"` as `\"a\"`\n- A `Transaction` instance as `{...}`, where `{...}` indicates the JSON encoding of a `Transaction` instance.\n\nFor more details on the difference between standard JSON and Avro JSON, see the https://github.com/linkedin/goavro/blob/5ec5a5ee7ec82e16e6e2b438d610e1cab2588393/union.go#L224-L249[comment in Goavro^] and the https://github.com/linkedin/goavro[underlying library used for Avro serialization^]."
          },
          {
            "name": "oauth",
            "description": "Allows you to specify open authentication using OAuth version 1."
          },
          {
            "name": "jwt",
            "description": "BETA: Allows you to specify JSON Web Token (JWT) authentication.",
            "children": [
              {
                "name": "private_key_file",
                "description": "A file with the PEM encoded using PKCS1 or PKCS8 as private key."
              },
              {
                "name": "signing_method",
                "description": "A method used to sign the token, such as RS256, RS384, RS512 or EdDSA."
              },
              {
                "name": "headers",
                "description": "Add key/value headers to the JWT (optional)."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "sentry_capture",
      "config": {
        "children": [
          {
            "name": "message",
            "description": "A message to set on the sentry event\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "tags",
            "description": "Sets key/value string tags on an event. Unlike context, these are indexed and searchable on Sentry but have length limitations.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "slack_thread",
      "config": {
        "children": [
          {
            "name": "bot_token",
            "description": "Your Slack bot user's OAuth token, which must have the correct permissions to read messages from the Slack channel specified in `channel_id`."
          },
          {
            "name": "channel_id",
            "description": "The encoded ID of the Slack channel from which to read threads. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "thread_ts",
            "description": "The timestamp of the parent message of the thread you want to read. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "sleep",
      "config": {
        "children": [
          {
            "name": "duration",
            "description": "The duration of time to sleep for each execution.\nThis field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "sql",
      "config": {
        "children": [
          {
            "name": "query",
            "description": "The query to execute. The style of placeholder to use depends on the driver, some drivers require question marks (`?`) whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2` and so on). The style to use is outlined in this table:\n\ninclude::components:partial$query_table.adoc[]"
          }
        ]
      }
    },
    {
      "name": "sql_insert",
      "config": {
        "children": [
          {
            "name": "dsn",
            "description": "A Data Source Name to identify the target database."
          }
        ]
      }
    },
    {
      "name": "sql_raw",
      "config": {
        "children": [
          {
            "name": "dsn",
            "description": "A Data Source Name to identify the target database."
          },
          {
            "name": "query",
            "description": "The query to execute.\n\nYou must include the correct placeholders for the specified database driver. Some drivers use question marks (`?`), whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2`, and so on). \n\ninclude::components:partial$query_table.adoc[]"
          },
          {
            "name": "args_mapping",
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] that includes the same number of values in an array as the placeholder arguments in the <<query, `query`>> field."
          },
          {
            "name": "exec_only",
            "description": "Whether to discard the <<query, `query`>> result. Set to `true` to leave the message contents unchanged, which is useful when you are executing inserts, updates, and so on. By default, the message contents are kept for the last query executed, and previous queries don't change the results."
          },
          {
            "name": "queries",
            "description": "A list of database statements to run in addition to your main <<query, `query`>>. If you specify multiple queries, they are executed within a single transaction. For more information, see <<Examples, Examples>>."
          }
        ]
      }
    },
    {
      "name": "sql_select",
      "config": {
        "children": [
          {
            "name": "dsn",
            "description": "A Data Source Name to identify the target database."
          }
        ]
      }
    },
    {
      "name": "text_chunker",
      "config": {
        "children": [
          {
            "name": "strategy",
            "description": "Choose a strategy for breaking content down into chunks."
          },
          {
            "name": "chunk_size",
            "description": "The maximum size of each chunk, using the selected <<length_measure,`length_measure`>>."
          },
          {
            "name": "chunk_overlap",
            "description": "The number of characters duplicated in adjacent chunks of text."
          },
          {
            "name": "separators",
            "description": "A list of strings to use as separators between chunks when the <<strategy, `recursive_character` strategy option>> is specified.\n\nBy default, the following separators are tried in turn until one is successful:\n\n- Double newlines (`\n\n`)\n- Single newlines (`\n`)\n- Spaces (`\" \"`,`\"\"`)"
          },
          {
            "name": "length_measure",
            "description": "Choose a method to measure the length of a string."
          },
          {
            "name": "token_encoding",
            "description": "The type of encoding to use for tokenization."
          },
          {
            "name": "allowed_special",
            "description": "A list of special tokens to include in the output from this processor."
          },
          {
            "name": "disallowed_special",
            "description": "A list of special tokens to exclude from the output of this processor."
          },
          {
            "name": "include_code_blocks",
            "description": "When set to `true`, this processor includes code blocks in the output."
          },
          {
            "name": "keep_reference_links",
            "description": "When set to `true`, this processor includes reference links in the output."
          }
        ]
      }
    }
  ],
  "caches": [
    {
      "name": "redpanda",
      "summary": "A Kafka cache implemented using the https://github.com/twmb/franz-go[Franz Kafka client library^].",
      "description": "\nA cache that stores data in a Kafka topic.\n\nThis cache is useful for data that is written frequently and queried infrequently.\nReads from the cache require scanning the entire topic partition. If you expect frequent access, consider placing an in-memory caching layer in front of this one.\n\nBecause only the latest values are needed, configure compaction for topics used as caches so that reads are less expensive when topics are rescanned. See xref:ROOT:manage:cluster-maintenance/compaction-settings.adoc[].\n\nThe cache does not have any time-to-live (TTL) mechanism. Use the Kafka topic retention policies to manage TTL.\n",
      "config": {
        "children": [
          {
            "name": "conn_idle_timeout",
            "description": "The amount of time that connections can remain idle before they are closed."
          },
          {
            "name": "request_timeout_overhead",
            "description": "Additional time to apply as overhead when calculating request deadlines. This buffer helps prevent premature timeouts, especially for requests that already define their own timeout values."
          },
          {
            "name": "seed_brokers",
            "description": "A list of broker addresses to connect to. Items containing commas are expanded into multiple addresses."
          },
          {
            "name": "tls",
            "description": "Use this field for custom TLS settings that override system defaults.",
            "children": [
              {
                "name": "enable_renegotiation",
                "description": "Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you see the error message `local error: tls: no renegotiation`."
              },
              {
                "name": "root_cas_file",
                "description": "An optional file path of a root certificate authority file to use, usually with the .pem extension. This file contains a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate."
              },
              {
                "name": "skip_cert_verify",
                "description": "Whether to skip server-side certificate verification."
              },
              {
                "name": "client_certs",
                "description": "A list of client certificates to use. For each certificate, specify only one of the field pairs `cert` and `key`, or `cert_file` and `key_file`. Do not include both pairs.",
                "children": [
                  {
                    "name": "cert",
                    "description": "The plaintext certificate to use for TLS authentication."
                  },
                  {
                    "name": "cert_file",
                    "description": "The path to a file containing the certificate to use for TLS authentication."
                  },
                  {
                    "name": "key",
                    "description": "The plaintext private key to use for TLS authentication."
                  },
                  {
                    "name": "key_file",
                    "description": "The path to a file containing the private key to use for TLS authentication."
                  },
                  {
                    "name": "password",
                    "description": "The password to use for the private key, if it is encrypted. This field is optional and only required if the private key is encrypted. The PKCS#1 and PKCS#8 formats are supported.\n\nThe `pbeWithMD5AndDES-CBC` algorithm is obsolete and not supported for the PKCS#8 format. This algorithm does not authenticate the ciphertext, making it vulnerable to padding oracle attacks that can let an attacker recover the plaintext."
                  }
                ]
              }
            ]
          },
          {
            "name": "sasl",
            "description": "Specify one or more SASL authentication methods. Each method is tried in the order specified. If the broker supports the first mechanism, outgoing client connections use that mechanism. If the first mechanism fails, the client will use the first supported mechanism. If the broker does not support any client mechanisms, connections will fail.",
            "children": [
              {
                "name": "aws",
                "description": "Contains AWS-specific fields for when <<sasl-mechanism,`sasl.mechanism`>> is set to `AWS_MSK_IAM`.",
                "children": [
                  {
                    "name": "credentials",
                    "description": "Optional manual configuration of AWS credentials to use. For more information, see the xref:guides:cloud/aws.adoc[credentials for AWS] guide.",
                    "children": [
                      {
                        "name": "from_ec2_role",
                        "description": "The credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^]."
                      },
                      {
                        "name": "role",
                        "description": "The ARN of the role to assume."
                      },
                      {
                        "name": "role_external_id",
                        "description": "An external ID to provide when assuming the specified role."
                      },
                      {
                        "name": "token",
                        "description": "The token for the credentials being used. Required only when using short-term credentials."
                      }
                    ]
                  },
                  {
                    "name": "endpoint",
                    "description": "Specify a custom endpoint for the AWS API."
                  },
                  {
                    "name": "mechanism",
                    "description": "The SASL mechanism to use for authentication.",
                    "annotated_options": [
                      [
                        "AWS_MSK_IAM",
                        "AWS IAM based authentication as specified by the 'aws-msk-iam-auth' Java library."
                      ],
                      [
                        "OAUTHBEARER",
                        "OAuth Bearer authentication."
                      ],
                      [
                        "PLAIN",
                        "Plaintext authentication."
                      ],
                      [
                        "SCRAM-SHA-256",
                        "SCRAM authentication as specified in RFC5802."
                      ],
                      [
                        "SCRAM-SHA-512",
                        "SCRAM authentication as specified in RFC5802."
                      ],
                      [
                        "none",
                        "Disable SASL authentication"
                      ]
                    ]
                  },
                  {
                    "name": "password",
                    "description": "The password to use for PLAIN or SCRAM-* authentication."
                  },
                  {
                    "name": "username",
                    "description": "The username to use for PLAIN or SCRAM-* authentication."
                  }
                ]
              }
            ]
          }
        ]
      }
    }
  ]
}