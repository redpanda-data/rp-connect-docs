= MCP Server for Redpanda Connect

Redpanda Connect's MCP (Model Context Protocol) server enables you to expose your pipelines as MCP tools (AI-consumable HTTP endpoints). MCP provides a standardized way for AI systems to interact with tools and services. Learn more about MCP in the link:https://docs.anthropic.com/en/docs/mcp[official documentation^].

In Redpanda Connect, pipelines are declarative YAML files composed of inputs, processors, and outputs.
In MCP, these pipelines are referred to as *tools*, which are discrete units of functionality that AI system can discover and execute through the MCP interface.

Modern AI agents can perform complex tasks, but they need actionable interfaces to interact with real systems. The MCP server provides a simple way to expose your internal tools as structured, typed HTTP endpoints that AI systems can understand and use.

MCP allows you to:

* Expose your tools as structured, typed HTTP endpoints
* Embed metadata and documentation LLMs can parse and understand
* Allow tools to be invoked using natural language with zero prompt engineering

This means you can build *LLM-native* applications where the AI dynamically selects and invokes your tools based on user intent.

== How it works

Each tool is defined as a small, independent unit. Tools are described with metadata and parameters so that AI systems can:

- Discover available capabilities
- Understand tool inputs and outputs
- Construct valid calls programmatically

For example, an internal system that fetches customer data, sends alerts, or generates reports can be exposed as a tool with:

- A unique `label`
- A plain-English `description`
- A structured list of input `properties`

== Key features

[cols="1,3",options="header"]
|===
|Feature |Description

|**AI-optimized tool descriptions**
|Each tool is self-documented in a format that LLMs can read. No extra API docs or plugins required.

|**Minimal surface area**
|Expose only the tools you want, reducing attack and confusion surface.

|**Composability**
|Each tool runs independently over HTTP. They can be composed by the AI into chains or workflows.

|**Fast iteration**
|Define tools as YAML files, reload your server, and your AI agents can use the new logic instantly.
|===

== Example of exposing a search tool

[source,yaml]
----
label: search-bluesky-posts
try:
  - mutation: |
      root.limit = root.limit.number(25)
      root.limit = [ root.limit, 100 ].min()
      root.limit = [ root.limit, 1 ].max()
      meta query_string = "q=" + root.query.escape_url_query() + "&limit=%v".format(root.limit)
      root = ""
  - http:
      url: "https://public.api.bsky.app/xrpc/app.bsky.feed.searchPosts?${! @query_string }"
      verb: GET
  - mapping: 'root = this.posts'
  - unarchive:
      format: json_array

meta:
  tags: [ bluesky, social ]
  mcp:
    enabled: true
    description: Search public Bluesky posts based on a query string.
  properties:
    - name: query
      type: string
      required: true
      description: A Lucene-style query string to search posts.
    - name: limit
      type: number
      description: Number of posts to return (1-100). Defaults to 25.
----

This example defines a tool that searches public Bluesky posts based on a query string. The tool:
- Has a unique `label` for identification
- Provides a clear `description` for LLMs
- Defines structured `properties` for inputs like `query` and `limit`
- Uses a series of processors to build the HTTP request, handle the response, and format the output
- Is tagged with `bluesky` and `social` for discoverability

When this tool is registered with the MCP server, LLMs can invoke it using natural language like "find recent posts about AI on Bluesky" without needing to know the exact API details.

== Best practices for AI tooling

* Use **unique, descriptive labels** and avoid generic patterns like `*-search`
* Write **clear, plain-language descriptions** that explain what the tool does
* Define **structured inputs** so the AI can build correct requests

== Get started

To start using the MCP server, try the xref:agentic-ai:quickstart.adoc[quickstart].

