= Test MCP Examples
:description: Automated testing strategies for Redpanda Connect MCP server examples and best practices.

This document describes the automated testing strategies for Redpanda Connect MCP server examples and best practices documentation.

== MCP tool examples

All MCP tool examples are automatically tested to ensure:

. YAML syntax and structure are correct
. MCP metadata is complete and valid
. Component schemas match Redpanda Connect specifications
. Environment variables are handled gracefully (both `${secrets.X}` and `${X}` syntax)

== Testing approaches

=== Configuration linting

Validate MCP tool configurations using `rpk connect lint`:

[,bash]
----
# Lint a single MCP tool
rpk connect lint resources/processors/weather-api.yaml

# Lint all processor examples
rpk connect lint resources/processors/*.yaml

# Lint with environment variable checking skipped (recommended for MCP)
rpk connect lint --skip-env-var-check resources/processors/*.yaml
----

This checks for common issues such as:

* YAML syntax errors
* Unknown component types
* Invalid field names
* Type mismatches
* Missing required fields

=== MCP metadata validation

The test script validates MCP-specific metadata for all tool examples:

[,bash]
----
# Run all tests (includes linting + MCP validation)
./test-mcp-examples.sh

# Test specific component types
./test-mcp-examples.sh processors
./test-mcp-examples.sh inputs
./test-mcp-examples.sh outputs
----

MCP metadata validation checks:

* Presence of `meta.mcp` section
* `enabled: true` is set
* `description` field exists and is non-empty
* `properties` are properly structured (if present)

=== Unit testing limitations

[IMPORTANT]
====
MCP tool examples are standalone component definitions, not full pipelines with `input:`, `pipeline:`, `output:` sections. This means they cannot use inline `tests:` sections like cookbook examples do.

The `rpk connect test` command requires full pipeline structure with paths like `/pipeline/processors/0`, which don't exist in MCP tool definitions.
====

For testing MCP tools:

Linting is the primary validation:: Ensures syntax and schema correctness.
MCP metadata validation:: Verifies tool has proper description and properties.
Manual testing:: Use `rpk connect mcp-server` to start a server and test tools with an MCP client.

== MCP tool structure

MCP tools are structured as standalone components:

[,yaml]
----
label: fetch-weather
processors:
  - label: prepare_parameters
    mutation: |
      meta city_name = this.city_name

  - label: fetch_weather
    http:
      url: 'https://wttr.in/${! @city_name }?format=j1'
      verb: GET

  - label: format_response
    mutation: |
      root = {
        "city": @city_name,
        "temperature": this.current_condition.0.temp_C.number()
      }

meta:
  mcp:
    enabled: true
    description: "Fetch current weather information for a specified city"
    properties:
      - name: city_name
        type: string
        description: "Name of the city to get weather information for"
        required: true
----

This differs from full pipeline configurations used in cookbooks:

[,yaml]
----
# Cookbook style (full pipeline)
input:
  generate: { ... }

pipeline:
  processors: [ ... ]

output:
  stdout: {}

tests: [ ... ]  # Can use inline tests
----

== Test script usage

The `test-mcp-examples.sh` script provides automated validation:

[,bash]
----
# Test all examples
./test-mcp-examples.sh

# Test specific component types
./test-mcp-examples.sh processors
./test-mcp-examples.sh inputs
./test-mcp-examples.sh outputs
./test-mcp-examples.sh caches
./test-mcp-examples.sh o11y

# Test specific files
./test-mcp-examples.sh resources/processors/weather-*.yaml
----

The script provides color-coded output:

[,console]
----
ğŸ§ª Redpanda Connect MCP Examples Test Suite
============================================

ğŸ“„ Testing: resources/processors/weather-api.yaml (processor)
  Linting weather-api.yaml... PASSED
  Validating MCP metadata... PASSED

============================================
ğŸ“Š Test Summary
============================================
Total configs tested: 7
Passed: 7
Failed: 0

âœ… All tests passed!
----

== Manual end-to-end testing

For comprehensive validation, test MCP tools with an actual MCP server:

[,bash]
----
# Navigate to examples directory
cd modules/ai-agents/examples

# Start MCP server with your tools
rpk connect mcp-server --address localhost:4195

# In another terminal, connect with an MCP client
# Example: Claude Code with mcp-remote
claude mcp add local -- npx mcp-remote http://localhost:4195/sse

# Test your tool through the MCP client
# The tool should appear in the tools list and be invocable
----

This validates:

* Tool loads correctly in MCP server
* MCP metadata is properly exposed
* Tool executes with provided parameters
* Responses are formatted correctly

== GitHub Actions CI/CD

Automated tests run on every push and pull request using GitHub Actions.

The workflow includes two jobs:

. `lint-and-test` tests all examples at once.
. `test-matrix` tests each component type in parallel for faster feedback.

See `.github/workflows/test-mcp-examples.yaml` for the complete workflow.

== Best practices examples

The `best-practices/` directory contains executable examples that demonstrate patterns from the MCP development best practices documentation. Unlike MCP tool definitions, these are full pipelines that can be run directly with `rpk connect run`.

=== Directory structure

[cols="1,2"]
|===
|Directory |Purpose

|`best-practices/input-validation/`
|Input validation patterns (required fields, sanitization, ranges, enums)

|`best-practices/response-formatting/`
|Response formatting patterns (timestamps, arrays, conditional fields, filtering)

|`best-practices/error-handling/`
|Error handling patterns (try/catch, error types, logging, context preservation)
|===

=== Running best practices tests

[,bash]
----
# Navigate to best-practices directory
cd modules/ai-agents/examples/best-practices

# Test all examples
./test-best-practices.sh

# Test specific category
./test-best-practices.sh input-validation
./test-best-practices.sh response-formatting
./test-best-practices.sh error-handling
----

The test script:

. Lints each configuration with `rpk connect lint`
. Runs each pipeline with `rpk connect run`
. Validates successful execution (exit code 0)
. Shows sample output for verification

=== Example output

[,console]
----
ğŸ§ª Redpanda Connect Best Practices Test Suite
==============================================

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ Category: input-validation
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“„ Testing: input-validation/validate-required-field
  Linting... PASSED
  Running... PASSED
    Output: {"city":"London"}...

ğŸ“„ Testing: input-validation/sanitize-string-input
  Linting... PASSED
  Running... PASSED
    Output: {"city":"New York"}...

==============================================
ğŸ“Š Test Summary
==============================================
Total tests: 17
Passed: 17

âœ… All tests passed!
----

=== Best practices example structure

Best practices examples use full pipeline structure with generated test data:

[,yaml]
----
# Test: Input validation pattern
# Expected: Valid input passes, invalid input returns error

input:
  sequence:
    inputs:
      - generate:
          count: 1
          mapping: 'root = {"city": "London"}'      # Valid input
      - generate:
          count: 1
          mapping: 'root = {"city": "  "}'          # Whitespace only
      - generate:
          count: 1
          mapping: 'root = {}'                       # Missing field

pipeline:
  processors:
    - label: validate_input
      mutation: |
        let city = this.city.or("").trim()
        root = if $city == "" {
          {"error": "City name is required"}
        } else {
          {"city": $city}
        }

output:
  stdout: {}
----

The `sequence` input runs multiple test cases through the same pipeline, allowing validation of both success and error paths.

=== CI/CD for best practices

Best practices tests run automatically via GitHub Actions when:

* Files in `best-practices/` are modified
* The test script is updated
* Best practices partials in `partials/mcp/` are changed

See `.github/workflows/test-best-practices.yaml` for the workflow configuration.

== Writing good examples

=== Use descriptive tool names

[,yaml]
----
# Good
label: fetch-customer-orders

# Bad
label: tool1
----

=== Write clear MCP descriptions

[,yaml]
----
# Good
meta:
  mcp:
    description: "Fetch a customer's order history and calculate spending metrics over the last 30 days"

# Bad
meta:
  mcp:
    description: "Get orders"
----

=== Document all properties

[,yaml]
----
# Good
properties:
  - name: customer_id
    type: string
    description: "Unique identifier for the customer"
    required: true
  - name: days
    type: number
    description: "Number of days to look back (default: 30)"
    required: false

# Bad
properties:
  - name: id
    type: string
    required: true
----

=== Use environment variables for secrets

[,yaml]
----
# For Cloud (Secrets Store)
dsn: "${secrets.POSTGRES_DSN}"

# For self-managed Connect (environment variables)
dsn: "${POSTGRES_DSN}"
----

=== Tag your examples

[,yaml]
----
meta:
  tags: [ example, weather, api ]  # Helps organize and filter
  mcp:
    enabled: true
----

== Adding new examples

When adding new MCP tool examples:

. Choose the appropriate directory:
+
[cols="1,2"]
|===
|Directory |Purpose

|`resources/processors/`
|Most MCP tools (data transformations, API calls)

|`resources/inputs/`
|Streaming data sources

|`resources/outputs/`
|Data sinks for batch operations

|`resources/caches/`
|Caching components

|`o11y/`
|Observability configurations (metrics, tracing)
|===

. Include complete MCP metadata:
+
[,yaml]
----
meta:
  mcp:
    enabled: true
    description: "Clear, task-oriented description"
    properties:
      - name: param_name
        type: string
        description: "Parameter purpose and constraints"
        required: true
----

. Lint your example:
+
[,bash]
----
rpk connect lint --skip-env-var-check resources/processors/my-tool.yaml
----

. Run automated tests:
+
[,bash]
----
cd modules/ai-agents/examples
./test-mcp-examples.sh processors
----

. Test manually (recommended):
+
[,bash]
----
rpk connect mcp-server --address localhost:4195
# Connect with MCP client and verify tool works end-to-end
----

. Commit your example:
+
[,bash]
----
git add modules/ai-agents/examples/resources/processors/my-tool.yaml
git commit -m "Add my-tool MCP example"
----