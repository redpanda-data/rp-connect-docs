= MCP Tool Patterns
:description: Cookbook of reusable patterns for building MCP tools with Redpanda Connect.
:page-aliases: ai-agents:mcp-server/pipeline-patterns.adoc
:page-topic-type: cookbook
:personas: ai_agent_developer, data_engineer_pipeline_architect
// Reader journey: "I need an example for X"
:learning-objective-1: Find reusable patterns for common MCP tool scenarios

This cookbook provides reusable patterns for building MCP tools with Redpanda Connect. Use these patterns as building blocks for your own tools.

Use this cookbook to find reusable patterns for common MCP tool scenarios.

Each pattern is a reusable example for a common MCP tool scenario. Patterns are grouped by use case. All YAML is ready to use in your MCP server project.

TIP: For step-by-step instructions, see xref:ai-agents:mcp-server/quickstart.adoc[]. For best practices, see xref:ai-agents:mcp-server/best-practices.adoc[]. For conceptual background, see xref:ai-agents:mcp-server/concepts.adoc[].

== Pattern selection guide

Choose the right pattern for your use case:

* <<data-generators,Generate test data or synthetic events>>
* <<external-api-calls,Call external REST APIs>>
* <<database-queries,Query databases>>
* <<consuming-from-redpanda-topics,Read from Redpanda topics>>
* <<data-transformation,Transform or validate data>>
* <<publishing-to-redpanda-topics,Publish to Redpanda topics>>
* <<stream-processing-with-redpanda-connect,Process streaming data>>
* <<event-driven-workflows,Build event-driven workflows>>
* <<aillm-integration,Integrate with AI/LLM services>>
* <<caching-systems,Cache frequently accessed data>>

== Data generators

Use xref:components:inputs/about.adoc[`inputs`] to create tools that read data from internal or external systems or generate sample data for testing and development.

*When to use:* Development and testing environments where you need synthetic data, load testing scenarios, or demonstrating data flows without real data sources.

*Example use cases:* Mock user events, test order data, synthetic sensor readings, demo data for presentations.

This example generates a realistic user event message:

[source,yaml]
----
include::ai-agents:example$resources/inputs/generate-input.yaml[]
----

See also: xref:components:inputs/generate.adoc[`generate` input component]

== External API calls

Use xref:components:processors/about.adoc[`processors`] to fetch data from external APIs, databases, or services and return formatted results. This is one of the most common patterns for MCP tools.

*When to use:* Integrating with third-party services, fetching real-time data, calling internal microservices, or enriching event data with external information.

*Example use cases:* Fetch user profile from CRM, get product pricing from inventory API, validate addresses with geocoding service, retrieve weather data.

[source,yaml]
----
include::ai-agents:example$resources/processors/weather-api.yaml[]
----

See also: xref:components:processors/http.adoc[`http` processor], xref:components:processors/mutation.adoc[`mutation` processor]

== Database queries

Query external databases and return structured results. This pattern is essential for tools that need to access business data.

*When to use:* Retrieving customer records, querying analytics data, looking up configuration values, or joining streaming data with dimensional data from data warehouses.

*Example use cases:* Fetch customer details from PostgreSQL, query sales data from BigQuery, retrieve product catalog from MongoDB, look up reference data.

NOTE: This example requires setting the `DATABASE_URL` environment variable with your PostgreSQL connection string. For example, `export DATABASE_URL="postgres://user:password@localhost:5432/dbname"`.

[source,yaml]
----
include::ai-agents:example$resources/processors/database-query.yaml[]
----

See also: xref:components:processors/sql_select.adoc[`sql_select` processor]

== Redpanda integration and data publishing

Build tools that interact with Redpanda topics to publish data, consume events, or stream processing results back to topics for other systems to consume.

NOTE: The examples in this section require setting the `REDPANDA_BROKERS` environment variable with your Redpanda broker addresses. For example, `export REDPANDA_BROKERS="localhost:19092"`.

[[publishing-to-redpanda-topics]]
=== Publish to Redpanda topics

Create tools that write data to Redpanda topics using the `redpanda` output.

*When to use:* Publishing events to Redpanda for consumption by other services, creating event sourcing patterns, building audit trails, or triggering downstream workflows.

*Example use cases:* Publish order confirmations, emit audit events, trigger notifications, create event-driven workflows.

[source,yaml]
----
include::ai-agents:example$resources/outputs/redpanda-publish.yaml[]
----

[[outputs-with-processors]]
==== Outputs with processors

Output tools can include processors to transform data before publishing. This pattern is useful when you need to process data and save the result to a destination in a single tool.

*When to use:* Processing user input with an LLM and saving the response, transforming data before publishing to a topic, enriching events before writing to external systems.

*Example use cases:* Send a prompt to an LLM, then save the answer to a topic in Redpanda.

[source,yaml]
----
include::ai-agents:example$resources/outputs/redpanda-output-with-processors.yaml[]
----

[[consuming-from-redpanda-topics]]
=== Consume from Redpanda topics

Build tools that read data from topics and return processed results.

*When to use:* Processing events from Redpanda topics, building event-driven AI agents, consuming audit logs, or subscribing to data change streams.

*Example use cases:* Monitor order events, process user activity streams, consume IoT sensor data, react to system notifications.

[source,yaml]
----
include::ai-agents:example$resources/inputs/redpanda-consume.yaml[]
----

== Data transformation

Transform, validate, and enrich data as it flows through your MCP tools. Use Bloblang mapping language for powerful data manipulation.

*When to use:* Converting data formats, validating schemas, filtering events, enriching messages with computed fields, or normalizing data structures.

*Example use cases:* Parse JSON payloads, validate required fields, add timestamps, convert units, mask sensitive data, aggregate nested objects.

[source,yaml]
----
mapping: |
  # Parse and validate incoming data
  root.user_id = this.user_id.or(throw("user_id is required"))
  root.timestamp = now().ts_format("2006-01-02T15:04:05Z07:00")

  # Transform and enrich
  root.email_domain = this.email.split("@").index(1)
  root.is_premium = this.subscription_tier == "premium"

  # Filter sensitive data
  root.profile = this.profile.without("ssn", "credit_card")
----

See also: xref:components:processors/mapping.adoc[`mapping` processor], xref:guides:bloblang/about.adoc[Bloblang guide]

== Stream processing with Redpanda Connect

Create tools that process streaming data and return aggregated results.

*When to use:* Real-time analytics, windowed aggregations, computing metrics over time, or building streaming dashboards.

*Example use cases:* Calculate rolling averages, count events per time window, detect anomalies in streams, aggregate metrics.

[source,yaml]
----
include::ai-agents:example$resources/inputs/stream-analytics.yaml[]
----

== Event-driven workflows

Build tools that trigger workflows based on Redpanda events.

*When to use:* Orchestrating multi-step processes, responding to business events, implementing saga patterns, or coordinating microservices.

*Example use cases:* Order fulfillment workflows, approval processes, notification cascades, data pipeline orchestration.

[source,yaml]
----
include::ai-agents:example$resources/inputs/event-workflow.yaml[]
----

See also: xref:components:inputs/redpanda.adoc[`redpanda` input]

== AI/LLM integration

Integrate AI and LLM services into your MCP tools for intelligent data processing, embeddings generation, and natural language understanding.

*When to use:* Generating embeddings for semantic search, calling LLM APIs for text generation, building RAG (Retrieval Augmented Generation) pipelines, or analyzing sentiment.

*Example use cases:* Generate embeddings for documents, classify customer feedback, summarize long text, extract entities, answer questions with context.

=== OpenAI integration

Use the `openai_chat_completion` processor to call OpenAI models:

[source,yaml]
----
openai_chat_completion:
  api_key: "${OPENAI_API_KEY}"
  model: "gpt-4"
  prompt: |
    Analyze this customer feedback and provide:
    1. Sentiment (positive/negative/neutral)
    2. Key themes
    3. Actionable insights

    Feedback: ${! json("feedback_text") }
  max_tokens: 500
----

See also: xref:components:processors/openai_chat_completion.adoc[`openai_chat_completion`], xref:components:processors/openai_embeddings.adoc[`openai_embeddings`]

=== Embeddings generation

Generate vector embeddings for semantic search and RAG pipelines:

[source,yaml]
----
openai_embeddings:
  api_key: "${OPENAI_API_KEY}"
  model: "text-embedding-3-small"
  text: ${! json("content") }
----

See also: xref:components:processors/cohere_embeddings.adoc[`cohere_embeddings`], xref:components:processors/gcp_vertex_ai_embeddings.adoc[`gcp_vertex_ai_embeddings`]

== Caching systems

Use caching to store frequently accessed data, reduce latency, and minimize external API calls. You can implement caching using either Redpanda topics or in-memory stores.

*When to use:* Reducing repeated API calls, storing lookup tables, caching database query results, or maintaining session state across tool invocations.

*Example use cases:* Cache user profiles, store API rate limit counters, maintain configuration values, cache product catalogs.

Use an in-memory cache for low-latency access to small datasets:

[source,yaml]
----
memory:
  default_ttl: 300s
  compaction_interval: 60s
----

See also: xref:components:caches/memory.adoc[`memory` cache], Redpanda-backed cache using xref:components:outputs/redpanda.adoc[`redpanda` output]

// Production workflows section - single-sourced from partial
include::ai-agents:partial$mcp/production-workflows.adoc[]

NOTE: The multi-step enrichment example requires setting the `POSTGRES_DSN` environment variable with your PostgreSQL connection string. For example, `export POSTGRES_DSN="postgres://user:password@localhost:5432/dbname"`.

== Next steps

* xref:ai-agents:mcp-server/create-tool.adoc[]: Step-by-step tool creation guide
* xref:ai-agents:mcp-server/best-practices.adoc[]: Apply naming and design guidelines
* xref:ai-agents:mcp-server/troubleshooting.adoc[]: Diagnose common issues
