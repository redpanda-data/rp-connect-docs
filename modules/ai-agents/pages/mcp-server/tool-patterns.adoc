= MCP Tool Patterns
:description: Cookbook of reusable patterns for building MCP tools with Redpanda Connect.
:page-aliases: ai-agents:mcp-server/pipeline-patterns.adoc
:page-topic-type: cookbook
:personas: ai_agent_developer, data_engineer
// Reader journey: "I need an example for X"
:learning-objective-1: Find reusable patterns for common MCP tool scenarios
:learning-objective-2: Apply validation and error handling patterns for production robustness
:learning-objective-3: Format responses consistently for AI client consumption

When building tools, use these patterns as starting points for common scenarios. For step-by-step instructions, see xref:ai-agents:mcp-server/create-tool.adoc[]. For design guidelines, see xref:ai-agents:mcp-server/best-practices.adoc[].

After reading this page, you will be able to:

* [ ] {learning-objective-1}
* [ ] {learning-objective-2}
* [ ] {learning-objective-3}



[[read-data]]
== Read data

Use xref:components:inputs/about.adoc[inputs] to create tools that read from data sources or generate sample data.

[[data-generators]]
=== Generate test data

*When to use:* Development and testing environments where you need synthetic data, load testing scenarios, or demonstrating data flows without real data sources.

*Example use cases:* Mock user events, test order data, synthetic sensor readings, demo data for presentations.

[source,yaml]
----
include::ai-agents:example$resources/inputs/generate-input.yaml[]
----

See also: xref:components:inputs/generate.adoc[`generate` input component]

[[consume-from-redpanda]]
=== Consume from Redpanda topics

*When to use:* Processing events from Redpanda topics, building event-driven AI agents, consuming audit logs, or subscribing to data change streams.

*Example use cases:* Monitor order events, process user activity streams, consume IoT sensor data, react to system notifications.

NOTE: This example requires setting the `REDPANDA_BROKERS` environment variable with your Redpanda broker addresses.

[source,yaml]
----
include::ai-agents:example$resources/inputs/redpanda-consume.yaml[]
----

[[stream-processing]]
=== Process streaming data

*When to use:* Real-time analytics, windowed aggregations, computing metrics over time, or building streaming dashboards.

*Example use cases:* Calculate rolling averages, count events per time window, detect anomalies in streams, aggregate metrics.

[source,yaml]
----
include::ai-agents:example$resources/inputs/stream-analytics.yaml[]
----

[[call-external-services]]
== Call external services

Use xref:components:processors/about.adoc[processors] to fetch data from external APIs, databases, or AI services.

[[external-api-calls]]
=== Call REST APIs

*When to use:* Integrating with third-party services, fetching real-time data, calling internal microservices, or enriching event data with external information.

*Example use cases:* Fetch user profile from CRM, get product pricing from inventory API, validate addresses with geocoding service, retrieve weather data.

[source,yaml]
----
include::ai-agents:example$resources/processors/weather-api.yaml[]
----

See also: xref:components:processors/http.adoc[`http` processor], xref:components:processors/mutation.adoc[`mutation` processor]

[[database-queries]]
=== Query databases

*When to use:* Retrieving customer records, querying analytics data, looking up configuration values, or joining streaming data with dimensional data from data warehouses.

*Example use cases:* Fetch customer details from PostgreSQL, query sales data from BigQuery, retrieve product catalog from MongoDB, look up reference data.

NOTE: This example requires setting the `DATABASE_URL` environment variable with your PostgreSQL connection string.

[source,yaml]
----
include::ai-agents:example$resources/processors/database-query.yaml[]
----

See also: xref:components:processors/sql_select.adoc[`sql_select` processor]

[[jira-queries]]
=== Query Jira issues

*When to use:* Fetching tickets by status, checking assignments, finding recent issues, or building AI agents that interact with project management data.

*Example use cases:* Get open bugs for a sprint, find issues assigned to a user, list recently updated tickets, search by custom fields.

NOTE: The `jira` processor requires an Enterprise license. For more information, see xref:get-started:licensing.adoc[].

[source,yaml]
----
label: search-jira

processors:
  - generate:
      count: 1
      mapping: |
        root.jql = this.jql
        root.maxResults = this.max_results.or(50)
        root.fields = ["key", "summary", "status", "assignee", "priority"]
  - jira:
      base_url: "${JIRA_BASE_URL}"
      username: "${JIRA_USERNAME}"
      api_token: "${JIRA_API_TOKEN}"

meta:
  mcp:
    enabled: true
    description: "Search Jira issues using JQL. Returns matching issues with key, summary, status, assignee, and priority."
    properties:
      - name: jql
        type: string
        description: "JQL query (e.g., 'project = DOC AND status = Open')"
        required: true
      - name: max_results
        type: number
        description: "Maximum issues to return (default: 50)"
        required: false
----

For more patterns including pagination, custom fields, and creating issues via the HTTP processor, see xref:cookbooks:jira.adoc[].

[[ai-llm-integration]]
=== Integrate with AI/LLM services

*When to use:* Generating embeddings for semantic search, calling LLM APIs for text generation, building RAG pipelines, or analyzing sentiment.

*Example use cases:* Generate embeddings for documents, classify customer feedback, summarize long text, extract entities, answer questions with context.

==== OpenAI chat completion

[source,yaml]
----
openai_chat_completion:
  api_key: "${OPENAI_API_KEY}"
  model: "gpt-4"
  prompt: |
    Analyze this customer feedback and provide:
    1. Sentiment (positive/negative/neutral)
    2. Key themes
    3. Actionable insights

    Feedback: ${! json("feedback_text") }
  max_tokens: 500
----

See also: xref:components:processors/openai_chat_completion.adoc[`openai_chat_completion`], xref:components:processors/openai_embeddings.adoc[`openai_embeddings`]

==== Generate embeddings

[source,yaml]
----
openai_embeddings:
  api_key: "${OPENAI_API_KEY}"
  model: "text-embedding-3-small"
  text: ${! json("content") }
----

See also: xref:components:processors/cohere_embeddings.adoc[`cohere_embeddings`], xref:components:processors/gcp_vertex_ai_embeddings.adoc[`gcp_vertex_ai_embeddings`]

[[write-data]]
== Write data

Use xref:components:outputs/about.adoc[outputs] to write data to Redpanda topics or cache stores.

[[publish-to-redpanda]]
=== Publish to Redpanda topics

*When to use:* Publishing events to Redpanda for consumption by other services, creating event sourcing patterns, building audit trails, or triggering downstream workflows.

*Example use cases:* Publish order confirmations, emit audit events, trigger notifications, create event-driven workflows.

NOTE: This example requires setting the `REDPANDA_BROKERS` environment variable.

[source,yaml]
----
include::ai-agents:example$resources/outputs/redpanda-publish.yaml[]
----

==== Outputs with processors

Output tools can include processors to transform data before publishing. This pattern is useful when you need to process data and save the result to a destination in a single tool.

*When to use:* Processing user input with an LLM and saving the response, transforming data before publishing to a topic, enriching events before writing to external systems.

[source,yaml]
----
include::ai-agents:example$resources/outputs/redpanda-output-with-processors.yaml[]
----

[[caching]]
=== Cache data

*When to use:* Reducing repeated API calls, storing lookup tables, caching database query results, or maintaining session state across tool invocations.

*Example use cases:* Cache user profiles, store API rate limit counters, maintain configuration values, cache product catalogs.

[source,yaml]
----
memory:
  default_ttl: 300s
  compaction_interval: 60s
----

See also: xref:components:caches/memory.adoc[`memory` cache], xref:components:outputs/redpanda.adoc[`redpanda` output]

[[transform-data]]
== Transform data

Use Bloblang and processors to transform, validate, and route data.

[[data-transformation]]
=== Transform and validate

*When to use:* Converting data formats, validating schemas, filtering events, enriching messages with computed fields, or normalizing data structures.

*Example use cases:* Parse JSON payloads, validate required fields, add timestamps, convert units, mask sensitive data, aggregate nested objects.

[source,yaml]
----
mapping: |
  # Parse and validate incoming data
  root.user_id = this.user_id.or(throw("user_id is required"))
  root.timestamp = now().ts_format("2006-01-02T15:04:05Z07:00")

  # Transform and enrich
  root.email_domain = this.email.split("@").index(1)
  root.is_premium = this.subscription_tier == "premium"

  # Filter sensitive data
  root.profile = this.profile.without("ssn", "credit_card")
----

See also: xref:components:processors/mapping.adoc[`mapping` processor], xref:guides:bloblang/about.adoc[Bloblang guide]

[[event-driven-workflows]]
=== Build event-driven workflows

*When to use:* Orchestrating multi-step processes, responding to business events, implementing saga patterns, or coordinating microservices.

*Example use cases:* Order fulfillment workflows, approval processes, notification cascades, data pipeline orchestration.

[source,yaml]
----
include::ai-agents:example$resources/inputs/event-workflow.yaml[]
----

See also: xref:components:inputs/redpanda.adoc[`redpanda` input]

[[production-readiness]]
== Production readiness

Build production-ready tools with proper input validation, error handling, and response formatting.

[[input-validation]]
=== Validate input

AI clients may send unexpected or malformed input. Validate early to return helpful error messages instead of cryptic failures from downstream components.

include::ai-agents:partial$mcp/tool-patterns/input-validation.adoc[leveloffset=+1]

[[error-handling]]
=== Handle errors

External services fail. Databases go down. APIs return unexpected responses. Wrap risky operations in error handling so your tool returns useful error messages instead of crashing.

include::ai-agents:partial$mcp/tool-patterns/error-handling.adoc[leveloffset=+1]

[[response-formatting]]
=== Format responses

AI clients work best with clean, predictable response structures. Transform raw component output into consistent formats.

include::ai-agents:partial$mcp/tool-patterns/response-formatting.adoc[leveloffset=+1]

// Production workflows section - single-sourced from partial
include::ai-agents:partial$mcp/tool-patterns/production-workflows.adoc[]

NOTE: The multi-step enrichment example requires setting the `POSTGRES_DSN` environment variable with your PostgreSQL connection string.

== Next steps

* xref:ai-agents:mcp-server/create-tool.adoc[]: Step-by-step tool creation guide
* xref:ai-agents:mcp-server/best-practices.adoc[]: Apply naming and design guidelines
* xref:ai-agents:mcp-server/troubleshooting.adoc[]: Diagnose common issues
