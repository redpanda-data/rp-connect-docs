processors:
  label: ""
  ollama_chat:
    model: "" # No default (required)
    prompt: "" # No default (optional)
    image: "" # No default (optional)
    response_format: text
    max_tokens: "" # No default (optional)
    temperature: "" # No default (optional)
    save_prompt_metadata: false
    history: "" # No default (optional)
    tools:
      name: "" # No default (required)
      description: "" # No default (required)
      parameters:
        required: []
        properties:
          type: "" # No default (required)
          description: "" # No default (required)
          enum: []
      processors: [] # No default (optional)
    runner:
      context_size: "" # No default (optional)
      batch_size: "" # No default (optional)
      gpu_layers: "" # No default (optional)
      threads: "" # No default (optional)
      use_mmap: "" # No default (optional)
    server_address: "" # No default (optional)