= kafka
// tag::single-source[]
:type: input
:status: deprecated
:categories: ["Services"]

// Â© 2024 Redpanda Data Inc.


component_type_dropdown::[]

[WARNING]
.Deprecated in 4.68.0
====
This component is deprecated and will be removed in the next major version release. Please consider moving onto the unified xref:components:inputs/redpanda.adoc[`redpanda` input] and xref:components:outputs/redpanda.adoc[`redpanda` output] components.
====


Connects to Kafka brokers and consumes one or more topics.


[tabs]
======
Common::
+
--

```yml
include::components:example$common/inputs/kafka.yaml[]
```

--
Advanced::
+
--

```yml
include::components:example$advanced/inputs/kafka.yaml[]
```

--
======

Offsets are managed within Kafka under the specified consumer group, and partitions for each topic are automatically balanced across members of the consumer group.

The Kafka input allows parallel processing of messages from different topic partitions, and messages of the same topic partition are processed with a maximum parallelism determined by the field <<checkpoint_limit,`checkpoint_limit`>>.

To enforce ordered processing of partition messages, set the <<checkpoint_limit,`checkpoint_limit`>> to `1`, which makes sure that a message is only processed after the previous message is delivered.

Batching messages before processing can be enabled using the <<batching,`batching`>> field, and this batching is performed per-partition such that messages of a batch will always originate from the same partition. This batching mechanism is capable of creating batches of greater size than the <<checkpoint_limit,`checkpoint_limit`>>, in which case the next batch will only be created upon delivery of the current one.

== Metadata

This input adds the following metadata fields to each message:

- kafka_key
- kafka_topic
- kafka_partition
- kafka_offset
- kafka_lag
- kafka_timestamp_ms
- kafka_timestamp_unix
- kafka_tombstone_message
- All existing message headers (version 0.11+)

The field `kafka_lag` is the calculated difference between the high water mark offset of the partition at the time of ingestion and the current message offset.

You can access these metadata fields using xref:configuration:interpolation.adoc#bloblang-queries[function interpolation].

== Ordering

By default messages of a topic partition can be processed in parallel, up to a limit determined by the field `checkpoint_limit`. However, if strict ordered processing is required then this value must be set to 1 in order to process shard messages in lock-step. When doing so it is recommended that you perform batching at this component for performance as it will not be possible to batch lock-stepped messages at the output level.

== Troubleshooting

If you're seeing issues writing to or reading from Kafka with this component then it's worth trying out the newer xref:components:inputs/kafka_franz.adoc[`kafka_franz` input].

- I'm seeing logs that report `Failed to connect to kafka: kafka: client has run out of available brokers to talk to (Is your cluster reachable?)`, but the brokers are definitely reachable.

Unfortunately this error message will appear for a wide range of connection problems even when the broker endpoint can be reached. Double check your authentication configuration and also ensure that you have <<tlsenabled, enabled TLS>> if applicable.

include::redpanda-connect:components:partial$fields/inputs/kafka.adoc[]

// end::single-source[]