= postgres_cdc
:page-aliases: components:inputs/pg_stream.adoc
// tag::single-source[]
:type: input
:categories: ["Services"]

component_type_dropdown::[]

Streams data changes from a PostgreSQL database using logical replication. There is also a configuration option to <<stream_snapshot,stream all existing data>> from the database.

ifndef::env-cloud[]
Introduced in version 4.40.0 and renamed from `pg_stream` to `postgres_cdc` in version 4.43.0.
endif::[]

```yml
include::components:example$common/inputs/postgres_cdc.yaml[]
```

The `postgres_cdc` input uses logical replication to capture changes made to a PostgreSQL database in real time and streams them to Redpanda Connect. Redpanda Connect uses this replication method to allow you to choose which database tables in your source database to receive changes from. There are also <<choose-a-replication-mode,two replication modes>> to choose from, and an <<receive-toast-and-deleted-values,option to receive TOAST and deleted values>> in your data updates.

== Prerequisites

- PostgreSQL version 13 or later
ifdef::env-cloud[]
- Network access from the cluster where your Redpanda Connect pipeline is running to the source database environment. For detailed networking information, including how to set up a VPC peering connection, see xref:networking:index.adoc[Redpanda Cloud Networking].
endif::[]
- Logical replication enabled on your PostgreSQL cluster
+
To check whether logical replication is already enabled, run the following query:
+
[,SQL]
----
SHOW wal_level;
----
+
If the `wal_level` value is `logical`, you can start to use this connector. Otherwise, choose from the following sets of instructions to update your replication settings.


[tabs]
=====
Cloud platforms::
+
--
- https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/PostgreSQL.Concepts.General.FeatureSupport.LogicalReplication.html[Amazon RDS for PostgreSQL DB^]
- https://learn.microsoft.com/en-us/azure/postgresql/flexible-server/concepts-logical#prerequisites-for-logical-replication-and-logical-decoding[Azure Database for PostgreSQL^]
- https://cloud.google.com/sql/docs/postgres/replication/configure-logical-replication[Google Cloud SQL for PostgreSQL^], including creating a user with replication privileges
- https://neon.tech/docs/guides/logical-replication-guide[Neon^]

--
Self-Hosted PostgreSQL::
+
--
Use an account with sufficient permissions (superuser) to update your replication settings.

. Open the `postgresql.conf` file.
. Find the `wal_level` parameter.
. Update the parameter value to `wal_level = logical`. If you already use replication slots, you may need to increase the limit on replication slots (`max_replication_slots`). The `max_wal_senders` parameter value must also be greater than or equal to `max_replication_slots`.
. Restart the PostgreSQL server.

For this input to make a successful connection to your database, also make sure that it allows replication connections.

. Open the `pg_hba.conf` file.
. Update this line.

+
[source,yaml]
----
host    replication     <replication-username>   <connector-ip>/32    md5
----

+
Replace the following placeholders with your own values:

- `<replication-username>`: The username from an account with superuser privileges.
- `<connector-ip>`: The IP address of the server where you are running Redpanda Connect.

. Restart the PostgreSQL server.
--
=====

== Choose a replication mode

When you run a pipeline that uses the `postgres_cdc` input, Redpanda Connect connects to your PostgreSQL database and creates a replication slot. The replication slot uses a copy of the Write-Ahead Log (WAL) file to subscribe to changes in your database records as they are applied to the database. There are two replication modes you can choose from: snapshot mode and streaming mode.

In snapshot mode, Redpanda Connect first takes a snapshot of the database and streams the contents before processing changes from the WAL. In streaming mode, Redpanda Connect directly processes changes from the WAL starting from the most recent changes without taking a snapshot first.

For local testing, you can use the <<example-pipeline,example pipeline on this page>>, which runs in snapshot mode.

=== Snapshot mode

If you set the <<stream_snapshot,`stream_snapshot` field>> to `true`, Redpanda Connect:

. Creates a snapshot of your database.
. Streams the contents of the tables specified in the `postgres_cdc` input.
. Starts processing changes in the WAL that occurred since the snapshot was taken, and streams them to Redpanda Connect. 

Once the initial replication process is complete, the snapshot is removed and the input keeps a connection open to the database so that it can receive data updates.

If the pipeline restarts during the replication process, Redpanda Connect resumes processing data changes from where it left off. If there are other interruptions while the snapshot is taken, you may need to restart the snapshot process. For more information, see <<troubleshoot_replication_failures,Troubleshoot replication failures>>.

=== Streaming mode

If you set the <<stream_snapshot,`stream_snapshot` field>> to `false`, Redpanda Connect starts processing data changes from the end of the WAL. If the pipeline restarts, Redpanda Connect resumes processing data changes from the last acknowledged position in the WAL.

== Monitor the replication process

You can monitor the initial replication of data using the following metrics:

|===
| Metric name | Description

| `replication_lag_bytes`
| Indicates how far the connector is lagging behind the source database when processing the transaction log.

| `postgres_snapshot_progress`
| Shows the progress of snapshot processing for each table.

|===


== Troubleshoot replication failures

If the database snapshot fails, the replication slot has only an incomplete record of the existing data in your database. To maintain data integrity, you must drop the replication slot manually in your source database and run the Redpanda Connect pipeline again.

```SQL
SELECT pg_drop_replication_slot(SLOT_NAME);
```

== Receive TOAST and deleted values

For full visibility of all data updates, you can also choose to stream https://www.postgresql.org/docs/current/storage-toast.html[TOAST^] and deleted values. To enable this option, run the following query on your source database:

```SQL
ALTER TABLE large_data REPLICA IDENTITY FULL;
```

== Data mappings

The following table shows how selected PostgreSQL data types are mapped to data types supported in Redpanda Connect. All other data types are mapped to string values.

|===
| PostgreSQL data type | Bloblang value

| TEXT, TIMESTAMP, UUID, VARCHAR
| JSON strings, for example: `this data`

| BOOL
| Boolean JSON fields, for example: `true` or `false`

| Numeric types (INT4)
| JSON number types, for example: `1`.

| JSONB
| JSON objects, for example: `{ "message": "message text" }`

| INTEGER[] 
| An array of integer values, for example: `[1,2,3]`

| TEXT[]
| An array of string values, for example: `["value1", "value2", "value3"]`

| INET 
| A string that contains an IP address, for example: `"192.168.1.1"`

| POINT
| A string that represents a point in a two-dimensional plane, for example: `(x, y)`

| TSRANGE
| A string that includes range bounds, for example: `[2010-01-01 14:30, 2010-01-01 15:30)`

| TSVECTOR
| A string that includes vector data, for example: `"'the':2 'question':3 'is':4"`

|===

== Metadata

This input adds the following metadata fields to each message:

- `table`: The name of the database table from which the message originated.
- `operation`: The type of database operation that generated the message, such as `read`, `insert`, `update`, `delete`, `begin` and `commit`. A `read` operation occurs when a snapshot of the database is processed. The `begin` and `commit` operations are only included if the `include_transaction_markers` field is set to `true`.
- `lsn`: The https://www.postgresql.org/docs/current/datatype-pg-lsn.html[Log Sequence Number^] of each data update from the source PostgreSQL database. The `lsn` values are strings that can be sorted to determine the order in which data updates were written to the WAL.

include::redpanda-connect:components:partial$fields/inputs/postgres_cdc.adoc[]

== Example pipeline

You can run the following pipeline locally to check that data updates are streamed from your source database to Redpanda Connect. All transactions are written to stdout.

```yml
input:
  label: "postgres_cdc"
  postgres_cdc:
    dsn: postgres://user:password@host:port/dbname
    include_transaction_markers: false
    slot_name: test_slot_native_decoder
    snapshot_batch_size: 100000
    stream_snapshot: true
    temporary_slot: true
    schema: schema_name
    tables:
      - table_name

cache_resources:
  - label: data_caching
    file:
      directory: /tmp/cache

output:
  label: main
  stdout: {}
```

// end::single-source[]
