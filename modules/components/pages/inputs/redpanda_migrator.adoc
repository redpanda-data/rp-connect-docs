= redpanda_migrator
:page-aliases: components:inputs/kafka_migrator.adoc
// tag::single-source[]
:type: input
:status: experimental
:categories: ["Services"]

component_type_dropdown::[]

Unified Kafka consumer for migrating data between Kafka/Redpanda clusters. Use this input with the xref:components:outputs/redpanda_migrator.adoc[`redpanda_migrator` output] to safely transfer topic data, ACLs, schemas, and consumer group offsets between clusters. This component is designed for migration scenarios.

ifndef::env-cloud[]
Introduced in version 4.67.5.
endif::[]

[tabs]
======
Common::
+
--

```yml
include::components:example$common/inputs/redpanda_migrator.yaml[]
```

--
Advanced::
+
--

```yml
include::components:example$advanced/inputs/redpanda_migrator.yaml[]
```

--
======

The `redpanda_migrator` input:

* Reads a batch of messages from a broker.
* Waits for the `redpanda_migrator` output to acknowledge the writes before updating the Kafka consumer group offset.
* Provides the same delivery guarantees and ordering semantics as the xref:components:inputs/redpanda.adoc[`redpanda` input].

Specify a consumer group to make this input consume one or more topics and automatically balance the topic partitions across any other connected clients with the same consumer group. Otherwise, topics are consumed in their entirety or with explicit partitions.

This input requires a corresponding `redpanda_migrator` output in the same pipeline. Each pipeline must have both input and output components configured.
For capabilities, guarantees, scheduling, and examples, see the output documentation.

== Requirements

* Must be paired with a `redpanda_migrator` output in the same pipeline.
* Requires access to a source Kafka or Redpanda cluster.
* Consumer group configuration is recommended for partition balancing.

== Multiple migrator pairs
When using multiple migrator pairs in a single pipeline, coordination is based on the `label` field. The label of the input and output must match exactly for correct pairing. If labels do not match, migration fails for that pair.

== Performance tuning for high throughput

For workloads with high message rates or large messages, adjust the following settings to optimize throughput:

On this input component:

- `partition_buffer_bytes`: Set to 2MB to increase per-partition buffer size
- `max_yield_batch_bytes`: Set to 1MB to allow larger batches to be yielded

On the paired `redpanda_migrator` output component:

- `max_in_flight`: Set to the total number of partitions being copied in parallel (up to all partitions in the cluster)

[NOTE]
====
Setting `max_yield_batch_bytes` over 1MB is counter-productive unless you change the broker settings to allow bigger messages or batches. The `partition_buffer_bytes` setting allows for partition readahead.
====

== Metrics
This input emits an `input_redpanda_migrator_lag` metric with `topic` and `partition` labels for each consumed topic. This metric records the number of produced messages that remain to be read from each topic/partition pair by the specified consumer group. Monitor this metric to track migration progress and detect bottlenecks.

== Metadata
This input adds the following metadata fields to each message:

- kafka_key
- kafka_topic
- kafka_partition
- kafka_offset
- kafka_lag
- kafka_timestamp_ms
- kafka_timestamp_unix
- All record headers

include::redpanda-connect:components:partial$fields/inputs/redpanda_migrator.adoc[]

== Troubleshooting

* Ensure the input and output `label` fields match exactly.
* Both input and output must be present in the pipeline.
* Verify consumer group configuration for partition balancing.
* Monitor the lag metric for stalled migration.

== Suggested reading

* xref:components:outputs/redpanda_migrator.adoc[`redpanda_migrator` output]
* xref:guides:migration/migrate-unified-redpanda-migrator.adoc[Migrating from legacy components]

// end::single-source[]
