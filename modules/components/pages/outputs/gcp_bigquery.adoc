= gcp_bigquery
// tag::single-source[]
:type: output
:status: beta
:categories: ["GCP","Services"]

// Â© 2024 Redpanda Data Inc.


component_type_dropdown::[]


Inserts message data as new rows in a Google Cloud BigQuery table.

ifndef::env-cloud[]
Introduced in version 3.55.0.
endif::[]

[tabs]
======
Common::
+
--

```yml
# Common configuration fields, showing default values
output:
  label: ""
  gcp_bigquery:
    project: ""
    job_project: ""
    dataset: "" # No default (required)
    table: "" # No default (required)
    format: NEWLINE_DELIMITED_JSON
    max_in_flight: 64
    job_labels: {}
    credentials_json: "" # No default (optional)
    csv:
      header: []
      field_delimiter: ','
    batching:
      count: 0
      byte_size: 0
      period: ""
      check: ""
```

--
Advanced::
+
--

```yml
# All configuration fields, showing default values
output:
  label: ""
  gcp_bigquery:
    project: ""
    job_project: ""
    dataset: "" # No default (required)
    table: "" # No default (required)
    format: NEWLINE_DELIMITED_JSON
    max_in_flight: 64
    write_disposition: WRITE_APPEND
    create_disposition: CREATE_IF_NEEDED
    ignore_unknown_values: false
    max_bad_records: 0
    auto_detect: false
    job_labels: {}
    credentials_json: "" # No default (optional)
    csv:
      header: []
      field_delimiter: ','
      allow_jagged_rows: false
      allow_quoted_newlines: false
      encoding: UTF-8
      skip_leading_rows: 1
    batching:
      count: 0
      byte_size: 0
      period: ""
      check: ""
      processors: [] # No default (optional)
```

--
======

== Credentials

By default, Redpanda Connect uses a xref:guides:cloud/gcp.adoc[shared credentials file] when connecting to GCP services.

== Format

The `gcp_bigquery` output currently supports only `NEWLINE_DELIMITED_JSON`, `CSV` and `PARQUET` formats. To learn more about how to use BigQuery with these formats, see the following documentation:

- https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-json[`NEWLINE_DELIMITED_JSON`^]
- https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv[`CSV`^]
- https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-parquet[`PARQUET`]

=== Newline-delimited JSON

Each JSON message may contain multiple elements separated by newlines. For example, a single message containing:

```json
{"key": "1"}
{"key": "2"}
```

Is equivalent to two separate messages:

```json
{"key": "1"}
```

And:

```json
{"key": "2"}
```

The same is true for the CSV format.

=== CSV

When the field `csv.header` is specified for the `CSV` format, a header row is inserted as the first line of each message batch. If this field is not provided, then the first message of each message batch must include a header line.

=== Parquet

Each message sent to this output must be a Parquet file. You can use the xref:components:processors/parquet_encode.adoc[`parquet_encode` processor] to convert message data into the correct format. For example:

```yaml
input:
  generate:
    mapping: |
      root = {
        "foo": random_int(),
        "bar": uuid_v4(),
        "time": now(),
      }
    interval: 0
    count: 1000
    batch_size: 1000
pipeline:
  processors:
    - parquet_encode:
        schema:
          - name: foo
            type: INT64
          - name: bar
            type: UTF8
          - name: time
            type: UTF8
        default_compression: zstd
output:
  gcp_bigquery:
    project: "${PROJECT}"
    dataset: "my_bq_dataset"
    table: "redpanda_connect_ingest"
    format: PARQUET
```

== Performance

The `gcp_bigquery` output benefits from sending multiple messages in parallel for improved performance. You can tune the maximum number of in-flight messages (or message batches) with the field `max_in_flight`.

This output also sends messages as a batch for improved performance. Redpanda Connect can form batches at both the input and output level. For more information, see xref:configuration:batching.adoc[].

include::redpanda-connect:components:partial$fields/outputs/gcp_bigquery.adoc[]

// end::single-source[]