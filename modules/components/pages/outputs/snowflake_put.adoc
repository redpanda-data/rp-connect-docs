= snowflake_put
// tag::single-source[]
:type: output
:categories: ["Services"]

// Â© 2024 Redpanda Data Inc.


component_type_dropdown::[]

TIP: Use the xref:components:outputs/snowflake_streaming.adoc[`snowflake_streaming` output] for improved performance, cost-effectiveness, and ease of use.

Sends messages to Snowflake stages and, optionally, calls Snowpipe to load this data into one or more tables.

ifndef::env-cloud[]
Introduced in version 4.0.0.
endif::[]

[tabs]
======
Common::
+
--

```yml
# Common configuration fields, showing default values
output:
  label: ""
  snowflake_put:
    account: "" # No default (required)
    region: us-west-2 # No default (optional)
    cloud: aws # No default (optional)
    user: "" # No default (required)
    password: "" # No default (optional)
    private_key: "" # No default (optional)
    private_key_file: "" # No default (optional)
    private_key_pass: "" # No default (optional)
    role: "" # No default (required)
    database: "" # No default (required)
    warehouse: "" # No default (required)
    schema: "" # No default (required)
    stage: "" # No default (required)
    path: ""
    file_name: ""
    file_extension: ""
    compression: AUTO
    request_id: ""
    snowpipe: "" # No default (optional)
    batching:
      count: 0
      byte_size: 0
      period: ""
      check: ""
    max_in_flight: 1
```

--
Advanced::
+
--

```yml
# All configuration fields, showing default values
output:
  label: ""
  snowflake_put:
    account: "" # No default (required)
    region: us-west-2 # No default (optional)
    cloud: aws # No default (optional)
    user: "" # No default (required)
    password: "" # No default (optional)
    private_key: "" # No default (optional)
    private_key_file: "" # No default (optional)
    private_key_pass: "" # No default (optional)
    role: "" # No default (required)
    database: "" # No default (required)
    warehouse: "" # No default (required)
    schema: "" # No default (required)
    stage: "" # No default (required)
    path: ""
    file_name: ""
    file_extension: ""
    upload_parallel_threads: 4
    compression: AUTO
    request_id: ""
    snowpipe: "" # No default (optional)
    client_session_keep_alive: false
    batching:
      count: 0
      byte_size: 0
      period: ""
      check: ""
      processors: [] # No default (optional)
    max_in_flight: 1
```

--
======

In order to use a different stage and / or Snowpipe for each message, you can use function interpolations as described in
xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries]. When using batching, messages are grouped by the calculated
stage and Snowpipe and are streamed to individual files in their corresponding stage and, optionally, a Snowpipe
`insertFiles` REST API call will be made for each individual file.

== Credentials

Two authentication mechanisms are supported:

- User/password
- Key Pair Authentication

=== User/password

This is a basic authentication mechanism which allows you to PUT data into a stage. However, it is not compatible with
Snowpipe.

=== Key pair authentication

This authentication mechanism allows Snowpipe functionality, but it does require configuring an SSH Private Key
beforehand. Please consult the https://docs.snowflake.com/en/user-guide/key-pair-auth.html#configuring-key-pair-authentication[documentation^]
for details on how to set it up and assign the Public Key to your user.

Note that the Snowflake documentation https://twitter.com/felipehoffa/status/1560811785606684672[used to suggest^]
using this command:

```bash
openssl genrsa 2048 | openssl pkcs8 -topk8 -inform PEM -out rsa_key.p8
```

to generate an encrypted SSH private key. However, in this case, it uses an encryption algorithm called
`pbeWithMD5AndDES-CBC`, which is part of the PKCS#5 v1.5 and is considered insecure. Due to this, Redpanda Connect does not
support it and, if you wish to use password-protected keys directly, you must use PKCS#5 v2.0 to encrypt them by using
the following command (as the current Snowflake docs suggest):

```bash
openssl genrsa 2048 | openssl pkcs8 -topk8 -v2 des3 -inform PEM -out rsa_key.p8
```

If you have an existing key encrypted with PKCS#5 v1.5, you can re-encrypt it with PKCS#5 v2.0 using this command:

```bash
openssl pkcs8 -in rsa_key_original.p8 -topk8 -v2 des3 -out rsa_key.p8
```

Please consult the https://linux.die.net/man/1/pkcs8[pkcs8 command documentation^] for details on PKCS#5 algorithms.

== Batching

It's common to want to upload messages to Snowflake as batched archives. The easiest way to do this is to batch your
messages at the output level and join the batch of messages with an
xref:components:processors/archive.adoc[`archive`] and/or xref:components:processors/compress.adoc[`compress`]
processor.

For the optimal batch size, please consult the Snowflake https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare.html[documentation^].

== Snowpipe

Given a table called `BENTHOS_TBL` with one column of type `variant`:

```sql
CREATE OR REPLACE TABLE BENTHOS_DB.PUBLIC.BENTHOS_TBL(RECORD variant)
```

and the following `BENTHOS_PIPE` Snowpipe:

```sql
CREATE OR REPLACE PIPE BENTHOS_DB.PUBLIC.BENTHOS_PIPE AUTO_INGEST = FALSE AS COPY INTO BENTHOS_DB.PUBLIC.BENTHOS_TBL FROM (SELECT * FROM @%BENTHOS_TBL) FILE_FORMAT = (TYPE = JSON COMPRESSION = AUTO)
```

you can configure Redpanda Connect to use the implicit table stage `@%BENTHOS_TBL` as the `stage` and
`BENTHOS_PIPE` as the `snowpipe`. In this case, you must set `compression` to `AUTO` and, if
using message batching, you'll need to configure an xref:components:processors/archive.adoc[`archive`] processor
with the `concatenate` format. Since the `compression` is set to `AUTO`, the
https://github.com/snowflakedb/gosnowflake[gosnowflake^] client library will compress the messages automatically so you
don't need to add a xref:components:processors/compress.adoc[`compress`] processor for message batches.

If you add `STRIP_OUTER_ARRAY = TRUE` in your Snowpipe `FILE_FORMAT`
definition, then you must use `json_array` instead of `concatenate` as the archive processor format.

NOTE: Only Snowpipes with `FILE_FORMAT` `TYPE` `JSON` are currently supported.

== Snowpipe troubleshooting

Snowpipe https://docs.snowflake.com/en/user-guide/data-load-snowpipe-rest-apis.html[provides^] the `insertReport`
and `loadHistoryScan` REST API endpoints which can be used to get information about recent Snowpipe calls. In
order to query them, you'll first need to generate a valid JWT token for your Snowflake account. There are two methods
for doing so:

- Using the `snowsql` https://docs.snowflake.com/en/user-guide/snowsql.html[utility^]:

```bash
snowsql --private-key-path rsa_key.p8 --generate-jwt -a <account> -u <user>
```

- Using the Python `sql-api-generate-jwt` https://docs.snowflake.com/en/developer-guide/sql-api/authenticating.html#generating-a-jwt-in-python[utility^]:

```bash
python3 sql-api-generate-jwt.py --private_key_file_path=rsa_key.p8 --account=<account> --user=<user>
```

Once you successfully generate a JWT token and store it into the `JWT_TOKEN` environment variable, then you can,
for example, query the `insertReport` endpoint using `curl`:

```bash
curl -H "Authorization: Bearer ${JWT_TOKEN}" "https://<account>.snowflakecomputing.com/v1/data/pipes/<database>.<schema>.<snowpipe>/insertReport"
```

If you need to pass in a valid `requestId` to any of these Snowpipe REST API endpoints, you can set a
xref:guides:bloblang/functions.adoc#uuid_v4[uuid_v4()] string in a metadata field called
`request_id`, log it via the xref:components:processors/log.adoc[`log`] processor and
then configure `request_id: ${ @request_id }` ). Alternatively, you can xref:components:logger/about.adoc[enable debug logging]
 and Redpanda Connect will print the Request IDs that it sends to Snowpipe.

== General troubleshooting

The underlying https://github.com/snowflakedb/gosnowflake[`gosnowflake` driver^] requires write access to
the default directory to use for temporary files. Please consult the https://pkg.go.dev/os#TempDir[`os.TempDir`^]
docs for details on how to change this directory via environment variables.

A silent failure can occur due to https://github.com/snowflakedb/gosnowflake/issues/701[this issue^], where the
underlying https://github.com/snowflakedb/gosnowflake[`gosnowflake` driver^] doesn't return an error and doesn't
log a failure if it can't figure out the current username. One way to trigger this behavior is by running Redpanda Connect in a
Docker container with a non-existent user ID (such as `--user 1000:1000`).


== Performance

This output benefits from sending multiple messages in flight in parallel for improved performance. You can tune the max number of in flight messages (or message batches) with the field `max_in_flight`.

This output benefits from sending messages as a batch for improved performance. Batches can be formed at both the input and output level. You can find out more xref:configuration:batching.adoc[in this doc].

include::redpanda-connect:components:partial$examples/outputs/snowflake_put.adoc[]

include::redpanda-connect:components:partial$fields/outputs/snowflake_put.adoc[]

// end::single-source[]