// This content is autogenerated. Do not edit manually.

== Examples

=== End of Stream Message

A common use case for sequence might be to generate a message at the end of our main input. With the following config once the records within `./dataset.csv` are exhausted our final payload `{"status":"finished"}` will be routed through the pipeline.

[source,yaml]
----
input:
  sequence:
    inputs:
      - file:
          paths: [ ./dataset.csv ]
          scanner:
            csv: {}
      - generate:
          count: 1
          mapping: 'root = {"status":"finished"}'
----

=== Joining Data (Simple)

Redpanda Connect can be used to join unordered data from fragmented datasets in memory by specifying a common identifier field and a number of sharded iterations. For example, given two CSV files, the first called "main.csv", which contains rows of user data:

```csv
uuid,name,age
AAA,Melanie,34
BBB,Emma,28
CCC,Geri,45
```

And the second called "hobbies.csv" that, for each user, contains zero or more rows of hobbies:

```csv
uuid,hobby
CCC,pokemon go
AAA,rowing
AAA,golf
```

We can parse and join this data into a single dataset:

```json
{"uuid":"AAA","name":"Melanie","age":34,"hobbies":["rowing","golf"]}
{"uuid":"BBB","name":"Emma","age":28}
{"uuid":"CCC","name":"Geri","age":45,"hobbies":["pokemon go"]}
```

With the following config:

[source,yaml]
----
input:
  sequence:
    sharded_join:
      type: full-outer
      id_path: uuid
      merge_strategy: array
    inputs:
      - file:
          paths:
            - ./hobbies.csv
            - ./main.csv
          scanner:
            csv: {}
----

=== Joining Data (Advanced)

In this example we are able to join unordered and fragmented data from a combination of CSV files and newline-delimited JSON documents by specifying multiple sequence inputs with their own processors for extracting the structured data.

The first file "main.csv" contains straight forward CSV data:

```csv
uuid,name,age
AAA,Melanie,34
BBB,Emma,28
CCC,Geri,45
```

And the second file called "hobbies.ndjson" contains JSON documents, one per line, that associate an identifier with an array of hobbies. However, these data objects are in a nested format:

```json
{"document":{"uuid":"CCC","hobbies":[{"type":"pokemon go"}]}}
{"document":{"uuid":"AAA","hobbies":[{"type":"rowing"},{"type":"golf"}]}}
```

And so we will want to map these into a flattened structure before the join, and then we will end up with a single dataset that looks like this:

```json
{"uuid":"AAA","name":"Melanie","age":34,"hobbies":["rowing","golf"]}
{"uuid":"BBB","name":"Emma","age":28}
{"uuid":"CCC","name":"Geri","age":45,"hobbies":["pokemon go"]}
```

With the following config:

[source,yaml]
----
input:
  sequence:
    sharded_join:
      type: full-outer
      id_path: uuid
      iterations: 10
      merge_strategy: array
    inputs:
      - file:
          paths: [ ./main.csv ]
          scanner:
            csv: {}
      - file:
          paths: [ ./hobbies.ndjson ]
          scanner:
            lines: {}
        processors:
          - mapping: |
              root.uuid = this.document.uuid
              root.hobbies = this.document.hobbies.map_each(this.type)
----


