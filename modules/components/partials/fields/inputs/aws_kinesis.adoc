// This content is autogenerated. Do not edit manually. To override descriptions, use the doc-tools CLI with the --overrides option: https://redpandadata.atlassian.net/wiki/spaces/DOC/pages/1247543314/Generate+reference+docs+for+Redpanda+Connect

== Fields

=== `auto_replay_nacks`

Whether messages that are rejected (nacked) at the output level should be automatically replayed indefinitely, eventually resulting in back pressure if the cause of the rejections is persistent. If set to `false` these messages will instead be deleted. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data can be discarded immediately upon consumption and mutation.

*Type*: `bool`

*Default*: `true`

=== `batching`


Allows you to configure a xref:configuration:batching.adoc[batching policy].

*Type*: `object`

[source,yaml]
----
# Examples:
batching:
  byte_size: 5000
  count: 0
  period: 1s

# ---

batching:
  count: 10
  period: 1s

# ---

batching:
  check: this.contains("END BATCH")
  count: 0
  period: 1m
----

=== `batching.byte_size`

An amount of bytes at which the batch should be flushed. If `0` disables size based batching.

*Type*: `int`

*Default*: `0`

=== `batching.check`

A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.

*Type*: `string`

*Default*: `""`

[source,yaml]
----
# Examples:
check: this.type == "end_of_transaction"
----

=== `batching.count`

A number of messages at which the batch should be flushed. If `0` disables count based batching.

*Type*: `int`

*Default*: `0`

=== `batching.period`

A period in which an incomplete batch should be flushed regardless of its size.

*Type*: `string`

*Default*: `""`

[source,yaml]
----
# Examples:
period: 1s

# ---

period: 1m

# ---

period: 500ms
----

=== `batching.processors[]`

A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.

*Type*: `processor`

[source,yaml]
----
# Examples:
processors:
  - archive:
      format: concatenate


# ---

processors:
  - archive:
      format: lines


# ---

processors:
  - archive:
      format: json_array

----

=== `checkpoint_limit`

The maximum gap between the in flight sequence versus the latest acknowledged sequence at a given time. Increasing this limit enables parallel processing and batching at the output level to work on individual shards. Any given sequence will not be committed unless all messages under that offset are delivered in order to preserve at least once delivery guarantees.

*Type*: `int`

*Default*: `1024`

=== `commit_period`

The period of time between each update to the checkpoint table.

*Type*: `string`

*Default*: `5s`

=== `credentials`

Manually configure the AWS credentials to use (optional). For more information, see the xref:guides:cloud/aws.adoc[].

*Type*: `object`

=== `credentials.from_ec2_role`

Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].

ifndef::env-cloud[]
Requires version 4.2.0 or later.
endif::[]

*Type*: `bool`

=== `credentials.id`

The ID of the AWS credentials to use.

*Type*: `string`

=== `credentials.profile`

The profile from `~/.aws/credentials` to use.

*Type*: `string`

=== `credentials.role`

The role ARN to assume.

*Type*: `string`

=== `credentials.role_external_id`

An external ID to use when assuming a role.

*Type*: `string`

=== `credentials.secret`

The secret for the AWS credentials in use.

include::redpanda-connect:components:partial$secret_warning.adoc[]

*Type*: `string`

=== `credentials.token`

The token for the AWS credentials in use. This is a required value for short-term credentials.

*Type*: `string`

=== `dynamodb`

Determines the table used for storing and accessing the latest consumed sequence for shards, and for coordinating balanced consumers of streams.

*Type*: `object`

=== `dynamodb.billing_mode`

When creating the table determines the billing mode.

*Type*: `string`

*Default*: `PAY_PER_REQUEST`

*Options*: `PROVISIONED`, `PAY_PER_REQUEST`

=== `dynamodb.create`

Whether, if the table does not exist, it should be created.

*Type*: `bool`

*Default*: `false`

=== `dynamodb.credentials`

Manually configure the AWS credentials to use (optional). For more information, see the xref:guides:cloud/aws.adoc[].

*Type*: `object`

=== `dynamodb.credentials.from_ec2_role`

Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].

ifndef::env-cloud[]
Requires version 4.2.0 or later.
endif::[]

*Type*: `bool`

=== `dynamodb.credentials.id`

The ID of the AWS credentials to use.

*Type*: `string`

=== `dynamodb.credentials.profile`

The profile from `~/.aws/credentials` to use.

*Type*: `string`

=== `dynamodb.credentials.role`

The role ARN to assume.

*Type*: `string`

=== `dynamodb.credentials.role_external_id`

An external ID to use when assuming a role.

*Type*: `string`

=== `dynamodb.credentials.secret`

The secret for the AWS credentials in use.

include::redpanda-connect:components:partial$secret_warning.adoc[]

*Type*: `string`

=== `dynamodb.credentials.token`

The token for the AWS credentials in use. This is a required value for short-term credentials.

*Type*: `string`

=== `dynamodb.endpoint`

A custom endpoint URL for AWS API requests. Use this to connect to AWS-compatible services or local testing environments instead of the standard AWS endpoints.

*Type*: `string`

=== `dynamodb.read_capacity_units`

Set the provisioned read capacity when creating the table with a `billing_mode` of `PROVISIONED`.

*Type*: `int`

*Default*: `0`

=== `dynamodb.region`

The AWS region to target.

*Type*: `string`

=== `dynamodb.table`

The name of the table to access.

*Type*: `string`

*Default*: `""`

=== `dynamodb.tcp`

Configure TCP socket-level settings to optimize network performance and reliability. These low-level controls are useful for:

- **High-latency networks**: Increase `connect_timeout` to allow more time for connection establishment
- **Long-lived connections**: Configure `keep_alive` settings to detect and recover from stale connections
- **Unstable networks**: Tune keep-alive probes to balance between quick failure detection and avoiding false positives
- **Linux systems with specific requirements**: Use `tcp_user_timeout` (Linux 2.6.37+) to control data acknowledgment timeouts

Most users should keep the default values. Only modify these settings if you're experiencing connection stability issues or have specific network requirements.

*Type*: `object`

=== `dynamodb.tcp.connect_timeout`

Maximum amount of time a dial will wait for a connect to complete. Zero disables.

*Type*: `string`

*Default*: `0s`

=== `dynamodb.tcp.keep_alive`

TCP keep-alive probe configuration.

*Type*: `object`

=== `dynamodb.tcp.keep_alive.count`

Maximum unanswered keep-alive probes before dropping the connection. Zero defaults to 9.

*Type*: `int`

*Default*: `9`

=== `dynamodb.tcp.keep_alive.idle`

Duration the connection must be idle before sending the first keep-alive probe. Zero defaults to 15s. Negative values disable keep-alive probes.

*Type*: `string`

*Default*: `15s`

=== `dynamodb.tcp.keep_alive.interval`

Duration between keep-alive probes. Zero defaults to 15s.

*Type*: `string`

*Default*: `15s`

=== `dynamodb.tcp.tcp_user_timeout`

Maximum time to wait for acknowledgment of transmitted data before killing the connection. Linux-only (kernel 2.6.37+), ignored on other platforms. When enabled, keep_alive.idle must be greater than this value per RFC 5482. Zero disables.

*Type*: `string`

*Default*: `0s`

=== `dynamodb.write_capacity_units`

Set the provisioned write capacity when creating the table with a `billing_mode` of `PROVISIONED`.

*Type*: `int`

*Default*: `0`

=== `endpoint`

A custom endpoint URL for AWS API requests. Use this to connect to AWS-compatible services or local testing environments instead of the standard AWS endpoints.

*Type*: `string`

=== `lease_period`

The period of time after which a client that has failed to update a shard checkpoint is assumed to be inactive.

*Type*: `string`

*Default*: `30s`

=== `rebalance_period`

The period of time between each attempt to rebalance shards across clients.

*Type*: `string`

*Default*: `30s`

=== `region`

The AWS region to target.

*Type*: `string`

=== `start_from_oldest`

Whether to consume from the oldest message when a sequence does not yet exist for the stream.

*Type*: `bool`

*Default*: `true`

=== `steal_grace_period`

Determines how long beyond the next commit period a client will wait when stealing a shard for the current owner to store a checkpoint. A longer value increases the time taken to balance shards but reduces the likelihood of processing duplicate messages.

*Type*: `string`

*Default*: `2s`

=== `streams[]`

One or more Kinesis data streams to consume from. Streams can either be specified by their name or full ARN. Shards of a stream are automatically balanced across consumers by coordinating through the provided DynamoDB table. Multiple comma separated streams can be listed in a single element. Shards are automatically distributed across consumers of a stream by coordinating through the provided DynamoDB table. Alternatively, it's possible to specify an explicit shard to consume from with a colon after the stream name, e.g. `foo:0` would consume the shard `0` of the stream `foo`.

*Type*: `array`

[source,yaml]
----
# Examples:
streams:
  - foo
  - "arn:aws:kinesis:*:111122223333:stream/my-stream"
----

=== `tcp`

Configure TCP socket-level settings to optimize network performance and reliability. These low-level controls are useful for:

- **High-latency networks**: Increase `connect_timeout` to allow more time for connection establishment
- **Long-lived connections**: Configure `keep_alive` settings to detect and recover from stale connections
- **Unstable networks**: Tune keep-alive probes to balance between quick failure detection and avoiding false positives
- **Linux systems with specific requirements**: Use `tcp_user_timeout` (Linux 2.6.37+) to control data acknowledgment timeouts

Most users should keep the default values. Only modify these settings if you're experiencing connection stability issues or have specific network requirements.

*Type*: `object`

=== `tcp.connect_timeout`

Maximum amount of time a dial will wait for a connect to complete. Zero disables.

*Type*: `string`

*Default*: `0s`

=== `tcp.keep_alive`

TCP keep-alive probe configuration.

*Type*: `object`

=== `tcp.keep_alive.count`

Maximum unanswered keep-alive probes before dropping the connection. Zero defaults to 9.

*Type*: `int`

*Default*: `9`

=== `tcp.keep_alive.idle`

Duration the connection must be idle before sending the first keep-alive probe. Zero defaults to 15s. Negative values disable keep-alive probes.

*Type*: `string`

*Default*: `15s`

=== `tcp.keep_alive.interval`

Duration between keep-alive probes. Zero defaults to 15s.

*Type*: `string`

*Default*: `15s`

=== `tcp.tcp_user_timeout`

Maximum time to wait for acknowledgment of transmitted data before killing the connection. Linux-only (kernel 2.6.37+), ignored on other platforms. When enabled, keep_alive.idle must be greater than this value per RFC 5482. Zero disables.

*Type*: `string`

*Default*: `0s`


