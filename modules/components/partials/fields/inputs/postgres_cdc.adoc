// This content is autogenerated. Do not edit manually. To override descriptions, use the doc-tools CLI with the --overrides option: https://redpandadata.atlassian.net/wiki/spaces/DOC/pages/1247543314/Generate+reference+docs+for+Redpanda+Connect

== Fields

=== `auto_replay_nacks`

Whether to automatically replay rejected messages (negative acknowledgements) at the output level. If the cause of rejections is persistent, leaving this option enabled can result in back pressure.

Set `auto_replay_nacks` to `false` to delete rejected messages. Disabling auto replays can greatly improve memory efficiency of high throughput streams as the original shape of the data is discarded immediately upon consumption and mutation.

*Type*: `bool`

*Default*: `true`

=== `batching`


Allows you to configure a xref:configuration:batching.adoc[batching policy].

*Type*: `object`

[source,yaml]
----
# Examples:
batching:
  byte_size: 5000
  count: 0
  period: 1s
batching:
  count: 10
  period: 1s
batching:
  check: this.contains("END BATCH")
  count: 0
  period: 1m
----

=== `batching.byte_size`

The number of bytes at which the batch is flushed. Set to `0` to disable size-based batching.

*Type*: `int`

*Default*: `0`

=== `batching.check`

A xref:guides:bloblang/about.adoc[Bloblang query] that returns a boolean value indicating whether a message should end a batch.

*Type*: `string`

*Default*: `""`

[source,yaml]
----
# Examples:
check: this.type == "end_of_transaction"
----

=== `batching.count`

The number of messages after which the batch is flushed. Set to `0` to disable count-based batching.

*Type*: `int`

*Default*: `0`

=== `batching.period`

The period of time after which an incomplete batch is flushed regardless of its size.

*Type*: `string`

*Default*: `""`

[source,yaml]
----
# Examples:
period: 1s
period: 1m
period: 500ms
----

=== `batching.processors[]`

For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches.

*Type*: `processor`

[source,yaml]
----
# Examples:
processors:
  - archive:
      format: concatenate

  - archive:
      format: lines

  - archive:
      format: json_array

----

=== `checkpoint_limit`

The maximum number of messages that this input can process at a given time. Increasing this limit enables parallel processing, and batching at the output level. To preserve at-least-once guarantees, any given log sequence number (LSN) is not acknowledged until all messages under that offset are delivered.

*Type*: `int`

*Default*: `1024`

=== `dsn`

The data source name (DSN) of the PostgreSQL database from which you want to stream updates. Use the format `postgres://[user[:password]@][netloc][:port][/dbname][?param1=value1&...]`. For example, if you wanted to disable SSL in a secure environment, you would add `sslmode=disable` to the connection string.

*Type*: `string`

[source,yaml]
----
# Examples:
dsn: postgres://foouser:foopass@localhost:5432/foodb?sslmode=disable
----

=== `heartbeat_interval`

The interval between heartbeat messages, which Redpanda Connect writes to the WAL using the `pg_logical_emit_message` function. 

Heartbeat messages are useful when you subscribe to data changes from tables with low activity, while other tables in the database have higher-frequency updates. Heartbeat messages allow Redpanda Connect to periodically acknowledge new messages even when no data updates occur. Each acknowledgement advances the committed point in the WAL, which ensures that PostgreSQL can safely reclaim older log segments, preventing excessive disk space usage.

Set `heartbeat_interval` to `0s` to disable heartbeats.

*Type*: `string`

*Default*: `1h`

[source,yaml]
----
# Examples:
heartbeat_interval: 0s
heartbeat_interval: 24h
----

=== `include_transaction_markers`

When set to `true`, creates empty messages for `BEGIN` and `COMMIT` operations which start and complete each transaction. Messages with the `operation` metadata field set to `BEGIN` or `COMMIT` have null message payloads.

*Type*: `bool`

*Default*: `false`

=== `max_parallel_snapshot_tables`

Specify the maximum number of tables that are processed in parallel when the initial snapshot of the source database is taken.

*Type*: `int`

*Default*: `1`

=== `pg_standby_timeout`

Specify the standby timeout after which an idle connection is refreshed to keep the connection alive.

*Type*: `string`

*Default*: `10s`

[source,yaml]
----
# Examples:
pg_standby_timeout: 30s
----

=== `pg_wal_monitor_interval`

How often to report changes to the replication lag and write them to Redpanda Connect metrics.

*Type*: `string`

*Default*: `3s`

[source,yaml]
----
# Examples:
pg_wal_monitor_interval: 6s
----

=== `schema`

The PostgreSQL schema from which to replicate data.

*Type*: `string`

[source,yaml]
----
# Examples:
schema: public
schema: "MyCaseSensitiveSchemaNeedingQuotes"
----

=== `slot_name`

The name of the PostgreSQL logical replication slot to use. If not provided, a random name is generated unless you create a replication slot manually before starting replication.

ifndef::env-cloud[]
NOTE: Starting from version 4.48.1, Redpanda Connect no longer adds the prefix `rs_` to the names of replication slots it creates. To continue using an existing replication slot after upgrading, manually add the `rs_` prefix to the slot name.
endif::[]

*Type*: `string`

[source,yaml]
----
# Examples:
slot_name: my_test_slot
----

=== `snapshot_batch_size`

The number of table rows to fetch in each batch when querying the snapshot.

This option is only available when `stream_snapshot` is set to `true`.

*Type*: `int`

*Default*: `1000`

[source,yaml]
----
# Examples:
snapshot_batch_size: 10000
----

=== `stream_snapshot`

When set to `true`, this input streams a snapshot of all existing data in the source database before streaming data changes. To use this setting, all database tables that you want to replicate _must_ have a primary key.

*Type*: `bool`

*Default*: `false`

[source,yaml]
----
# Examples:
stream_snapshot: true
----

=== `tables[]`

A list of database table names to include in the snapshot and logical replication. Specify each table name as a separate item.

*Type*: `array`

[source,yaml]
----
# Examples:
tables:
  - my_table_1
  - "MyCaseSensitiveTableNeedingQuotes"

----

=== `temporary_slot`

If set to `true`, the input creates a temporary replication slot that is automatically dropped when the connection to your source database is closed. You might use this option to:

- Avoid data accumulating in the replication slot when a pipeline is paused or stopped
- Test the connector

If the pipeline is restarted, another data snapshot is taken before data updates are streamed.

*Type*: `bool`

*Default*: `false`

=== `unchanged_toast_value`

Specify the value to emit when unchanged <<receive-toast-and-deleted-values, TOAST values>> appear in the message stream. Unchanged values occur for data updates and deletes when `REPLICA IDENTITY` is not set to `FULL`.

*Type*: `unknown`

*Default*:
[source,yaml]
----
null
----

[source,yaml]
----
# Examples:
unchanged_toast_value: __redpanda_connect_unchanged_toast_value__
----


