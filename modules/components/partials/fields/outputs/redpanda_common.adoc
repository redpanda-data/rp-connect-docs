// This content is autogenerated. Do not edit manually. To override descriptions, use the doc-tools CLI with the --overrides option: https://redpandadata.atlassian.net/wiki/spaces/DOC/pages/1247543314/Generate+reference+docs+for+Redpanda+Connect

== Fields

=== `batching`


Allows you to configure a xref:configuration:batching.adoc[batching policy].

*Type*: `object`

[source,yaml]
----
# Examples:
batching:
  byte_size: 5000
  count: 0
  period: 1s
batching:
  count: 10
  period: 1s
batching:
  check: this.contains("END BATCH")
  count: 0
  period: 1m
----

=== `batching.byte_size`

The number of bytes at which the batch is flushed. Set to `0` to disable size-based batching.

*Type*: `int`

*Default*: `0`

=== `batching.check`

A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.

*Type*: `string`

*Default*: `""`

[source,yaml]
----
# Examples:
check: this.type == "end_of_transaction"
----

=== `batching.count`

The number of messages after which the batch is flushed. Set to `0` to disable count-based batching.

*Type*: `int`

*Default*: `0`

=== `batching.period`

The period after which an incomplete batch is flushed regardless of its size.

*Type*: `string`

*Default*: `""`

[source,yaml]
----
# Examples:
period: 1s
period: 1m
period: 500ms
----

=== `batching.processors[]`

For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches.

*Type*: `processor`

[source,yaml]
----
# Examples:
processors:
  - archive:
      format: concatenate

  - archive:
      format: lines

  - archive:
      format: json_array

----

=== `key`

A key to populate for each message (optional). This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

*Type*: `string`

=== `max_in_flight`

The maximum number of messages to have in flight at a given time. Increase this number to improve throughput until performance plateaus.

*Type*: `int`

*Default*: `10`

=== `metadata`

Specify which (if any) metadata values are added to messages as headers.

*Type*: `object`

=== `metadata.include_patterns[]`

Provide a list of explicit metadata key regular expression (re2) patterns to match against.

*Type*: `array`

*Default*: `[]`

[source,yaml]
----
# Examples:
include_patterns:
  - .*

  - _timestamp_unix$

----

=== `metadata.include_prefixes[]`

Provide a list of explicit metadata key prefixes to match against.

*Type*: `array`

*Default*: `[]`

[source,yaml]
----
# Examples:
include_prefixes:
  - foo_
  - bar_

  - kafka_

  - content-

----

=== `partition`

Set a partition for each message (optional). This field is only relevant when the `partitioner` is set to `manual`.
This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

You must provide an interpolation string that is a valid integer.

*Type*: `string`

[source,yaml]
----
# Examples:
partition: ${! meta("partition") }
----

=== `timestamp_ms`

Set a timestamp (in milliseconds) for each message (optional). When left empty, the current timestamp is used. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

*Type*: `string`

[source,yaml]
----
# Examples:
timestamp_ms: ${! timestamp_unix_milli() }
timestamp_ms: ${! metadata("kafka_timestamp_ms") }
----

=== `topic`

A topic to write messages to. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

*Type*: `string`


