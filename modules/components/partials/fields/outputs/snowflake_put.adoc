// This content is autogenerated. Do not edit manually. To override descriptions, use the doc-tools CLI with the --overrides option: https://redpandadata.atlassian.net/wiki/spaces/DOC/pages/1247543314/Generate+reference+docs+for+Redpanda+Connect

== Fields

=== `account`

Account name, which is the same as the https://docs.snowflake.com/en/user-guide/admin-account-identifier.html#where-are-account-identifiers-used[Account Identifier^].
However, when using an https://docs.snowflake.com/en/user-guide/admin-account-identifier.html#using-an-account-locator-as-an-identifier[Account Locator^],
the Account Identifier is formatted as `<account_locator>.<region_id>.<cloud>` and this field needs to be
populated using the `<account_locator>` part.


*Type*: `string`

=== `batching`


Allows you to configure a xref:configuration:batching.adoc[batching policy].

*Type*: `object`

[source,yaml]
----
# Examples:
batching:
  byte_size: 5000
  count: 0
  period: 1s
batching:
  count: 10
  period: 1s
batching:
  check: this.contains("END BATCH")
  count: 0
  period: 1m
----

=== `batching.byte_size`

An amount of bytes at which the batch should be flushed. If `0` disables size based batching.

*Type*: `int`

*Default*: `0`

=== `batching.check`

A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.

*Type*: `string`

*Default*: `""`

[source,yaml]
----
# Examples:
check: this.type == "end_of_transaction"
----

=== `batching.count`

A number of messages at which the batch should be flushed. If `0` disables count based batching.

*Type*: `int`

*Default*: `0`

=== `batching.period`

A period in which an incomplete batch should be flushed regardless of its size.

*Type*: `string`

*Default*: `""`

[source,yaml]
----
# Examples:
period: 1s
period: 1m
period: 500ms
----

=== `batching.processors[]`

A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op.

*Type*: `processor`

[source,yaml]
----
# Examples:
processors:
  - archive:
      format: concatenate

  - archive:
      format: lines

  - archive:
      format: json_array

----

=== `client_session_keep_alive`

Enable Snowflake keepalive mechanism to prevent the client session from expiring after 4 hours (error 390114).

*Type*: `bool`

*Default*: `false`

=== `cloud`

Optional cloud platform field which needs to be populated
when using an https://docs.snowflake.com/en/user-guide/admin-account-identifier.html#using-an-account-locator-as-an-identifier[Account Locator^]
and it must be set to the `<cloud>` part of the Account Identifier
(`<account_locator>.<region_id>.<cloud>`).


*Type*: `string`

[source,yaml]
----
# Examples:
cloud: aws
cloud: gcp
cloud: azure
----

=== `compression`

Compression type.

*Type*: `string`

*Default*: `AUTO`

[cols="1m,2a"]
|===
|Option |Summary

|AUTO
|Compression (gzip) is applied automatically by the output and messages must contain plain-text JSON. Default `file_extension`: `gz`.

|DEFLATE
|Messages must be pre-compressed using the zlib algorithm (with zlib header, RFC1950). Default `file_extension`: `deflate`.

|GZIP
|Messages must be pre-compressed using the gzip algorithm. Default `file_extension`: `gz`.

|NONE
|No compression is applied and messages must contain plain-text JSON. Default `file_extension`: `json`.

|RAW_DEFLATE
|Messages must be pre-compressed using the flate algorithm (without header, RFC1951). Default `file_extension`: `raw_deflate`.

|ZSTD
|Messages must be pre-compressed using the Zstandard algorithm. Default `file_extension`: `zst`.

|===

=== `database`

Database.

*Type*: `string`

=== `file_extension`

Stage file extension. Will be derived from the configured `compression` if not set or empty.
This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

ifndef::env-cloud[]
Requires version v4.12.0 or later.
endif::[]

*Type*: `string`

*Default*: `""`

[source,yaml]
----
# Examples:
file_extension: csv
file_extension: parquet
----

=== `file_name`

Stage file name. Will be equal to the Request ID if not set or empty.
This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

ifndef::env-cloud[]
Requires version v4.12.0 or later.
endif::[]

*Type*: `string`

*Default*: `""`

=== `max_in_flight`

The maximum number of parallel message batches to have in flight at any given time.

*Type*: `int`

*Default*: `1`

=== `password`

An optional password.

include::redpanda-connect:components:partial$secret_warning.adoc[]

*Type*: `string`

=== `path`

Stage path.
This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

*Type*: `string`

*Default*: `""`

=== `private_key`

Your private SSH key. When using encrypted keys, you must also set a value for <<private_key_pass,`private_key_pass`>>.

include::redpanda-connect:components:partial$secret_warning.adoc[]

*Type*: `string`

=== `private_key_file`

The path to a file containing your private SSH key. When using encrypted keys, you must also set a value for <<private_key_pass,`private_key_pass`>>.

*Type*: `string`

=== `private_key_pass`

The passphrase for your private SSH key.

include::redpanda-connect:components:partial$secret_warning.adoc[]

*Type*: `string`

=== `region`

Optional region field which needs to be populated when using
an https://docs.snowflake.com/en/user-guide/admin-account-identifier.html#using-an-account-locator-as-an-identifier[Account Locator^]
and it must be set to the `<region_id>` part of the Account Identifier
(`<account_locator>.<region_id>.<cloud>`).


*Type*: `string`

[source,yaml]
----
# Examples:
region: us-west-2
----

=== `request_id`

Request ID. Will be assigned a random UUID (v4) string if not set or empty.
This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

ifndef::env-cloud[]
Requires version v4.12.0 or later.
endif::[]

*Type*: `string`

*Default*: `""`

=== `role`

Role.

*Type*: `string`

=== `schema`

Schema.

*Type*: `string`

=== `snowpipe`

An optional Snowpipe name. Use the `<snowpipe>` part from `<database>.<schema>.<snowpipe>`.
This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

*Type*: `string`

=== `stage`

Stage name. Use either one of the
		https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage.html[supported^] stage types.
This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

*Type*: `string`

=== `upload_parallel_threads`

Specifies the number of threads to use for uploading files.

*Type*: `int`

*Default*: `4`

=== `user`

Username.

*Type*: `string`

=== `warehouse`

Warehouse.

*Type*: `string`


